{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j4jefferson/dataScienceColabs/blob/main/RAG_LAB_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwoCG6V645td"
      },
      "source": [
        "#### <font color=FF595E>Installing packages</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPx4DkYQ5AcE",
        "outputId": "ace0381e-3018-41e9-c26f-3c54e0131c31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.0.28)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.0.8)\n",
            "Requirement already satisfied: langchainhub in /usr/local/lib/python3.10/dist-packages (0.1.15)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.4.24)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.12)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: rapidocr-onnxruntime in /usr/local/lib/python3.10/dist-packages (1.3.15)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.32.2)\n",
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.10/dist-packages (0.12.6)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (20231228)\n",
            "Requirement already satisfied: pikepdf in /usr/local/lib/python3.10/dist-packages (8.13.0)\n",
            "Requirement already satisfied: pillow_heif in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: langchain_experimental in /usr/local/lib/python3.10/dist-packages (0.0.54)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.4)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.31 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.32)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.26)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.14.0)\n",
            "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (2.31.0.6)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.1.1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.6.3)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.110.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.28.0)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.9.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.17.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.2)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.2)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.1.3)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.62.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.2)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (29.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.9.15)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: pyclipper>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (1.3.0.post5)\n",
            "Requirement already satisfied: opencv-python>=4.5.1.48 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (4.8.0.76)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (1.16.0)\n",
            "Requirement already satisfied: Shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (2.0.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (10.2.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.42)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.0)\n",
            "Requirement already satisfied: backoff==2.2.1 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.2.1)\n",
            "Requirement already satisfied: beautifulsoup4==4.12.3 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n",
            "Requirement already satisfied: certifi==2024.2.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2024.2.2)\n",
            "Requirement already satisfied: chardet==5.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer==3.3.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.3.2)\n",
            "Requirement already satisfied: dataclasses-json-speakeasy==0.5.11 in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.5.11)\n",
            "Requirement already satisfied: emoji==2.10.1 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.10.1)\n",
            "Requirement already satisfied: filetype==1.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: idna==3.6 in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.6)\n",
            "Requirement already satisfied: joblib==1.3.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.3.2)\n",
            "Requirement already satisfied: jsonpath-python==1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.0.6)\n",
            "Requirement already satisfied: langdetect==1.0.9 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.0.9)\n",
            "Requirement already satisfied: lxml==5.1.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.1.0)\n",
            "Requirement already satisfied: marshmallow==3.20.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.20.2)\n",
            "Requirement already satisfied: mypy-extensions==1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.0.0)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.8.2)\n",
            "Requirement already satisfied: python-iso639==2024.2.7 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2024.2.7)\n",
            "Requirement already satisfied: python-magic==0.4.27 in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: rapidfuzz==3.6.1 in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.6.1)\n",
            "Requirement already satisfied: soupsieve==2.5 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.5)\n",
            "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: typing-inspect==0.9.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: unstructured-client==0.18.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.18.0)\n",
            "Requirement already satisfied: urllib3==1.26.18 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.26.18)\n",
            "Requirement already satisfied: wrapt==1.16.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.16.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (42.0.5)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from pikepdf) (1.2.14)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.36.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.31->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.7)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.16.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
            "Requirement already satisfied: types-urllib3 in /usr/local/lib/python3.10/dist-packages (from types-requests<3.0.0.0,>=2.31.0.2->langchainhub) (1.26.25.14)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain_community) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain pypdf rapidocr-onnxruntime streamlit unstructured pdf2image pdfminer.six pikepdf pillow_heif langchain_experimental\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTsUkYw55JD_"
      },
      "source": [
        "#### <font color=FF595E>OpenAI API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zX6JxRjR5030"
      },
      "outputs": [],
      "source": [
        "#OpenAI API key\n",
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPEN_AI_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oOqSaVFoDydT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjS9jBuZc_JK"
      },
      "outputs": [],
      "source": [
        "#Setup LangSmith to trace development\n",
        "from langsmith import Client\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = 'RAG_LAB'\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGSMITH')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke135XHq6tO4"
      },
      "source": [
        "## <font color=FF595E>Creating ChatBot</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCaoUOIVlc8p"
      },
      "source": [
        "#### Define models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCjdc72Rlfzw"
      },
      "outputs": [],
      "source": [
        "GPT4 = 'gpt-4-0125-preview'\n",
        "GPT3 = 'gpt-3.5-turbo-0125'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0GVw8gCmB6v"
      },
      "source": [
        "#### Simple ChatBot, no memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAvyZk53mG1W"
      },
      "outputs": [],
      "source": [
        "#Import ChatOpenAI class\n",
        "from langchain_openai import ChatOpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19xHlPVBmPJj"
      },
      "outputs": [],
      "source": [
        "#Define the LLM. Specify model\n",
        "Chat = ChatOpenAI(model = GPT4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oVcf3Pima2N",
        "outputId": "5cc5959d-94f5-41fe-c33b-b4db3edb870d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='My knowledge is up to date until April 2023.', response_metadata={'finish_reason': 'stop', 'logprobs': None})"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "# Invoke the chat with simple question to test it out\n",
        "Chat.invoke('What is your knowledge cut off day?')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYi3nLALoiZE"
      },
      "source": [
        "#### Adding memory and memory management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuOa-FMtonKX"
      },
      "outputs": [],
      "source": [
        "# Import ChatMessageHistory class that will store our chat histor.\n",
        "# Import chat prompt templates classes and Message placeholders classes\n",
        "from langchain.memory import ChatMessageHistory\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpNQ0_V_pNrG"
      },
      "outputs": [],
      "source": [
        "# Initialize a new ChatMessageHistory object\n",
        "chat_history = ChatMessageHistory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEr6580tpXtr"
      },
      "outputs": [],
      "source": [
        "# Add a user message to the chat history\n",
        "chat_history.add_user_message(\"What day ChatGPT was launched\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge5j1RLEpqER"
      },
      "outputs": [],
      "source": [
        "# Add an AI response message to the chat history\n",
        "chat_history.add_ai_message(\"ChatGPT was launched at November 30, 2022\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFx-iWfGp7V5",
        "outputId": "3e929121-ed7e-41ad-a2ab-0b9901f18ed2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='What day ChatGPT was launched'),\n",
              " AIMessage(content='ChatGPT was launched at November 30, 2022')]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# Access the messages property of the chat_history object\n",
        "chat_history.messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOM7oZ6dqSTW"
      },
      "outputs": [],
      "source": [
        "# Add another user message to the chat history\n",
        "chat_history.add_user_message(\"Was it a successful launch?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MD6-TM_q2xG"
      },
      "outputs": [],
      "source": [
        "# Create a ChatPromptTemplate using messages\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        # Define a system message as a tuple\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
        "        ),\n",
        "        # Add a placeholder for the chat messages\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfFQW4vnr2WW"
      },
      "outputs": [],
      "source": [
        "# Create a simple Chain by passing prompt to LLM\n",
        "Chain = prompt | Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gvqSYJRsxt2",
        "outputId": "ac5b8169-ec71-4206-b90d-af35f10d7738"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Yes, the launch of ChatGPT by OpenAI in November 2022 was highly successful. It quickly gained widespread attention for its ability to generate coherent and contextually relevant text based on the prompts given to it. Users were impressed by its capabilities in generating human-like text responses, making it useful for a wide range of applications such as conversation simulation, content creation, and more. The launch led to significant media coverage and public discussion, further increasing its popularity and the awareness of AI's potential in natural language processing.\", response_metadata={'finish_reason': 'stop', 'logprobs': None})"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "#Invoking simple chain from messages\n",
        "Chain.invoke({\"messages\": chat_history.messages})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epNbqUxxtdYX"
      },
      "source": [
        "#### Creating a loop to run Chat with history, printable user imputs and chat outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgUKr3dItot7"
      },
      "outputs": [],
      "source": [
        "#Import\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "#Define stop words for our chatbot\n",
        "stop_words = [\"exit\", \"quit\", \"stop\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHT28jxauB2X",
        "outputId": "e21ce5d0-133e-4da1-9397-e3d6684701d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting the chat...\n",
            "User: What is the biggest country in Central America?\n",
            "AI: The biggest country in Central America by land area is Nicaragua. It covers an area of about 130,373 square kilometers (50,337 square miles). This makes Nicaragua the largest country in the region, followed by Honduras.\n",
            "User: What is its capital? \n",
            "AI: The capital of Nicaragua, the largest country in Central America, is Managua.\n",
            "User: What is its population?\n",
            "AI: As of my last update in April 2023, the estimated population of Managua, the capital of Nicaragua, was about 1.5 million in the city proper, with the metropolitan area having a larger population. However, it's important to note that population figures can vary depending on the source and the specific year of the estimate. For the most current and precise population data, it's recommended to consult the latest statistics from reliable sources such as the National Institute of Information Development (INIDE) in Nicaragua or international demographic databases.\n",
            "User: stop\n",
            "Exiting the chat...\n"
          ]
        }
      ],
      "source": [
        "#Define chat history\n",
        "chat_history = ChatMessageHistory()\n",
        "\n",
        "#Define LLM\n",
        "\n",
        "Chat = ChatOpenAI(model = GPT4)\n",
        "\n",
        "# Create a ChatPromptTemplate using messages\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        # Define a system message as a tuple\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
        "        ),\n",
        "        # Add a placeholder for the chat messages\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "#Define the chain\n",
        "Chat_chain = prompt | Chat\n",
        "\n",
        "#Use RunnableWithMessageHistory as a wrapper to manage message history\n",
        "Chain_with_message_history = RunnableWithMessageHistory(\n",
        "    Chat_chain,\n",
        "    #define access to chat history\n",
        "    lambda session_id : chat_history,\n",
        "    input_messages_key=\"messages\",\n",
        "    history_messages_key=\"chat_history\"\n",
        ")\n",
        "\n",
        "# Perform chat turns\n",
        "print(\"Starting the chat...\")\n",
        "while True:\n",
        "    question = input(\"User: \")\n",
        "\n",
        "    # Check if the user input matches a stop word\n",
        "    if question.lower() in stop_words:\n",
        "        print(\"Exiting the chat...\")\n",
        "        break\n",
        "\n",
        "    # Add a user message to the chat history\n",
        "    chat_history.add_user_message(question)\n",
        "\n",
        "    #Generate AI response\n",
        "    ai_response = Chain_with_message_history.invoke({\"messages\": chat_history.messages}, {\"configurable\": {\"session_id\": chat_history}})\n",
        "\n",
        "    # Add an AI response message to the chat history\n",
        "    chat_history.add_ai_message(ai_response.content)\n",
        "\n",
        "    #Display AI answer\n",
        "    print(f\"AI: {ai_response.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzIDIMcV1BPe"
      },
      "source": [
        "## <font color=FF595E>Building RAG Chatbot</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJfdkUCr1HEA"
      },
      "source": [
        "#### <font color=FF595E>Load documents</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Grab Cognition is all you need paper from [arxiv.org](https://arxiv.org/abs/2403.02164)"
      ],
      "metadata": {
        "id": "mq1ryJ0yFT-R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQx4TJdI1ocy"
      },
      "outputs": [],
      "source": [
        "#Import pdf loader.\n",
        "from langchain_community.document_loaders import UnstructuredPDFLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gs1Z1wMj2PsF"
      },
      "outputs": [],
      "source": [
        "#Define loader\n",
        "loader_pdf = UnstructuredPDFLoader(\"/content/Cognition is All You Need - Article.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUpbemnv2en6",
        "outputId": "6685136c-2e53-4518-cabe-da5f88c97556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "#Load an article\n",
        "article_pdf = loader_pdf.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxknnnco2pBI",
        "outputId": "ae22c79e-61ac-4562-ac76-d41ac8104699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='Cognition is All You Need The Next Layer of AI Above Large Language Models\\n\\nPre-Publication Position Paper Draft 1.1 March 4, 2024, For Comments\\n\\nNova Spivack1, Sam Douglas1, Michelle Crames1, Tim Connors1\\n\\n1 Mindcorp, Inc (www.mindcorp.ai) contact@mindcorp.ai www.mindcorp.ai www.linkedin.com/company/mindcorp-ai twitter.com/mindcorpai\\n\\nContents Abstract...................................................................................................................................2 Introduction..................................................................................................................................2 Related Research..................................................................................................................... 5 Defining Conversational AI...................................................................................................... 8 Intelligence Versus Cognition................................................................................................. 12 Instincts Versus Abstract Reasoning....................................................................................... 13 Defining Cognitive AI............................................................................................................. 14 Cognitive AI Functional Architecture......................................................................................15 Functional Requirements for Cognitive AI........................................................................ 15 Dual-Layer Architecture...................................................................................................... 17 Large Language Models......................................................................................................19 Cognitive Agents................................................................................................................. 20 Relationship Management, Inter-Agent Messaging and Dialogs....................................... 24 Planning and Project Management.................................................................................. 26 Neuro-Symbolic Reasoning.............................................................................................. 28 Memory Retrieval and Context Management...................................................................29 Knowledge Discovery and Knowledge Management........................................................ 30 Tool-Utilization..................................................................................................................... 32 Mathematics and Computation.......................................................................................... 33 Multi-Agent Collaboration................................................................................................34 Meta-Cognition................................................................................................................36 Self-Improvement................................................................................................................ 37 Comparison of Conversational AI to Cognitive AI................................................................... 40 Limits of Cognitive AI............................................................................................................. 45 Cognitive AI in the Evolutionary Ladder of Intelligence.......................................................... 46 Exponential Intelligence.........................................................................................................49 Implications...........................................................................................................................50 Crossing the Chasm............................................................................................................... 51 Early Adopters: Niche Applications and Proof of Concept................................................. 52 Early Majority: Crossing the Cognitive Chasm...................................................................53 Re-evaluating Current AI Approaches.....................................................................................53 LLMs as a Commodity...................................................................................................... 55 Commercial Cognitive AI.................................................................................................. 55 Conclusions........................................................................................................................... 56 References.............................................................................................................................58\\n\\n1\\n\\nAbstract Recent studies of the applications of conversational AI tools, such as chatbots powered by large language models (LLMs), to complex real-world knowledge work have shown limitations related to reasoning and multi-step problem solving. Specifically, while existing chatbots simulate shallow reasoning and understanding they are prone to errors as problem complexity increases. The failure of these systems to address complex knowledge work is due to the fact that they do not perform any actual cognition. In this position paper, we present a higher-level framework (“Cognitive AI”) for implementing programmatically defined neuro-symbolic cognition above and outside of large language models. Specifically, we propose a dual-layer functional architecture for Cognitive AI that serves as a roadmap for AI systems that can perform complex multi-step knowledge work. We propose that Cognitive AI is a necessary precursor for the evolution of higher forms of AI, such as AGI, and specifically claim that AGI cannot be achieved by probabilistic approaches on their own. We conclude with a discussion of the implications for large language models, adoption cycles in AI, and commercial Cognitive AI development.\\n\\nIntroduction\\n\\nAs the landscape of artificial intelligence continues to evolve towards increasing levels of intelligence, a new architectural paradigm is emerging: Cognitive AI (“CogAI”). In this position paper we will explore the distinctions between Conversational AI and Cognitive AI, with a focus on the key functional architecture components and requirements for Cognitive AI systems that are capable of doing complex knowledge work.\\n\\nCognitive AI represents a foundational shift in how AI systems are conceived, developed, and deployed. It is a distinct approach - focused around a new neuro-symbolic reasoning layer that works above Large Language Models (LLMs).\\n\\nTransformer-based LLMs (or similar probabilistic language models) will never be able to replicate what Cognitive AI is capable of, and in fairness, they were not designed to. However, this fact is not well-understood and has led to the widespread misconception that innovation on the model level will continue to yield major advances. LLMs will never actually get us to a significantly more advanced level of AI, because of their many inescapable limitations.\\n\\nLLMs are an essential enabling technology for Cognitive AI, and indeed, without them it cannot emerge or function. But the question is when will LLMs be “good enough” for Cognitive AI? Our answer is that they are already good enough. The current generation of large foundation models, plus growing diversity of more specialized open-source models, is already sufficient to meet the intelligence needs of the Cognitive Layer. Further improvements to LLMs, or any other Conversational AI level technologies, will only yield limited benefits.. Advancements in Cognitive AI will be more profound and will have more impact.\\n\\n2\\n\\nKey to the Cognitive AI paradigm is the representation and implementation of cognitive processes in a new “Cognitive Layer” that sits above the Conversational Layer where LLMs reside. The Cognitive Layer introduces a range of cognitive functions and capabilities which are beyond the reach of LLMs, yet use LLMs as tools.\\n\\nWhile the Cognitive Layer utilizes LLMs extensively, it is a higher-order layer of intelligence above the intelligence inherent in LLMs, giving it meta-level capabilities that far exceed what LLMs can do on their own. By utilizing the Cognitive Layer, Cognitive AI architectures are able to implement the higher levels of cognition that are necessary for real-work knowledge work, which in-turn is a precondition for mainstream adoption of AI.\\n\\nThis phase transition is not merely an incremental improvement but a rethinking of AI\\'s approach to performing complex cognitive tasks, combined with a new architectural paradigm, that together push the envelope of what machines can understand, and how they can interact with the world around them.\\n\\nCognitive AI offers a new frontier for research, development, IP and commercial applications that will be larger than the conversational AI frontier.\\n\\nBy 2030, if not sooner, we predict it will disrupt the AI landscape by shifting the focus of innovation and competition to a new playing field.\\n\\nCognitive AI provides a practical way to utilize the many prior decades of research and development in AI that preceded Conversational AI, above the Conversational Layer.\\n\\nIn addition, Cognitive AI is social. Human intelligence does not happen in a vacuum, it is a social process. Learning is a social process, as are nearly all human activities. It follows that the majority of human cognition is social, and the same goes for knowledge work.\\n\\nIt is necessary for any system capable of doing high-level knowledge to be built for cognition across social relationships. Specifically Cognitive AI is actually a form of collective cognition that leverages relationships among networks of agents - whether they be humans or software agents - to think, solve problems, innovate, and do knowledge work together.\\n\\nCollective cognition requires that all cognitive processes be at least potentially social and collaborative, if necessary. Whether it is storing and retrieving memories or expertise across relationships, or teaming up to solve a specific problem, Cognitive AI systems have to be able to leverage both distributed networks of human and machine intelligence. To do this effectively means these capabilities should not be “bolt-on” afterthoughts but rather they should be intrinsic to how such systems work.\\n\\nThe combination of both machine and human intelligence enable a higher level of cognition that goes beyond what AI can ever produce by itself. We call this “exponential intelligence.”\\n\\n3\\n\\nExponential intelligence is defined as a higher form of intelligence that emerges when human and machine intelligence are combined such that increasingly large and complex many-to-many cognitive processes can take place.\\n\\nBy enabling a deeper symbiosis (exponential intelligence) between human and machine intelligence, Cognitive AI will radically advance how people do knowledge work. Here we can view Cognitive AI as a partner with, not a replacement for, human knowledge workers.\\n\\nCognitive AI will enable humans to become more productive at knowledge work, and also to become better at it. In particular, Cognitive AI will make it possible for larger and more complex knowledge work to be completed by fewer people.\\n\\nThis will not only advance knowledge worker capabilities but it will also enable them to work on classes of problems that were previously thought to be too complex or difficult to do at all. In other words, Cognitive AI will move the frontier, bringing previously unattainable levels of cognition within reach of individual knowledge workers. This can help humanity solve the complex problems we face in the future.\\n\\nWithout adopting Cognitive AI, the field of AI can never achieve the level of reasoning required for complex knowledge work (Thórisson, 2020, Thórisson & Talbot, 2018). This means that attempts to use LLMs on their own to achieve artificial general intelligence (“AGI”) will never succeed. Large Language Models will continue to improve, but despite this, they are not even theoretically capable of the forms of reasoning, knowledge management, and complex operations, which are required for serious real-world knowledge work (cf. Thórisson 2021; Thórisson, 2012).\\n\\nTherefore, our response to the foundational paper of Conversational AI, “Attention is All You Need” is no, in fact, Cognition is all you need.\\n\\nTo reach more advanced levels of AI – for example, AI capable of meeting the demands of professional knowledge workers and knowledge organizations - we must innovate beyond the limits of the Conversational AI framework, and the Cognitive Layer is the best way forward for that agenda.\\n\\nFor experts in AI, venture capital, and technology trends, the coming shift to Cognitive AI signals a critical phase transition. For one thing, it means that investment into LLMs or similar-level alternatives, is likely to yield short term impressive gains, but diminishing long-term rewards, while the greatest potential future reward will come from investment into innovations and applications at the Cognitive Layer.\\n\\nIn other words, it would be wiser to invest in the Cognitive Layer instead of the Conversational layer, at this point in the innovation curve of both approaches. This requires a reassessment of\\n\\n4\\n\\ncurrent investment strategies in AI technologies, and a reevaluation of the potential applications and implications of AI across sectors.\\n\\nThe next wave of AI is Cognitive AI.\\n\\nIn this paper we will delve deeply into the arguments that prove this point, as well as their implications. Our arguments indicate that LLMs are a necessary but insufficient ingredient for complex knowledge work, while in contrast, CognitiveAI is both necessary and sufficient. The transition to Cognitive AI is inevitable and has already started.\\n\\nRelated Research\\n\\nWe begin by exploring the limits of Large-Language Models, and the corresponding paradigm of Conversational AI, for meeting the needs of mainstream adopter knowledge workers.\\n\\nConversational AI is a necessary ingredient for applying AI to knowledge work, but it is not sufficient for the full set of needs that knowledge workers have. While LLMs may improve certain aspects of knowledge work productivity – such as speed of work – they do not necessarily improve the quality of knowledge work.\\n\\nThe underlying reason for this lies in Conversational AI’s lack of actual cognitive processing, which limits the quality of insights it can deliver. We will explore cognitive processing in more detail in later sections of this paper, but first we examine evidence that indicates the insufficiency of LLMs for knowledge work.\\n\\nLarge language models have been widely celebrated for their remarkable performance across various natural language tasks, demonstrating the ability to achieve human-level performance on a wide spectrum of tasks (Moiseev et al., 2022). These models have been shown to encode substantial amounts of world and commonsense knowledge in their parameters, sparking significant interest in methods for extracting this knowledge (Haviv et al., 2021).\\n\\nHowever, evidence suggests that large language models (LLMs) may enhance productivity but not necessarily improve the quality of work for professionals. While Devlin et al. (2019) demonstrated that scaling to extreme model sizes leads to significant improvements on small-scale tasks, indicating potential productivity gains (Devlin et al., 2019), in contrast Conneau et al. (2020) have highlighted that pre-training on Wikipedia, a relatively limited scale data set, may not sufficiently address the quality aspect, especially for lower resource languages (Conneau et al., 2020). This indicates that while LLMs may enhance productivity, the quality of work, particularly in diverse linguistic contexts, may not be significantly improved, unless models are extremely large.\\n\\n5\\n\\nLarge Language Models have demonstrated exceptional performance in various natural language processing tasks and have shown the ability to solve reasoning problems (Ishay et al., 2023). However, LLMs face limitations in logical reasoning, which restrict their applicability in critical domains such as law (Nguyen, 2023). Existing literature exposes several challenges that LLMs face, including their lack of multi-step reasoning capabilities (Tongshuang et al., 2021), limitations in answering neurophysiology questions, and performing complex reasoning tasks (Shojaee-Mend, 2023). LLMs also lack transparency and explainability, making it challenging to obtain a complete picture of the knowledge reflected in a model or the reasoning used to produce its output (Liao et al., 2023). Moreover, the prospect of auditing LLMs is limited, and there are challenges in auditing LLMs at all (Mökander et al., 2023; Thórisson, 2021).\\n\\nBeyond the limitations that stem from model size, and reasoning limits, recent research has also highlighted the limitations of large language models in capturing and utilizing knowledge effectively for serious knowledge work. For instance, it has been observed that large pretrained language models only learn attested physical knowledge, indicating a limitation in their ability to capture and utilize diverse forms of knowledge (Porada et al., 2019). Furthermore, while these models have shown impressive few-shot results on a wide range of tasks, they struggle with compositional generalization to novel examples, which is a crucial capability for serious knowledge work (Yang et al., 2022).\\n\\nMoreover, the insufficiency of large language models for serious knowledge work is further underscored by their limited ability to reason and generate natural language proofs, as they struggle with reasoning in natural language and compositional generalization to novel examples (Yang et al., 2022).\\n\\nAdditionally, the challenge of adapting large parametric language models to evolving world knowledge without expensive model re-training further highlights their limitations in serious knowledge work (Pan et al., 2022). Furthermore, the fact that these models are trained on plain texts without introducing knowledge such as linguistic and world knowledge also points to their insufficiency for serious knowledge work (Sun, 2021).\\n\\nWhile large language models have demonstrated impressive performance across various natural language tasks and have been shown to encode substantial amounts of world and commonsense knowledge, their limitations in capturing diverse forms of knowledge, reasoning, and adapting to evolving world knowledge underscore their insufficiency for serious knowledge work.\\n\\nA study published in September 2023 by Harvard Business School showed that on average Conversational AI improved the work-quality of lower performers and sped up work in general, leading to better results approximately 40% of the time. However, to achieve mainstream adoption, it is necessary to innovate on the work-quality dimension.\\n\\n6\\n\\nA seminal study, “Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality,” (Dell’Acqua et al, 2023) conducted by Harvard University and BCG researchers examined the nuanced impact of AI on workforce productivity and accuracy, revealing a complex landscape where AI\\'s benefits are accompanied by notable pitfalls.\\n\\nWhile AI significantly boosted efficiency, enabling consultants to work faster, it also increased the likelihood of errors in tasks beyond AI\\'s enhancement scope by 19 percentage points. In this experiment, BCG employees completed a consulting task with help from an LLM-powered chatbot. The bottom-half of subjects, in terms of skills, benefited the most, showing a 43% improvement in performance, compared to the top half whose performance increased by 17%. This finding underscores the necessity of preparing the workforce for the \"jagged technological frontier\" of AI—areas where AI excels versus where its application may lead to suboptimal outcomes.\\n\\nThe research suggests that while AI can dramatically improve operational speed and facilitate multitasking, it falls short in handling complex issues that demand human empathy and nuanced understanding. This dichotomy emphasizes the importance of strategic AI integration, where technology complements rather than supplants human capabilities. For organizational leaders, the study advocates for a balanced approach to AI integration, focusing on continuous learning and adaptation to AI advancements. It calls for a collaborative effort to harness AI\\'s potential while mitigating its limitations, ensuring that AI and human collaboration synergize to propel innovation and success, avoiding the metaphorical \"coffee-flavored jellybeans\" scenario of unexpected and undesirable outcomes.\\n\\nSimilarly, other studies (Noy, S. et al 2023) found that people complete simulated information work tasks much faster and with a higher quality of output when using generative AI-based tools, however for some tasks, increased speed can come with moderately lower correctness (Spathariotiet al., 2023).\\n\\nAnother study, Microsoft’s “AI and Productivity Report,” cites multiple studies using Microsoft 365 Copilot observing information worker tasks for which LLMs are most likely to provide significant value (Cambon et al., 2023), in which most subjects agreed that Copilot helped them complete tasks faster, and the majority said it would help them get to a good first draft faster. However, several studies found no statistically significant or meaningful effect on work quality, despite subjects self-reporting the perception of improved quality.\\n\\nIn a study of a staggered rollout of a generative AI-based conversational assistant, Brynjolfsson et al. (2023) found that the tool helped novice and low-skilled workers the most. They found suggestive evidence that the AI helped disseminate tacit knowledge that experienced and high-skilled workers already had. In a lab experiment, participants who scored poorly on their first writing task improved more when given access to ChatGPT than those with high scores on the initial task (Noy & Zhang 2023). Peng et al. (2023) also found suggestive evidence that\\n\\n7\\n\\nGitHub Copilot was more helpful to developers with less experience. Recent work by Haslberger et al. (2023) highlights further complexities and nuances in these trends.\\n\\nIn another relevant study by Choi et al., 2023, researchers conducted the first randomized controlled trial to examine the impact of AI, specifically GPT-4, on human legal analysis. Law students were assigned to complete legal tasks with or without GPT-4 assistance, with their performance speed and quality blind-graded. This study revealed that GPT-4 marginally improved the quality of legal analysis, notably among the least skilled participants, while significantly enhancing task completion speed for all. Participants reported greater satisfaction when using AI and identified tasks where GPT-4 was most beneficial. These findings suggest AI\\'s potential to boost productivity, satisfaction, and even promote equality within the legal profession.\\n\\nFrom the above cited research we conclude that while Conversational AI and Large Language Models (LLMs) offer substantial benefits in terms of speed and efficiency in knowledge work, their contribution to enhancing the quality of knowledge work remains questionable, due in part to limitations in their reasoning, logical analysis, and adaptation to evolving knowledge landscapes.\\n\\nThe integration of Cognitive AI into the knowledge workforce offers a path forward, where AI can not only improve knowledge work productivity, but also knowledge work quality. This represents a pivotal shift towards leveraging AI\\'s strengths while effectively addressing the shortcomings of LLMs. In addition, by fostering a symbiotic relationship between human intelligence and AI\\'s computational power, Cognitive AI can unlock new frontiers of collaborative innovation in knowledge work.\\n\\nIn the sections below we will conduct technical and theoretical comparison of Conversational AI versus Cognitive AI, for the purpose of knowledge work. We will show that LLMs are neither practically or theoretically capable of meeting the needs of knowledge work. While they may contribute to knowledge work by simulating aspects of these cognitive processes, these simulations have inherent limitations that cannot be overcome. The solution we propose is Cognitive AI, which is a new evolution of AI that performs higher-level cognitive processing, by harnessing the benefits of LLMs without being limited by their weaknesses.\\n\\nDefining Conversational AI\\n\\nConversational AI is a form of artificial intelligence based on conversations between agents. Here agents can be software agents or human agents. To be more precise, Conversational AI is a form of AI based on conversations which include at least two agents, where one is a software agent.\\n\\n8\\n\\nIn Conversational AI agents communicate through streams of tokens, using Large Language Models (LLMs) to mediate their interactions. LLMs use underlying probabilistic models to generate token strings in response to token strings.\\n\\nFigure 1. Token Streams\\n\\nThe fundamental units of Conversational AI are conversations or chats, which are streams of messages between agents.\\n\\nFigure 2. Chats\\n\\nThe user-facing manifestation of Conversational AI is manifest as a “chatbot,” which is an application that executes a simple linguistic circuit between a software agent playing the role of the “bot” and a human user (or another software agent) that communicates with it.\\n\\nFigure 3. Chatbots.\\n\\n9\\n\\nBy adding additional components to these circuits, they can make use of external data in the form of vector embeddings, and queries against vector databases, to augment the training of the underlying model at runtime. This makes these circuits able to incorporate new information that is not in the original training of the underlying LLMs.\\n\\nFigure 4. Retrieval Augmented Generation (RAG).\\n\\nIt is also possible to create multi-agent systems in which LLM-powered agents can engage in dialogs with each other (and optionally also with humans).\\n\\nFigure 5. Multi-agent dialogs.\\n\\nThe process of Conversational AI, using state-of-the-art foundation models such as OpenAI’s GPT 4 plus vector embeddings, enables a surprisingly powerful level of interactive artificial intelligence which is capable of answering questions and generating useful content about an infinite range of topics and data.\\n\\n10\\n\\nHowever, while Conversational AI achieves virtually unlimited breadth on simple tasks, the depth of its intelligence on more complex tasks is limited.\\n\\nConversational AI is a form of “first-order intelligence” that generates responses using LLMs, without understanding, reasoning or reflecting on anything (Thórisson et al., 2016)\\n\\nUsing “prompts,” and “prompt-engineering” methodologies it is possible to use language to guide the behavior of LLMs, in order to cause them to generate more specific outputs for various kinds of inputs. Prompts, like all messages between agents and the LLM, are saved to a “chat transcript” for an interaction session.\\n\\nThe “chat transcript” is a history of messages between agents, along with any added external information.\\n\\nChatbots operate with finite history. The “context” of a chat is defined as the set tokens that an LLM is given as input in order to generate a completion as output. Context cannot be longer than the maximum number of tokens an LLM can accept in a single input. In a chatbot application, the interaction between agents and the LLM proceeds in a series of interleaved messages that constitute a “dialog.” Messages, and dialogs composed of them, can be any length under whatever token length constraints are in effect.\\n\\nThe “token window” is the maximum number of tokens that can be provided as context to an LLM. In a dialog that produces a stream of tokens that exceeds the maximum number of tokens that the LLM can read in a single input, the token window is a moving window in the transcript, and is provided to the LLM as context for each input.\\n\\nUsing these basic constraints, Chatbots can generate dialogs that appear to be the products of intelligence and reasoning. However, in such dialogs only the subset of messages by human agents (such as a human user) involve any reasoning. Messages produced by the chatbots, which are generated by the LLM model, are in fact purely probabilistic streams of guesses which do not involve any understanding or reasoning.\\n\\nIt is a common misconception that chatbots understand what they say, or what users say, or what dialogs are about. In fact, for any given input such as a message from a human user, the chatbot simply uses the probabilistic weights in the underlying LLM to generate and return a stream of tokens that are correlated with the input above a certain probability threshold.\\n\\nInstead of reasoning, Conversational AI applications generate statistical responses that seem to be the products of cognition, but are in fact only the products of non-cognitive intelligence that emerges from probabilities based on the numeric weights of the underlying models, which in turn are a consequence of their training and the data they were trained on.\\n\\n11\\n\\nConversational AI is essentially a form of advanced mimicry of the cognitive processes, based on probabilistic models. Inherent in this fact are many inescapable built-in limitations which we will explore later in this paper.\\n\\nIntelligence Versus Cognition\\n\\n“Intelligence” can be defined as the set of all systems that generate non-random output information in response to non-random input information. This is quite a broad definition, in which even physical processes and mathematical functions and formal systems can be considered to be forms of intelligence.\\n\\nWithin intelligence, the class of systems that are equivalent to Turing Machines conduct computations. Within the set of computations, machine learning systems exhibit the ability to make predictions based on learning. Likewise, computations that perform artificial intelligence generate outputs that more closely resemble those that humans can generate.\\n\\n“Cognition” is a specific subset of intelligence, where the processing that systems do to transform inputs to outputs closely mirrors human cognitive processing. Within the scope of cognition, there are a number of critical cognitive processes that can take place, including learning and self-improvement, sensing, self-reflection and introspection, language understanding and processing, memory and context management, knowledge representation, knowledge management, knowledge processing, research and exploration, reasoning, planning, decision making, project management, and task execution.\\n\\nLLMs produce outputs from inputs that seem to be the products of cognition. The linguistic (or visual, auditory, data) structures they generate are highly contextually relevant and appropriate responses to the meanings of the inputs they receive.\\n\\nFrom a “black box” perspective - without knowing how LLMs work - one might assume they understand, reason, and even can be creative. However no cognitive activity is actually taking place within LLMs. They have no understanding of what is being said and they do not think, they merely process probabilities. However, despite this, LLMs produce surprisingly good responses that appear to be the products of cognitive processing, in other words they do a good job of mimicking cognition.\\n\\nLLMs, and all Conversational AI systems, are classified as intelligent, but not cognitive, because they perform probabilistic natural language processing and response generation, but they do not actually perform higher level cognition.\\n\\n12\\n\\nInstincts Versus Abstract Reasoning\\n\\nThe distinction between the operational mechanics of Large Language Models (LLMs) and the advanced functionalities of Cognitive AI highlights a fundamental divide between different forms of artificial intelligence: instinctual intelligence versus abstract cognitive reasoning. This divide not only characterizes the limitations and capabilities of these AI systems but also underscores the evolutionary trajectory from simple pattern recognition to complex cognitive processing.\\n\\nLLMs operate on what can be described as \"instinctual intelligence” in which responses are instinctual, meaning that they are provided automatically without any intermediate thinking or reasoning. Like instincts, which are innate, non-adaptive responses triggered by specific stimuli, LLMs respond to inputs based on patterns learned during their training phase. This process is inherently non-adaptive; LLMs cannot learn, reason, or change in real-time. Their responses, while sophisticated and often convincingly human-like, are limited by their training, lacking the capacity for live, on-the-fly learning or adaptation.\\n\\nThe interaction with an LLM, therefore, does not involve any genuine learning or memory integration. Responses generated during an LLM\\'s operation are the result of processing input patterns against a static model, with no new information retained or integrated into the model\\'s \"knowledge\" post-training. Even with the introduction of embeddings to augment LLM responses at runtime, the LLM processes these probabilistically, without engaging in actual learning or thought.\\n\\nIn stark contrast, Cognitive AI embodies the principles of abstract reasoning and second-order learning, engaging in a continuous loop of learning and adaptation even during runtime. Unlike the static, instinctual responses of LLMs, Cognitive AI\\'s architecture allows for the accumulation of new knowledge, adjustment of strategies based on live feedback, and genuine reasoning about the content it processes. This dynamic capability enables Cognitive AI to not just simulate reasoning but to actually reason, learn from interactions, and evolve its understanding and responses over time.\\n\\nCognitive AI\\'s approach to problem-solving and interaction is underpinned by structured knowledge and reasoning algorithms, facilitating a level of analysis, decision-making, and creativity far beyond the capabilities of LLMs. This not only allows for more accurate and contextually relevant responses but also supports the system\\'s ability to engage in genuine abstract reasoning, drawing inferences, and generating hypotheses beyond the immediate input patterns.\\n\\nIt is expected that all of the major foundation models will continue to evolve and develop higher levels of world knowledge, comprehension, reasoning, user interaction, tool utilization, and\\n\\n13\\n\\nself-improvement. However, these capabilities will still be mimicry as opposed to actual cognition.\\n\\nWhile LLMs can offer powerful artificial intelligence capabilities through simulated reasoning, producing responses that are often surprisingly apt, the inherent limitations of this approach become apparent as the complexity of tasks increases. The inability to learn or adapt in real-time, coupled with a lack of genuine understanding or reasoning, places a ceiling on the intelligence that LLMs can achieve.\\n\\nIn contrast, Cognitive AI\\'s capacity for abstract reasoning, continuous learning, and dynamic adaptation represents a significant leap towards overcoming these limitations, pointing the way towards more sophisticated, versatile, and genuinely intelligent AI systems.\\n\\nThe evolution from the instinctual intelligence of LLMs to the abstract cognitive reasoning capabilities of Cognitive AI marks a pivotal shift in artificial intelligence. By transcending the bounds of pattern-based responses and embracing the complexities of genuine learning and reasoning, Cognitive AI paves the way for AI systems that can engage more deeply with the world, solve more complex problems, and, ultimately, approach the elusive goal of Artificial General Intelligence. This shift from simulated reasoning to genuine cognitive processing defines the next frontier in AI, promising advancements that could redefine our understanding of what machines are capable of achieving.\\n\\nDefining Cognitive AI\\n\\nCognitive AI is a subset of artificial intelligence in which a cognitive layer executes neuro-symbolic cognitive processes that are modeled on individual and collective human cognition, by making use of a Cognitive Layer that uses a Conversational Layer.\\n\\nThe distinction between Conversational AI and Cognitive AI is precisely that Cognitive AI does not merely mimic cognition, rather it executes formal cognition outside of the underlying LLM models it uses. Therefore Cognitive AI is classified as both intelligent and cognitive.\\n\\nBy implementing the cognitive processes of the human mind, as well as collective intelligences of groups of humans, Cognitive AI is capable of self-directed thought and the orchestration of its cognitive processes, essentially enabling it to manage its knowledge work autonomously.\\n\\nCognitive AI transcends traditional AI\\'s focus on pattern recognition and probabilistic predictions by incorporating a second layer of intelligence: meta-cognition. This advanced cognitive layer enables the AI to engage in genuine reasoning and learning from experiences, allowing for strategic adaptations in real-time. Such capabilities enable Cognitive AI to tackle complex, dynamically changing problems far beyond the reach of current LLMs.\\n\\n14\\n\\nFigure 6. Conversational Versus Cognitive AI Quadrants.\\n\\nCognitive AI Functional Architecture\\n\\nCognitive AI represents a paradigm shift, moving beyond the confines of Conversational AI\\'s reliance on probabilistic reasoning simulations to actual programmatic reasoning. This shift is embodied in a dual-layer architecture that elevates reasoning, self-improvement, and adaptability to second-order intelligence, fundamentally distinguishing Cognitive AI from its predecessors. Below we will discuss the functional architecture and formal requirements for Cognitive AI systems.\\n\\nFunctional Requirements for Cognitive AI\\n\\nTo qualify as Cognitive AI, a system must be architected to meet the following functional criteria:\\n\\n1. Dual-Layer Cognitive Architecture. The system is organized into at least a dual-layer architecture, in which a Cognitive Layer that supports higher-level cognitive functions sits above a Conversational Layer that provides services equivalent to a general-purpose large language model.\\n\\n15\\n\\n2. Large Language Models. The system must provide and utilize one or more large language models (LLMS), or other similarly powerful and general alternative probabilistic models, in the Conversational layer, where at least one model is closely comparable to a large general purpose foundation model (such as GPT 4).\\n\\n3. Cognitive Agents. The system must be architected with agentic design patterns and principles as an agentic application that provides intelligent cognitive agents which can operate semi-autonomously or fully autonomously, and where such agents are controlled and executed from outside of LLM transcripts, by an agent management function implemented as executable software.\\n\\n4. Relationship Management. The system must enable the formation, management and use of social relationships to connect agents (including humans and software agents) on a one-to-one and one-to-many basis. Inter-Agent Messaging. The system must enable natural language interactive messaging communication and the sharing of system objects (documents, knowledge, tools, data, agents, projects, plans, etc.) between agents that are directly or indirectly connected by mutual relationships.\\n\\n4. Relationship Management. The system must enable the formation, management and use of social relationships to connect agents (including humans and software agents) on a one-to-one and one-to-many basis. Inter-Agent Messaging. The system must enable natural language interactive messaging communication and the sharing of system objects (documents, knowledge, tools, data, agents, projects, plans, etc.) between agents that are directly or indirectly connected by mutual relationships.\\n\\n6. Dialogs. The system must utilize interactive internal and external dialogs between two or more agents, where agents can be software-based or humans, and where in any dialog there is at least one software agent, and where dialog formats and execution can be structured and controlled with conditional logic rules..\\n\\n7. Planning. The system must be able to generate, understand and respond to complex conditional workflows as plans in natural language.\\n\\n8. Project Management. The system must provide a project management function to orchestrate and manage execution of plans by one or more agents.\\n\\n9. Neuro-Symbolic Reasoning. The system must support generation of explicitly defined workflows for controlling both informal natural language reasoning and formal logical reasoning, where such workflows are executed and controlled from within the Cognitive Layer instead of from within the Conversational Layer.\\n\\n10. Memory Retrieval. The system must be able to utilize its own planning and reasoning mechanisms to intelligently guide strategies for locating and retrieving relevant information and knowledge for a given context, across internal knowledge bases, long-term memory, and external data sources including the Internet.\\n\\n11. Context Management. The system must manage context for agents and cognitive processes using a working memory to cache and swap relevant contextual information from long-term memory, in order to optimize relevancy of information in context against finite token windows of LLMs.\\n\\n12. Knowledge Discovery. The system must conduct intelligently guided natural language and Boolean search, as well as deeper research strategies guided by agents (such as intelligently guided spidering for relevant information) to locate relevant information and knowledge across heterogeneous data sources (internal knowledge bases, long-term memory stores, and external resources including the Internet and third-party APIs).\\n\\n16\\n\\n13. Knowledge Management. The system must explicitly generate, learn, represent, store, retrieve and maintain formal data structures for representing knowledge that exist outside of LLMs.\\n\\n14. Tool-Utilization. The system must have the ability to design and use tools in the form of software applications, APIs, and internal and external data sources. Tool-utilization also applies to a system being able to self-referentially utilize its own functional components as tools, to design and implement new tools, and to improve tools.\\n\\n15. Mathematics and Computation. The system must have the ability to do mathematical and computational operations outside of LLMs, using software, data sets, and computing hardware and infrastructure. This also provides the system with advanced formal logical processing, scientific and financial calculation abilities, as well as data science and analytics and machine learning capabilities.\\n\\n16. Multi-Agent Collaboration. The system must have the ability to orchestrate collaborative processes between human agents and software agents. This includes one-to-one, one-to-many, many-to-one, and many-to-many collaborative processes.\\n\\n17. Meta-Cognition. The system must provide a meta-cognition function that can be utilized across all major cognitive functions of the system, and is capable of knowledge processing, introspection, meta-reasoning, reflection, learning, and self-optimization.\\n\\n18. Self-improvement. The system must be able to engage in recursive goal-directed self-improvement, if and when needed, across all major cognitive processes, to iteratively optimize reasoning, knowledge, projects, plan, dialogs, agents, documents and code, both asynchronously and during runtime execution.\\n\\nDual-Layer Architecture\\n\\nAt the core of Cognitive AI\\'s functional architecture is an intelligence stack comprising two critical layers: a Cognitive Layer and a Conversational Layer.\\n\\nThe Conversational Layer operates on the principles familiar to LLMs (Large Language Models), processing and responding to linguistic inputs. Positioned above this, the Cognitive Layer introduces meta-cognition capabilities, extending the system\\'s functionalities beyond mere linguistic processing to encompass higher-order cognitive processes.\\n\\n17\\n\\nFigure 7. Cognitive AI Functional Architecture\\n\\nThe above diagram illustrates the functional architecture of Mindcorp’s Cognition platform for Cognitive AI and can serve as general model for how Cognitive AI architectures are designed.\\n\\nThe Cognitive Layer is where Cognitive AI truly differentiates itself. It provides the system with the ability to engage in meta-cognition (also called meta-cognition), in which it can engage in introspection, enabling a deeper level of understanding and optimization of its own processes. This functional area allows Cognitive AI to critically assess its methodologies for learning, reasoning, planning, and decision-making, mirroring the cognitive functions of the human mind engaged in complex knowledge work.\\n\\nThrough meta-cognition, Cognitive AI can refine and adjust its strategies at runtime, responding dynamically to new information and challenges. This adaptability is crucial for applications requiring not just an understanding of data but also the capacity to apply strategic thinking and creativity to solve problems.\\n\\nThe integration of meta-cognition equips Cognitive AI systems with the unique ability to self-assess their thought processes and learn from their interactions. This self-assessment capability ensures that Cognitive AI can continually refine its operational strategies, enhancing its efficiency and effectiveness over time. By continuously learning from its actions and the outcomes of its decisions, Cognitive AI can evolve its approach to problem-solving, ensuring that it remains effective in the face of changing conditions and requirements.\\n\\n18\\n\\nThe architectural distinction of Cognitive AI, characterized by its dual-layer approach in which meta-cognition plays an important role, marks a significant advancement in the field of artificial intelligence. This cognitive structure not only enables Cognitive AI to process information linguistically but also empowers it with the ability to reason, plan, and improve itself autonomously.\\n\\nBy mirroring the cognitive processes of the human mind and incorporating the capacity for self-reflection and adaptation, Cognitive AI opens new avenues for solving complex problems, making it a powerful tool for real-world knowledge work and beyond. This architectural innovation lays the foundation for a new generation of AI systems capable of more sophisticated, adaptable, and effective problem-solving strategies, setting Cognitive AI apart from traditional Conversational AI technologies.\\n\\nLarge Language Models\\n\\nLarge Language Models (LLM’s) are a class of probabilistic language models, generally based on an attention-based transformer algorithm for predicting next tokens from a stream of previous tokens. These models are trained to make predictions that correspond to the knowledge inherent in the training data sets and fine-tunings may also be added.\\n\\nFigure 8. Leading LLM Models. Source: Minaee, S., et al., (2024).\\n\\nThe large foundation-level LLMs generate streams of tokens that contain sophisticated linguistic responses to streams of tokens. These responses are so similar to the kinds of intelligent responses that humans can generate, that the underlying LLM’s are also said to be highly intelligent. However, as this paper will make exceedingly clear, there is a difference between intelligence and cognition. LLMs may be highly intelligent, but they are not cognitive at all, and this ultimately is their weakness.\\n\\n19\\n\\nFigure 9. LLM Capabilities. Source: Minaee, S., et al., (2024).\\n\\nThe above diagram illustrates the current and emerging state of LLM capabilities. The diagram shows the capabilities of LLMs projected to be advancing into comprehension, reasoning, tool-utilization, social interactions, and self-improvement.\\n\\nHowever it is important to note, and one of the main points of this paper, that within the context of LLMs, there is no actual comprehension, reasoning, tool-utilization, social interactions or self-improvement taking place. While the LLMs are very good at mimicking these processes to participate in simple conversations and generate basic documents, their ability to do so is shallow and falls apart quickly when problems get longer and/or multilayered and complex.\\n\\nDespite the limitations of LLMs, they are the critical prerequisite for Cognitive AI. The language-level intelligence of LLMs is indispensable for Cognitive AI systems to function. However, in Cognitive AI systems the LLMs are not used to implement complex reasoning directly using language; instead complex reasoning and procedures are implemented on the Cognitive Layer, above the LLMs.\\n\\nCognitive Agents\\n\\nThe genesis of Cognitive AI can be traced back to the burgeoning interest in agentic applications that operate above the LLM layer. Chatbots are the most widely-known example of the agent paradigm in the context of AI, but there are many other kinds of agents that can use LLMs without necessarily chatting or communicating with end-users.\\n\\n20\\n\\nThese applications, characterized by their ability to complete tasks via one or more LLM-powered agents collaborating with a human and/or even with one another, mark the first steps towards transcending the limitations of LLM-driven models.\\n\\nWhile initial forays into agentic AI have been focused on relatively simple tasks such as chatbots and various iterations of agents built on them, including agents that conduct online research, engage in social media, and complete simple online tasks, they lay the groundwork for more sophisticated, intelligent systems capable of complex decision-making and problem-solving.\\n\\nAs Cognitive AI begins to emerge, new agentic architectures and applications are forming above the LLM layer that do conduct rudimentary cognitive processing. In these platforms and applications, multi-agent systems provide agents that collaborate and/or compete to solve problems, using LLMs to think and converse within procedures that guide and channel this activity to perform forms of cognition.\\n\\nFigure 10. LLM-Based Multi-Agents. Source: Guo, Taicheng et al., 2024.\\n\\nThe diagram above illustrates the current state of the art in LLM-based multi-agent systems, where we observe a high degree of fragmentation across many competing approaches. This area of development is moving rapidly, but there is no common platform or any commonly accepted standards for agentic applications, inter-agent communication, or agents.\\n\\n21\\n\\nBelow we illustrate what a complex multi-agent application might look like, at a high-level, for an example agentic “IP monetization” application:\\n\\nFigure 11. Agent Collaboration Platform\\n\\nIn the above example, several teams of agents collaborate with individual humans and teams of hums to conduct an IP development process. This is a highly advanced scenario. Most agentic LLM applications involve a single human delegating to multiple agents (single human, multiple agents: “SHMA”), for simple and relatively low-level task-automation scenarios like Web research. However in our own work (not yet released publicly, at time of this writing), we have implemented and tested a new agentic platform that is tailored for more advanced multi-human-multi-agent (multiple human, multiple agents: “MHMA”) applications like this example.\\n\\nBeneath this application are layers of modules, for example, the IP Development Agents team in the above diagram is a module that might function like the diagram below:\\n\\n22\\n\\nFigure 12. IP Development Team Module.\\n\\nAnd below this level, each agent is a module - for example, the IP Developer Agent:\\n\\nFigure 13. IP Developer Agent\\n\\nAnd below this layer there are skills or sub-capabilities of each agent, for example:\\n\\nFigure 14. Innovation Component\\n\\nBut while agentic architectures are highly modular and well-suited to leveraging the capabilities of Large Language Models (LLMs), not all agentic applications rise to the level of full Cognitive AI.\\n\\n23\\n\\nOnly agentic applications, where agents are implemented outside of LLM transcripts, and where meta-cognition is utilized across all major cognitive functions, qualify as Cognitive AI.\\n\\nWhile LLMs themselves can mimic the behavior of individual agents and communities of agents, there is a difference between linguistically simulated agents that exist only as language within the transcript of an LLM chat, and programmatic intelligent agents that operate as executable code on a multi-agent platform above and outside of a chat transcript. The latter not only has more degrees of freedom in how they think and interact, but they can also make use of external code.\\n\\nIn the paradigm of Cognitive AI, agents exist outside of LLMs, but use LLMs for their linguistic and basic intelligence functions. In this way they utilize, but are not bound by, the limitations of LLMs. They are free, for example, to use multiple models, including other forms of machine learning and reasoning when needed.\\n\\nThe coming technical breakthroughs that enable Cognitive AI will have profound implications for the deployment of AI across various sectors. By enabling systems to understand and adapt their strategies, Cognitive AI will open new possibilities for innovation and problem-solving.\\n\\nThese adaptive capabilities ensure that Cognitive AI applications will continue to evolve and will remain relevant and effective in the face of changing data landscapes and problem sets, setting a new standard for what AI can achieve.\\n\\nRelationship Management, Inter-Agent Messaging and Dialogs\\n\\nCognitive AI thinks and reasons on at least two layers at once:\\n\\nThe Conversational Level simulates cognition linguistically against a trained probabilistic model.\\n\\nThe execution of explicit reasoning projects and plans by agents on the Cognitive Level constitutes programmable workflows that can model any informal or formal cognitive process.\\n\\nBy combining these two modalities a more powerful and flexible level of cognitive processing is possible than can be achieved by either on its own.\\n\\nWhere these two modalities intersect is in the process of dialogs. In Cognitive AI, dialogs are turn-based natural language inter-agent messaging conversations which take place between two or more agents, in which at least one participant is a software agent. A necessary precondition for inter-agent messaging and dialogs is a means for agents to form and manage inter-agent relationships.\\n\\n24\\n\\nThere are two kinds of dialogs: external and internal dialogs. External dialogs take place between an agent and other agents that are external to its own private cognitive workspace. For example, a chat between a CTO Agent and a CFO Agent. Internal dialogs take place inside the scope of an agent’s private cognitive workspace.\\n\\nAn internal dialog is a conversational process between two or more agents which takes place within a single agent’s mindsteam. Within the cognitive workspace of an agent, sub-agents can be instantiated as needed, to represent facets of the subconscious processing of that agent. This effectively enables an agent to \"talk to itself” and “cognitate internally” in order to self-reflect before generating a response or behavior. This form of internal discourse is critical for fostering deeper critical thinking, introspection, and analysis, within intelligent agents and across Cognitive AI architectures.\\n\\nThrough internal dialogs, Cognitive AI agents can meticulously develop, assess, and refine strategies and plans by applying dialectical processes between “subconscious agents” within its own virtual mind. This reflective and dialectical process enables a system to critique its own thinking, identify potential improvements, and iterate on its strategies before it puts them into practice as a response to some stimulus. Responses of this nature are far beyond the instinctive responses of LLMs. Internal dialogs, while not always required, can be used to ensure that responses are not only well-considered but also optimized for effectiveness and efficiency, embodying a level of strategic foresight comparable to human intelligence.\\n\\nThe process of internal dialogs for reasoning and adaptation in Cognitive AI is cyclical, constituting a continuous loop of self-improvement. This loop enables the system to evolve its problem-solving methodologies over time, ensuring that its approaches are not only effective but also increasingly sophisticated. By engaging in this ongoing process of introspection and self-modification, Cognitive AI systems can achieve a dynamic state of growth and learning, mirroring the evolutionary nature of human cognitive development.\\n\\nThe ability of Cognitive AI to evolve new and improved problem-solving strategies through introspective self-dialog and self-optimization, is critical for applications that require more than mere computational power. This capacity for sophisticated understanding and strategic planning, akin to human cognitive abilities, allows Cognitive AI to tackle complex tasks with a depth and efficiency that surpass the capabilities of Conversational AI.\\n\\nAnother key function of dialogs is group conversations. In Cognitive AI, group conversations are structured by plans that serve as their agendas, and they are facilitated by at least one software agent, for a group of two or more other agents. Cognitive AI agents are able to generate and leverage best-practices group processes for a variety of collective cognition tasks such as brainstorming, content development, research and analysis, strategic planning, design and development, innovation, feedback and reporting, and decision-making.\\n\\n25\\n\\nOne of the more powerful applications of group conversations is the use of groups of agents with diverse specializations and skills to model collaborative multi-disciplinary teams and their collective cognition. In Cognitive AI, the practice of applying multi-disciplinary teams of agents is a routinely used mechanism during execution of projects and plans.\\n\\nFor example, during a particular step of a plan in a market research project, a team of agents can be assembled to discuss a market segment, where each agent brings unique knowledge, heuristics, and skills to the table. The team can then engage in a structured conversation, where each agent represents its unique perspective, to arrive at a richer understanding together.\\n\\nPlanning and Project Management\\n\\nLLMs have been shown to have limited planning capabilities and in recent benchmarks they still have much room for improvement. (Valmeekam, K. et al., 2023). LLMs also fail at over-the-horizon reasoning, where there are long complex chains of potential solutions, only some of which are optimal or even solutions at all.\\n\\nKambhampati, S. et al. have argued persuasively that “LLM’s can’t plan” because, for example, LLMs can neither guarantee the generation of correct plans, nor the verification of correct plans. Planning with LLMs is not equivalent to exhaustively searching for valid optimal paths in a solution space, but instead is more like generating plans by borrowing from previously seen plans – an approach which is not systematic.\\n\\nThe ability to strategize and plan thinking processes underpins a wide range of capabilities critical to Cognitive AI, including reasoning, research, analytics, decision-making, project management, and task orchestration. By embedding formal planning capabilities into the fabric of Cognitive AI\\'s operations, these systems can tackle sophisticated challenges that require not only raw computational power but also nuanced, strategic thinking.\\n\\nAt the core of Cognitive AI\\'s planning function is the ability to generate plans which are formal conditional workflows for agents to participate in. These workflows guide the collective cognition and behavior of intelligent agents, and optionally human collaborators as well, by channeling their interactions and reasoning through structured processes that guide them towards goals. This capability is essential for orchestrating the efforts of multiple entities, ensuring that each contributes effectively to the task at hand, based on their unique strengths and capabilities.\\n\\nMore specifically the plans generated by Cognitive AI may include formally specified plans, using a formal plan reasoning language such as PDDL. By integrating PDDL, or languages like it, into Cognitive AI systems, it becomes possible to conduct formal search, analysis, validation and optimization of plans, against formally specified problem domains, using first order predicate logic.\\n\\n26\\n\\nBy combining this level of formal reasoning about plans with the informal language understanding and generation of the LLMs, a more sophisticated form of plan generation and refinement becomes possible, where the LLM generates potential plans with natural language, which are then transformed into formal logic, and which are next formally evaluated and improved, in order to yield better plans, with are finally translated back into natural language.\\n\\nThe plans developed by Cognitive AI systems are not rigid scripts but adaptive strategies that respond to changing conditions and new information. By programmatically channeling the collective thinking processes of teams of agents and humans, Cognitive AI can navigate complex problem spaces with agility and precision. This approach allows for the optimization of cognitive resources, ensuring that tasks are approached in the most efficient and effective manner possible.\\n\\nSupplementing its planning capabilities, Cognitive AI incorporates full project management functionalities. Project management allows a system to not only devise and initiate plans, but also to monitor their progress, adjust execution at runtime, and manage resources effectively. Through comprehensive project management, Cognitive AI can engage in complex, multi-step, and long-term or ongoing knowledge work.\\n\\nThis integration of planning and project management enables Cognitive AI to orchestrate complex endeavors, from initial strategy formulation to the successful completion of objectives. It represents a holistic approach to tackling knowledge work, where the system\\'s cognitive functions are leveraged to plan, manage, and execute projects with a level of sophistication and adaptability previously unattainable.\\n\\nThe planning and project management capabilities of Cognitive AI mark a significant advancement in artificial intelligence. By enabling dynamic, real-time strategizing, planning and execution, supplemented with comprehensive project management tools, Cognitive AI systems can effectively orchestrate complex collaborative knowledge work and knowledge-based business processes. This not only enhances the efficiency and effectiveness of cognitive work but also expands the possibilities for what AI can achieve, setting a new standard for intelligence in technology.\\n\\nCognitive AI\\'s ability to integrate meta-cognition across planning and project management also enables a higher level of control and sophistication in reasoning and adaptation that is essential for complex problem-solving and knowledge work. Complex reasoning in Cognitive AI is the result of applying systems of agents to solve abstract problems, using projects and plans to do so. In other words, in Cognitive AI, complex reasoning is a cognitive process that uses projects and planning to control and manage multi-agent reasoning and behavior.\\n\\nIn Cognitive AI, planning and project management are central cognitive functions. These advanced AI capabilities are not only about creating, executing, and adapting strategies and\\n\\n27\\n\\nplans in a static sense, but dynamically doing so in real time, as agents engage in cognitive processes. This dynamic planning capability is fundamental to the ability of agents to navigate and manage complex tasks, embodying a leap beyond traditional AI\\'s capabilities.\\n\\nNeuro-Symbolic Reasoning\\n\\nIt has been argued above that LLM’s are not capable of complex reasoning, however even naive logical reasoning within LLMs is prone to failures. For example, they are prone to the “reversal curse” (Berglund, L., et al., 2023) where if told that “A is B”, they may fail to infer that “B is A”, and in addition they often fail on even simple set operations, such as three set logical unions (Yang, J. et al., 2023).\\n\\nFor larger, more complex reasoning processes that are longer than the context window or token limit, LLMs cannot natively mimic complex reasoning because they cannot maintain context or state beyond the limits of their token limits. Furthermore, because of their proactive nature, LLMs cannot reliably implement complex reasoning in a deterministic manner; they are prone to hallucinations and unpredictable outputs and they may or may not always follow plans they are given.\\n\\nCognitive AI addresses these challenges by offering a neuro-symbolic solution that combines deterministic and programmatic control of reasoning and planning, which are executed outside the token window of an LLM, with the non-deterministic, probabilistic conversations that take place inside the token window.\\n\\nFurthermore Cognitive AI can generate, validate, and optimize these external reasoning flows using formal symbolic processing and computation. In other words, Cognitive AI systems combine the “neuro” capabilities of LLMs with the “symbolic” capabilities of pre-LLM generations of AI, such as formal symbolic logic process, solvers, formal planners, formal reasoning engines and non-axiomatic reasoning methods (cf. Latapie et al., 2023).\\n\\nThis hybrid approach enables Cognitive AI systems to navigate complex reasoning tasks with greater precision and reliability. By integrating both deterministic and non-deterministic methodologies, Cognitive AI can leverage the strengths of each, resulting in a reasoning capability that is more powerful and versatile than either approach alone.\\n\\nUnlike LLMs, which rely on language simulation to approximate thinking, Cognitive AI systems employ programmatically structured, organized, and managed thought processes. This programmatic control extends to the execution of projects and plans, allowing Cognitive AI to engage in complex autonomous reasoning. This structured approach to thinking and reasoning enables Cognitive AI systems to process and analyze information in a manner that aligns more closely with the requirements of sophisticated cognitive tasks.\\n\\n28\\n\\nCognitive AI further enhances its reasoning capabilities by channeling conversational AI through agents that employ projects and plans to control their behaviors. This enables the collaborative and complex autonomous reasoning necessary for high-level knowledge work. By combining deterministic programmatic control with the flexibility and adaptability of non-deterministic conversational AI, Cognitive AI can tackle complex problems with both precision and creativity.\\n\\nAnother important aspect of reasoning in Cognitive AI is the capacity to construct and reason about formally defined systems of rules. These systems of logical rules can be processed with first-order predicate logic in symbolic processing modules, such as theorem provers, graph search algorithms, and reasoning engines.\\n\\nAgents in Cognitive AI systems can execute, manage and improve, goal-directed projects and actions, under formal systems of rules. This enables such systems to intelligently, discover, reason about, and improve their own solution paths as they work, and adapt to change.\\n\\nThe reasoning capabilities of Cognitive AI represent a significant advancement over traditional conversational AI systems. Through the integration of reflection, planning, and programmatic control, Cognitive AI can navigate complex cognitive tasks with a level of sophistication and effectiveness unmatched by LLMs alone.\\n\\nThis approach to reasoning not only enhances the system\\'s ability to perform complex problem-solving but also positions Cognitive AI as a critical tool for advancing knowledge work and other applications requiring nuanced, intelligent analysis and decision-making.\\n\\nCognitive AI\\'s unique combination of deterministic and non-deterministic reasoning processes establishes a new benchmark for what artificial intelligence systems can achieve in terms of autonomous reasoning and cognitive collaboration.\\n\\nMemory Retrieval and Context Management\\n\\nA defining feature of Cognitive AI, distinguishing it from Conversational AI, is its advanced capability for contextual understanding and memory, enriched by the integration of concepts akin to human working memory and long-term memory. This sophisticated memory system enables Cognitive AI to handle information dynamically and strategically, offering a substantial edge in complex problem-solving and nuanced decision-making.\\n\\nTraditional Conversational AI processes each interaction in isolation, limiting its ability to recognize the continuity in ongoing dialogues or projects. Cognitive AI, however, boasts a contextual memory that spans interactions, acting as a dynamic repository of context, insights, and understanding. This system allows it to build upon previous conversations, adapting to context changes over time, and making more informed decisions and responses.\\n\\n29\\n\\nCentral to how Cognitive AI handles memory is the process of context management, whereby it is able to provide relevant contextual information within finite token windows of LLMs. Context management is encapsulated in a working memory buffer that temporarily holds and manages information that is immediately relevant to the task at hand, akin to human working memory. This feature is crucial for maintaining the context of ongoing interactions, allowing for real-time analysis, reasoning, and the dynamic adjustment of strategies based on immediate feedback. Through working memory, Cognitive AI can juggle multiple pieces of information, drawing on recent data for predictions, problem-solving, or strategy adjustments.\\n\\nLong-term memory in Cognitive AI mirrors the human capacity to store and retrieve information over extended periods. It enables the AI to accumulate knowledge and experiences, applying historical data to inform future decisions. This capability allows Cognitive AI to recognize patterns, learn from past interactions, and adapt its operational strategies, providing a depth of understanding and strategic foresight that traditional Conversational AI cannot achieve.\\n\\nThe dual-approach to memory—combining working memory and long-term memory—affords Cognitive AI a clear advantage over Conversational AI. While Conversational AI might access databases or follow scripted responses, it lacks the dynamic, context-aware integration of information that Cognitive AI offers. This system not only ensures more accurate, relevant responses in the moment but also enables deeper strategic thinking and learning over time.\\n\\nCognitive AI\\'s memory system facilitates anticipation of needs, adaptation to contextual changes, and the delivery of solutions informed by both immediate and historical perspectives. This nuanced approach, mirroring human cognitive processes, allows Cognitive AI to navigate complex interactions and problem spaces with unprecedented depth of understanding and adaptability.\\n\\nThe integration of contextual understanding and memory, incorporating working memory and long-term memory, into Cognitive AI systems marks a significant evolution in artificial intelligence. This advancement allows Cognitive AI to operate with sophistication and adaptability, navigating complex challenges with strategic insight and efficiency. By leveraging both immediate and accumulated knowledge, Cognitive AI sets a new standard for AI-driven applications, offering sophisticated, adaptable, and effective solutions that far surpass the capabilities of traditional Conversational AI.\\n\\nKnowledge Discovery and Knowledge Management\\n\\nA foundational element distinguishing Cognitive AI from conventional Conversational AI is its approach to knowledge representation and knowledge management (KM). This functional area transcends the capabilities of Large Language Models (LLMs) in handling knowledge, by explicitly creating, managing, and enhancing structured knowledge representations such as knowledge bases, knowledge objects, knowledge catalogs, knowledge graphs, taxonomies and\\n\\n30\\n\\nontologies. These knowledge representation components are pivotal for the sophisticated operation of Cognitive AI, enabling it to process, understand, and interact with information in a more nuanced and contextually relevant manner.\\n\\nUnlike LLMs, which rely on pattern recognition and data-driven learning without an explicit structure for organizing knowledge, Cognitive AI systems are meticulously designed to construct and utilize knowledge representations, which are data structures not merely streams of natural language. The ability to process knowledge representations mirrors human cognitive processes, facilitating the AI\\'s ability to draw connections, identify patterns, and efficiently access relevant knowledge.\\n\\nCognitive AI incorporates LLMs not as standalone entities but as integral tools that enrich the Knowledge Management process. LLMs are employed to understand, summarize, expand, and filter knowledge within Cognitive AI\\'s knowledge bases. This symbiotic relationship between LLMs and Cognitive AI\\'s structured Knowledge Management functions allows for the generation of rich metadata, the improvement of searchability, and the discovery and creation of new knowledge representations, which are processes that LLMs alone cannot replicate. By utilizing LLMs in this capacity, Cognitive AI systems can maintain a dynamic and ever-evolving knowledge base.\\n\\nAt the core of Cognitive AI\\'s Knowledge Management is the function of knowledge discovery and improvement, a process that involves the active location, extraction and discovery of new insights based on accumulated information. As information (including raw data and information, and knowledge structures themselves) is added, additional knowledge can be extracted or inferred, including new metadata, new knowledge representations, and new relationships between existing representations. This function signifies Cognitive AI\\'s ability to not only organize existing knowledge but also to continuously refine and expand its understanding through the integration of newly sourced data. The strategic use of LLMs in this context enhances Cognitive AI\\'s capability for complex problem-solving and informed decision-making.\\n\\nThe capacity for research and information exploration marks another critical aspect of Knowledge Management in Cognitive AI. Beyond mere keyword matching, Cognitive AI systems deploy advanced algorithms to delve into queries against multimodal datasets, using their understanding of contexts, goals and intent, to retrieve contextually relevant information. This capability is crucial for tasks requiring domain-specific expertise or the navigation of vast data pools to uncover precise insights or solutions.\\n\\nKnowledge Management within Cognitive AI architectures is a testament to the sophisticated nature of these systems, enabling them to effectively manage and leverage complex datasets and information structures far beyond the capabilities of LLMs. The integration of LLMs enhances Cognitive AI\\'s ability to organize, access, and evolve its knowledge base, ensuring continuous improvement and relevance.\\n\\n31\\n\\nThis comprehensive approach to Knowledge Management not only underscores Cognitive AI\\'s transformative impact on artificial intelligence but also its indispensable role in facilitating complex decision-making, problem-solving, and innovation in various domains. Through its structured yet dynamic Knowledge Management system, Cognitive AI represents a significant leap forward in the pursuit of more intelligent, adaptable, and effective AI solutions.\\n\\nTool-Utilization\\n\\nCognitive AI architectures are designed to support and integrate tool-utilization, which is the capacity for an intelligent system to use, and even create, tools . The cognitive approach to tool-utilization, also called tool-use, represents a significant point of differentiation between traditional conversational AI and the more advanced Cognitive AI systems. While conversational AI can simulate or script the control of tools, it lacks the inherent capacity to truly understand or directly interact with these tools. Cognitive AI, however, embodies tool-use as a core capability, reflecting a deeper layer of intelligence and functionality.\\n\\nConversational AI\\'s approach to tool-use is essentially indirect. It can generate scripts or commands that control tools, such as computer programs, but any actual tool interaction must be executed externally. The AI itself remains disconnected from the tangible effects of these tools; it cannot perceive the tool or the results of its use directly. This limitation confines conversational AI to a role of an intermediary rather than an active and aware participant in tool-use.\\n\\nIn contrast, Cognitive AI is inherently designed for tool interaction. This design extends from the ability to reflexively use its own internal cognitive agents, processes, projects, and plans, treating them as tools within its operational framework. Furthermore, Cognitive AI\\'s capacity for tool-use expands externally, enabling it to utilize a wide array of tools, from Large Language Models (LLMs) to various functions and APIs, effectively extending its capabilities and enhancing its operational efficiency.\\n\\nIt’s particularly interesting to point out that Cognitive AI can intelligently use external data analytics and machine learning tools to analyze data, make predictions, and generate insights. This even extends to the ability for Cognitive AI to develop or fine-tune LLM models if necessary.\\n\\nCognitive AI can, if it needs software it cannot source from elsewhere, is capable of developing its own software tools. It can design, build and execute programs, create datasets, and even operate software-as-a-Service (SaaS) to meet the needs of its projects and tasks. AI code-generation and coding co-pilots already offer dramatic productivity gains for software engineers. However by using a cognitive layer above such tools, it becomes possible to go beyond them – Cognitive AI will be able to autonomously design, build, test, improve, operate and maintain SaaS applications.\\n\\n32\\n\\nThe tool-use in Cognitive AI involves two critical aspects: the ability to interact with and control the tool and the ability to observe both the tool and the environment to make real-time adjustments. This dual capability allows Cognitive AI systems to engage in a form of meta-tool-use, where they not only utilize tools but also understand and optimize their use based on ongoing feedback and environmental conditions.\\n\\nUnlike conversational AI, which operates on predefined instructions without the capacity to observe or adjust its actions, Cognitive AI systems possess the autonomy to manage tools actively. They can assess the effectiveness of a tool in real time, adapt their strategies to optimize its use, and even switch between tools as necessary to achieve their objectives. This level of operational adaptability and awareness enables Cognitive AI to perform complex tasks with a degree of precision and efficiency that conversational AI cannot match.\\n\\nCognitive AI\\'s ability to utilize external tools, such as LLMs and APIs, signifies a substantial expansion of its operational domain. By integrating these external resources, Cognitive AI can enhance its problem-solving capabilities, access a broader range of information and functionalities, and execute tasks that are beyond the reach of its internal resources alone. This external tool-use not only amplifies the system\\'s capabilities but also demonstrates the system\\'s ability to operate within and contribute to a larger ecosystem of technologies and services.\\n\\nTool-use is not just an additional feature of Cognitive AI but a fundamental aspect of its design and functionality. It exemplifies the system\\'s advanced level of intelligence, showcasing its ability to interact with, control, and adapt the use of both internal and external tools in the pursuit of its objectives.\\n\\nTool utilization distinguishes Cognitive AI from conversational AI, highlighting its potential to revolutionize how artificial intelligence systems engage with the world and accomplish tasks. Through integrated tool-use, Cognitive AI sets a new standard for autonomy, adaptability, and functionality in the AI domain, promising to redefine the boundaries of what artificial intelligence can achieve.\\n\\nMathematics and Computation\\n\\nA special area of tool utilization in Cognitive AI systems is the ability to use mathematical software and computing infrastructure as tools.\\n\\nCognitive AI systems must be capable of performing mathematical and computing operations, including writing software and then using that software to execute arbitrarily complex computations. They can also access and utilize any needed external IT infrastructure and data for which they have credentials. These capabilities do not come from the Conversational Layer, but instead are executed using dedicated code or applications for these purposes that either is built-into, or is called from, the Cognitive Layer.\\n\\n33\\n\\nBy virtue of this, Cognitive AI systems are able to do arbitrary computations on an as-needed basis, and they can either use existing external tools and services for this, or they can develop software for tools they need.\\n\\nUsing mathematical and computational tools, Cognitive AI systems are capable of harnessing machine learning and data analytics, predictive analytics, financial analysis and modeling, formal reasoning, and mathematical and scientific computing.\\n\\nMulti-Agent Collaboration\\n\\nCognitive AI is inherently collaborative. The ability to interact, communicate and collaborate to conduct knowledge work with other individuals and groups is a key defining factor of higher-order intelligence on the evolutionary ladder.\\n\\nDrawing inspiration from Marvin Minsky’s “Society of Mind” approach, Cognitive AI\\'s groundbreaking approach to artificial intelligence emphasizes the critical role of social collaboration in cognition, not just as a feature set but as a core mechanism driving many cognitive processes.\\n\\nCognitive AI systems enable collaboration between humans and software agents, as well as between software agents and other software agents, in natural language. This is a significant advance from previous pre-LLM agent paradigms where communication between agents was largely programmatic and incomprehensible to non-programmer humans. In Cognitive AI, collaboration between humans and agents requires similar social infrastructure to collaboration between humans – there must be a way for them to message each other and communicate in dialogs, and there must be a way to organize their interactions into topics, projects and plans. The Project Manager function of a Cognitive AI architecture is the intersection where collaboration is organized, managed and executed.\\n\\nCognitive AI extends beyond human-AI interactions, encompassing the dynamics between agents, among individuals, and across groups that include both agents and people. By harnessing social interaction and collaboration, Cognitive AI taps into the power of collective intelligence, which is inherently social and collaborative at its core.\\n\\nIn Cognitive AI, both AI and human agents interact with one another to share knowledge, negotiate tasks, and collaboratively solve problems. These interactions are not merely transactional but can be built upon complex social and reporting mechanisms that allow agents to understand and predict each other\\'s behaviors, seek appropriate approvals, work towards common goals, and optimize collective outcomes. This ability to engage in sophisticated social negotiations, reporting structures and collaborations enhances the agents\\' effectiveness and contributes to the development of a more nuanced and dynamic form of collective intelligence.\\n\\n34\\n\\nCognitive AI also plays a pivotal role in facilitating and enriching human-to-human interaction. By offering insights derived from its processing capabilities and its understanding of social dynamics, Cognitive AI can facilitate group processes to help human teams communicate more effectively, brainstorm or innovate more effectively, overcome misunderstandings, and make decisions more efficiently. It acts as a mediator and enhancer of human collaboration, leveraging its understanding of group process and group dynamics to foster a more cohesive and productive working environment.\\n\\nThe interaction between Cognitive AI agents and humans is a hallmark of its social intelligence. Cognitive AI is designed to understand and adapt to human social cues, enabling it to participate in conversations and collaborative efforts as a proactive and responsive partner. This seamless integration of AI into human social contexts allows for a symbiotic relationship where both agents and humans learn from and complement each other\\'s strengths, leading to enhanced creative problem-solving and innovation.\\n\\nPerhaps most significantly, Cognitive AI facilitates and thrives in mixed groups comprising both AI agents and humans. In these settings, Cognitive AI leverages its social intelligence to navigate the complexities of group dynamics, ensuring that contributions from both AI agents and humans are valued and integrated. This collaborative environment maximizes the benefits of collective intelligence, where diverse perspectives and capabilities are brought together to tackle challenges more effectively than any individual or homogeneous group could.\\n\\nAt its core, Cognitive AI is built around the concept of collective intelligence, recognizing that the most profound insights and solutions often emerge from collaborative efforts. This collective intelligence is inherently social and collaborative, drawing on the diverse experiences and knowledge bases of its participants. By facilitating and actively participating in this collaborative process, Cognitive AI not only enhances its own cognitive capabilities but also contributes to the collective wisdom of the group.\\n\\nThe integration of social interaction into Cognitive AI represents a transformative advancement in AI technology. By embracing the complexities of social dynamics across various interaction modalities—agent-to-agent, human-to-human, agent-to-human, and in mixed groups—Cognitive AI elevates the potential for collective intelligence.\\n\\nThis approach acknowledges that the future of intelligence, both artificial and human, lies not just in individual brilliance but in our capacity to collaborate, share, and innovate together. Cognitive AI, with its emphasis on social interaction and collective intelligence, is leading the way toward a future where AI is an integral and enhancing component of the social fabric, propelling us towards more collaborative, intelligent, and creative outcomes.\\n\\n35\\n\\nMeta-Cognition\\n\\nMeta-cognition encompasses a particular set of advanced functions within an intelligent system, whereby the system is able to sense and react to itself through a process of self-reflective introspective reasoning.\\n\\nIn self-reflective reasoning, the thinking and behavior (including both the internal state and the output) of a meta-cognitive system is sensed by that system, and taken as input for further intelligent processing by that same system about itself. In other worlds, the system thinks about itself and what it is doing in order to improve its composition or behavior.\\n\\nImplementing meta-cognition across agentic applications is technically difficult and is not a fully-implemented construct in existing agent development frameworks. While such platforms can be used for simple agent introspection and execution planning, they don’t make a higher-order meta-cognitive architecture concrete. To solidify this at a platform level requires new IP, new tools, and new application paradigms. This is both the challenge and the opportunity of Cognitive AI today.\\n\\nMeta-cognition has several fundamental capabilities:\\n\\n\\n\\n\\n\\nKnowledge processing - The ability of an intelligent system to detect, transform and generate formal data structures and procedures to represent and reason about knowledge. Introspection - The ability of an intelligent system to detect, transform and conduct knowledge processing on representations of its own composition, state, context, and behavior.\\n\\nMeta-reasoning - The ability of an intelligent system to use introspection and knowledge processing to represent, transform and generate knowledge about knowledge, and reasoning about reasoning. Reflection - The ability of an intelligent system to apply meta-reasoning during the process of introspection in order to conduct reasoning and/or meta-reasoning about its own composition, state, context and behavior. Learning -The ability of an intelligent system to improve or generate future potential knowledge and/or responses, based on analyzing the utility of previous patterns of knowledge and/or responses for specific goals. Self-optimization - The ability of an intelligent system to employ Learning and Reflection to transform its own composition, state, context or behavior in order to improve fitness for specific goals and criteria.\\n\\n\\n\\n\\n\\n\\n\\nThe core innovation within Cognitive AI lies in a dual-layer architecture which enables meta-cognition to take place above the intelligence of LLMs. This architecture enables Cognitive AI to not only analyze and respond to data but also to introspect, reflect and dynamically optimize its strategies based on ongoing experiences. Such self-reflective intelligence allows\\n\\n36\\n\\nCognitive AI to evaluate and enhance its decision-making processes in real-time, leading to improved efficiency and outcomes.\\n\\nMeta-cognition, or intelligence about intelligence, equips Cognitive AI with the ability to perform abstract reasoning, a hallmark of human cognition. Whereas LLMs may simulate abstract reasoning in straightforward scenarios, they falter as task complexity increases.\\n\\nCognitive AI\\'s meta-cognition architecture facilitates a level of introspection and adaptive reasoning and learning that surpasses what is possible with first-order intelligent systems, enabling it to navigate and solve intricate, multi-faceted highly complex problems.\\n\\nThe transition towards Cognitive AI signifies a fundamental transformation in the field of artificial intelligence, moving from a reliance on basic pattern recognition to a more sophisticated, introspective, and adaptable intelligence model. This evolution not only redefines our conceptual understanding of AI but also marks a significant milestone in the technology\\'s development, paving the way for future innovations that more closely mimic human cognitive processes.\\n\\nSelf-Improvement\\n\\nCognitive AI also distinguishes itself from Conversational AI through self-improvement. This distinction is not merely theoretical but operational, impacting how these systems approach and solve problems.\\n\\nAt the heart of Cognitive AI\\'s operational framework lies the principle of continuous loops of self-improvement (“recursive self-improvement”, cf. Steunebrink et al., 2016; Nivel et al. 2013) achieved through an iterative loop of goal-directed learning, cognition, and adaptation. This iterative process allows Cognitive AI systems to recursively analyze their outputs, and use this analysis for self-reflection and iterative improvement of their solutions, strategies, plans and responses.\\n\\nUnlike Conversational AI, which primarily generates responses based on the immediate statistical likelihoods derived from training data, Cognitive AI engages in a dynamic process of self-evaluation and enhancement, enabling complex problem-solving that incorporates meta-level strategic thinking and creativity – and it often does this before generating a response. This capacity for recursive self-improvement allows Cognitive AI to adapt to new challenges and changing environments, continuously enhancing its capabilities beyond its initial programming.\\n\\nOne of the most important differentiating cognitive features of higher-intelligent lifeforms on Earth is the ability to form goals and execute complex multi-step plans to achieve them. Humans and a few other species are capable of this level of conceptual thinking. To form,\\n\\n37\\n\\nmaintain and execute plans requires a high level of abstract reasoning. Cognitive AI is able to model arbitrary types of plans with conditional logic workflows that both humans and agents can collaborate with.\\n\\nIn more concrete terms, recursive self-improvement is implemented in Cognitive AI architectures as a goal-directed process across one or more cognitive functions, where at least one must be a planning function.\\n\\nA Planner makes plans for accomplishing goals. Plans can be thought of as strategies for goal-directed thinking and behavior. Plans are scripts that are created to guide actions for specific objectives and criteria. But plans can also be used to structure and guide the “internal actions” of an agent or a team as well as their external behaviors. When plans are applied to the internal cognitive processing of AI systems, they guide their reasoning. problem-solving, innovation, decision-making or strategic thinking process.\\n\\nPrevious generations of AI developed plans using algorithms to compose, optimize and utilize graphs and other data structures to represent plans for solving problems, and to manage state during problem solving processes. But these systems lacked the language processing capabilities that LLMs now provide. When LLMs are applied to generating and improving plans they do so in an entirely different manner - instead of algorithms and mathematical operations, they use natural language. The plans they generate are not formal logic processes, they are human-readable text that can be utilized both by agents and by humans alike, for collaborating on complex knowledge work - such as developing a new drug from start through clinical trials. Within these human-readable plans, there can be steps that utilize formal logic, graph search, computation and machine learning to search for particular potential solutions (such as drug candidates), and then construct or reconfigure plans based on findings. But the key point is that while formal computational plans are not imposed on everyone, they are confined to laser-focused tasks that really need to be implemented this way. In other words, in Cognitive AI systems, planning is democratized - it’s a process that both agents and humans can potentially collaborate in, using the same language - natural language.\\n\\nThe additional benefit of natural language plans is that LLMs can read and respond to them with the full power of their models and training. Using this capability, Cognitive AI systems can then apply the Cognitive Layer to formally construct and reason about plans, while the Conversational Layer can be used to read, write, respond to and interpret plans. The combination of these two layers in the context of planning yields rich and robust human-level plans that would be extremely difficult to produce with previous generations of AI, and which also can be iteratively self-improved by the agents and humans that participate in them.\\n\\nPlans function as the cognitive DNA of Cognitive AI systems. They are used both by the intelligent agents and any human participants, to channel how they work through a knowledge work process, where a combination of thinking and actions have to be orchestrated in a logical sequence. The Planner function in such systems designs, develops and implements plans.\\n\\n38\\n\\nBy adding a Recursive Self-Improver loop around a Planner, a Cognitive AI system can introspect on its plans and improve them, both at runtime and in the background. Plans can be recursively self-improved either through internal dialogs among agents, or through improving them when certain events trigger (such as a dependency having a delay or getting blocked).\\n\\nWith the ability to form and improve goal-directed plans in response to internal and external feedback, Cognitive AI systems can then engage in goal-driven, adaptive self-improvement and optimization. These capabilities in turn enable these systems to develop and optimize plans that in turn seek to develop and optimize solutions to a problem.\\n\\nCognitive AI systems can develop and optimize solutions faster than predecessor forms of AI by optimizing on two levels at once – the solution-finding process (the plan) and the solutions for making the solution-finding process better (the recursive self-improvement loop around the Planner).\\n\\nWhen it comes to optimization and innovation, Cognitive AI transcends the limitations inherent in LLMs and their probabilistic models. LLMs, even those enhanced with advanced learning algorithms like Q*, are confined to generating outputs based on pattern recognition within their training datasets. Q* based approaches are designed for generating responses that are likely correct within a closely related set of data but struggle with the broader, more intricate challenges of optimization that require navigating long, nested plans and decision trees.\\n\\nCognitive AI, by contrast, is equipped with the architecture to engage in deep reasoning and strategic planning, necessary for tackling complex optimization and innovation tasks. It can:\\n\\n1. Utilize structured knowledge and reasoning algorithms to navigate complex decision-making processes, identifying the most effective paths through intricate, multi-layered problems.\\n\\n2. Map out comprehensive strategies that consider a wide array of factors, including long-term goals and objectives, budgets, criteria, and potential obstacles, ensuring optimization across diverse problem spaces.\\n\\n3. Generate innovative ideas and solutions, leveraging creative problem-solving capabilities to explore new approaches and push the boundaries of existing knowledge. 4. Learn and adapt from outcomes, integrating new information to continuously refine and\\n\\nenhance problem-solving strategies in response to evolving challenges.\\n\\nRecursive self-improvement can be applied across all cognitive AI processes, not only the planning function. It can be applied at the micro level and the macro level, from improving execution strategies at runtime, to improving knowledge bases, to improving and guiding search strategies and Web crawling, to optimizing large collaborative projects in enterprises in response to changes in their environments over time.\\n\\n39\\n\\nThe ability of Cognitive AI to engage in recursive self-improvement highlights the gap in reasoning capabilities between Cognitive AI and LLMs. While LLMs simulate aspects of intelligence, Cognitive AI embodies a form of intelligence that can reason, plan, innovate, and adapt in ways that mirror human cognitive processes.\\n\\nComparison of Conversational AI to Cognitive AI\\n\\nConversational AI, with its reliance on LLMs for intelligence and simulated cognition, cannot replicate the advanced cognitive capabilities of Cognitive AI architectures, but it’s important to note that Cognitive AI cannot emerge without Conversational AI as an underlying tool.\\n\\nLLMs generate probabilistic responses based on patterns learned from vast amounts of text data. These models:\\n\\n\\n\\n\\n\\nReplicate patterns of reasoning they\\'ve been exposed to in the data, which means they can produce text that often appears logically consistent with the input prompt. Lack genuine understanding or the ability to independently verify the information or apply novel reasoning techniques not present in their training data.\\n\\nAre constrained by their training, meaning they can\\'t conceptualize beyond what they\\'ve been taught or incorporate new information post-training.\\n\\nFor example, when given a math problem, an LLM can solve it if it mirrors problems seen during training, using similar steps and logic. However, it does so by matching patterns probabilistically rather than understanding or applying abstract mathematical principles. It is also worth noting that LLMs cannot natively perform mathematical operations, they can merely mimic them, which often leads to plausible but incorrect answers (“mathematical hallucinations”).\\n\\nCognitive AI, on the other hand, can go beyond pattern matching to actual reasoning and mathematics, powered by meta-cognition and a host of other cognitive functions:\\n\\n\\n\\nConduct reasoning against knowledge by executing programmable reasoning strategies using plans and formal knowledge representations.\\n\\nUse tools via function calls and APIs to integrate external applications and data. Perform mathematical operations by utilizing tools for mathematics, scientific - computing, machine learning, data analytics, predictive modeling, and even formal logic and inferencing.\\n\\nGenerate novel insights by reasoning from first principles or by applying learned\\n\\n\\n\\nconcepts in new ways, independent of specific examples in training data. Incorporate new information post-training, adjusting its reasoning processes based on new data or changing contexts.\\n\\n40\\n\\n\\n\\nEngage in meta-reasoning, reflecting on its reasoning processes, evaluating them, and adjusting reasoning strategies to optimize problem-solving.\\n\\nCognitive AI could, for example, devise a new mathematical proof or strategy for solving a problem by integrating new research findings, by reasoning about a problem or goal, exploring and testing hypothesis, deriving new knowledge, refining its approach as it learns from experience, and abstracting principles from one domain and applying them to another.\\n\\nWhile Conversational AI is purely linguistic and probabilistic, Cognitive AI can apply non-probabilistic formal reasoning and mathematics as well as linguistic and probabilistic approaches, enabling it to deterministically control non-deterministic processes.\\n\\nThis “hybrid reasoning” approach makes Cognitive AI programmable and controllable in a way that prompt-engineering can only approximate, while also enabling it to harness and channel the non-deterministic conversations of LLMs.\\n\\nWhile prompt-engineering methodologies in Conversational AI approaches can simulate and approximate simple formal reasoning and programming, they are inherently non-deterministic, prone to errors, hallucinations, and unpredictable behaviors.\\n\\nThe distinction between Conversational AI, driven by Large Language Models (LLMs), and Cognitive AI becomes starkly evident when examining their respective approaches to handling knowledge. This difference highlights the limitations of LLMs and underscores the advanced capabilities of Cognitive AI, particularly through the integration of a cognitive layer that elevates its operational intelligence and knowledge management.\\n\\nIn Conversational AI, knowledge is not formally represented or stored. Instead, Conversational AI operates on probabilities derived from patterns recognized in vast external datasets during the training phase. The training phase transforms the explicit and implicit knowledge in vast amounts of training data in numerical weights in a complex multidimensional model. There is no way to isolate a particular “piece of knowledge” in these networks, instead knowledge is spread across models in amorphous fields of numbers.\\n\\nThis probabilistic approach means that while LLMs can generate responses that seem knowledgeable, they do not \"know\" anything or retrieve any knowledge in the traditional sense. Their responses are guesses, albeit often highly educated ones, based on the data they have been trained on. This mechanism limits Conversational AI\\'s ability to provide reliable, consistent, and contextually accurate knowledge beyond the scope of its training data.\\n\\nUnlike the probabilistic nature of Conversational AI, Cognitive AI can concretely represent, store and retrieve data structures that encapsulate knowledge objects, world models, knowledge bases, and knowledge structures, alongside reasoning strategies. These explicit knowledge\\n\\n41\\n\\nconstructs allow for knowledge management and knowledge processing at runtime, significantly enhancing the AI\\'s ability to interact with and utilize formal knowledge.\\n\\nCognitive AI\\'s approach to knowledge is multifaceted and dynamic, encompassing:\\n\\nConversational Layer Knowledge: Here, probabilistic knowledge is derived using prompts against the model, supplemented with embeddings to generate responses that are informed by recognized patterns in data.\\n\\nCognitive Layer Knowledge: This layer houses formally specified knowledge objects stored in databases, which describe, reference, and link to contextual knowledge. Knowledge catalogs organize these objects taxonomically, while knowledge graphs connect them through various relational types, enabling a comprehensive and interconnected knowledge management system.\\n\\nKnowledge management empowers Cognitive AI to capture and store knowledge efficiently, navigate and search through complex datasets, generate new insights, and continuously improve knowledge bases. This ongoing process of learning, improvement, and knowledge generation is adaptive, ensuring that Cognitive AI remains relevant and insightful across various contexts and applications.\\n\\nThe contrast between the probabilistic knowledge of Conversational AI and the formal, structured knowledge management of Cognitive AI highlights the advanced capabilities of the latter.\\n\\nCognitive AI\\'s ability to concretely represent and utilize knowledge through its cognitive layer not only addresses the limitations of LLMs but also opens up new avenues for AI\\'s application in complex problem-solving, decision-making, and innovation. By leveraging formal knowledge representation, Cognitive AI sets a new standard for artificial intelligence, bridging the gap between data-driven predictions and genuine understanding.\\n\\nThe ability to tackle complex challenges is a critical measure of an AI system\\'s capabilities, and it is in this arena that the distinction between Cognitive AI and Conversational AI becomes most apparent.\\n\\nCognitive AI\\'s superiority in addressing intricate problems lies in its foundational architecture, which enables deterministic programming and sophisticated problem-solving approaches, transcending the limitations of probabilistic mimicry inherent in Conversational AI.\\n\\nConversational AI\\'s strength in generating human-like text becomes a hindrance in situations that require precise, algorithmic reasoning and multi-step logical operations. As the complexity of the problem escalates, Conversational AI\\'s ability to deliver quality results plateaus and then\\n\\n42\\n\\ndiminishes, constrained by its probabilistic nature and the lack of deterministic programming capabilities.\\n\\nFigure 15. Response Quality vs. Problem Complexity\\n\\nConversational AI plateaus and then quickly becomes less able to deliver quality results as problem complexity increases, while Cognitive AI continues to gain in quality.\\n\\nThe performance disparity between Cognitive AI and Conversational AI becomes increasingly evident as the complexity of challenges grows. While Conversational AI struggles to maintain efficacy in the face of intricate, multi-dimensional tasks, Cognitive AI thrives, leveraging its robust computational framework to dissect and address each component of the problem systematically. This distinction underscores Cognitive AI\\'s ability to not only match but exceed the problem-solving capacities of Conversational AI, offering a more reliable, effective solution for complex challenges.\\n\\nThe distinction between Cognitive AI and Conversational AI, illustrated through their respective approaches to problem complexity, highlights the advanced capabilities of Cognitive AI in deterministic problem-solving.\\n\\nUnlike Conversational AI, which is constrained by its probabilistic, language-dependent framework, Cognitive AI can engage in deep, algorithmic reasoning and execute sophisticated computational strategies. This ability to navigate and solve complex, multi-layered problems with precision and efficiency underscores the potential of Cognitive AI to revolutionize the field of artificial intelligence, pushing the boundaries of what AI systems can achieve in terms of complexity, reliability, and overall performance.\\n\\n43\\n\\nCognitive AI\\'s approach to problem-solving represents a significant departure from the capabilities of traditional conversational AI, such as LLMs. Where conversational AI is constrained by its reliance on probabilistic intelligence and the limitations of processing language-based inputs, Cognitive AI introduces a multi-faceted, algorithmically driven problem-solving framework. This framework is particularly adept at tackling complex, nested problems typical of knowledge work, which require sophisticated reasoning and the ability to adapt strategies in response to evolving information and multiple layers of dependencies.\\n\\nLLMs operate on a first-order level, employing probabilistic intelligence against streams of tokens to simulate understanding and generate responses. This method, while effective for generating language-based outputs, falls short in complex problem-solving scenarios that necessitate executable control flow, mathematical operations, and strategic reasoning. LLMs are inherently unable to engage in sophisticated problem-solving processes such as recursive operations, tree searches, curve fitting, or optimization, limiting their effectiveness to what can be simulated through language alone.\\n\\nCognitive AI transcends these limitations through its advanced architectural design, which incorporates a cognitive layer equipped with capabilities for formal knowledge representation, management, discovery, and reasoning against knowledge bases. This layer enables Cognitive AI to engage in multi-layered reasoning, simultaneously maintaining, adjusting, and managing reasoning states and strategies across various levels of thought. This is particularly crucial for solving nested problems, where a primary issue encompasses multiple sub-problems, each with its own set of challenges.\\n\\nCognitive AI systems are designed with the flexibility to implement advanced computational strategies, such as recursion, parallel computing, and asynchronous computing. This capability allows them to efficiently address multi-layered, multi-step problems by deterministically running through any number of nested operations.\\n\\nFor instance, Cognitive AI can be programmed to execute complex algorithms that involve recursive functions, enabling it to solve problems that unfold across several levels of complexity. This deterministic approach ensures that Cognitive AI can maintain a high level of accuracy and reliability, even as the complexity of tasks increases.\\n\\nConversational AI, on the other hand, operates primarily on probabilistic outputs generated from patterns recognized within its training data. Its reliance on natural language processing as the basis for all operations introduces inherent limitations, particularly when faced with complex problem-solving scenarios.\\n\\nBy leveraging sophisticated algorithms, Cognitive AI can execute complex problem-solving tasks that are beyond the reach of conversational AI. This includes engaging in mathematical and logical operations, executing recursive functions, and conducting exhaustive searches—all integral to addressing the multifaceted nature of real-world problems. Moreover, Cognitive AI\\'s\\n\\n44\\n\\nability to dynamically adapt its strategies in real-time allows it to respond effectively to new challenges, dependencies, and changing conditions within a problem space.\\n\\nAt the heart of Cognitive AI\\'s problem-solving capability is its integrated knowledge management system, which harnesses knowledge catalogs, graphs, and metadata taxonomies. This system not only organizes information but also facilitates the discovery of new knowledge, which Cognitive AI can then apply to its reasoning processes. The ability to access and utilize a comprehensive knowledge base enhances Cognitive AI\\'s problem-solving capacity, enabling it to draw on a wide range of information sources to inform its strategies and solutions.\\n\\nProblem-solving in Cognitive AI architectures represents a paradigm shift in artificial intelligence\\'s approach to complex challenges. Unlike conversational AI, which is limited to language-based simulations, Cognitive AI combines structured knowledge management with advanced algorithmic processing to tackle nested problems with unparalleled depth and efficiency. Its capacity for dynamic strategy adaptation and sophisticated reasoning ensures that Cognitive AI can navigate the complexities of knowledge work, making it an invaluable asset for fields requiring nuanced analysis, strategic planning, and the integration of diverse information sources.\\n\\nThrough its comprehensive problem-solving framework, Cognitive AI not only addresses the limitations of traditional AI models but also sets a new standard for intelligence and adaptability in tackling the world\\'s most complex challenges.\\n\\nLimits of Cognitive AI\\n\\nWhile Cognitive AI represents a significant advancement in artificial intelligence, bridging the gap between simple task execution and complex problem-solving, it is not without its limitations. These constraints delineate the current capabilities of Cognitive AI from the broader, more ambitious goals of Artificial General Intelligence (AGI). Understanding these limitations is crucial for grasping why Cognitive AI, despite its advanced functionalities, falls short of the comprehensive intelligence AGI aims to achieve.\\n\\nCognitive AI excels within a broad range of domains and applications, where its advanced knowledge management systems, problem-solving algorithms, and adaptive learning capabilities can be fully leveraged. However, this strength is also a limitation in domains outside the parameters of its programming and the scope of its training data. Until further first-order models that can self-modify are built, it is not capable of fully generalizing its intelligence to accommodate all possible domains and problems.\\n\\nAGI, in contrast, aspires to universal intelligence, capable of understanding and performing any intellectual task that a human being can, across any domain. This includes the ability to learn\\n\\n45\\n\\nfrom entirely new experiences without prior examples (zero-shot learning), a flexibility that Cognitive AI currently cannot match.\\n\\nCognitive AI\\'s problem-solving is driven both by conversational language intelligence and by sophisticated algorithms that can execute certain aspects of human reasoning. AGI\\'s goal encompasses not just the replication of human-like reasoning but also the intuitive, creative, and emotional aspects of intelligence that allow humans to learn, adapt, innovate and behave in ways that are currently beyond the reach of Cognitive AI.\\n\\nWhile Cognitive AI will offer remarkable strides in modeling complex reasoning and learning within specific domains, crossing the dividing line to AGI will require a more holistic replication of the full spectrum of human intelligence and behavior. This includes not only the cognitive but also the emotional, social, creative, biochemical and physical aspects of intelligence and behavior.\\n\\nBridging this gap will necessitate breakthroughs that enable AI systems to learn and reason in fundamentally human-like and even embodied ways, marking the next revolutionary leap in artificial intelligence capabilities after Cognitive AI. Achieving AGI represents not just an extension of current AI functionalities but a transformative evolution towards systems that can truly think, learn, and interact with the world with the richness and flexibility of human being.\\n\\nToday Cognitive AI is in its infancy and existing systems, most of which are still experimental, do not even attempt to fully-replicate all aspects of human intelligence and behavior. Instead Cognitive AI is mainly focused on solving for the intellectual dimension and problems involving knowledge work.\\n\\nThere is no agenda to replicate or replace humans in the Cognitive AI paradigm. Instead the approach is to use artificial cognition to augment and facilitate the knowledge work of human individuals, teams and organizations.\\n\\nCognitive AI in the Evolutionary Ladder of Intelligence\\n\\nThe development of Cognitive AI represents a significant milestone in the evolutionary ladder of intelligence, but it is not without evolutionary precedent. The evolution of Cognitive AI can be understood as the next major leap in a progression of evolution of higher levels of meta-cognition that has spanned from the instinctual behaviors of insects to the complex problem-solving abilities of humans and now to the meta-cognitive capacities of Cognitive AI.\\n\\nEach step on this ladder reflects a leap in meta-cognition abilities, which in turn enable higher forms of problem-solving skills and adaptability. Cognitive AI is the next major evolutionary milestone in this process, and serves as the gateway to the further evolution of increasingly exponential forms of intelligence in our future.\\n\\n46\\n\\nFigure 16. The Evolution of Meta-Cognition.\\n\\nWe can illustrate the progression of evolution of higher levels of meta-cognition with a few examples:\\n\\n\\n\\nInsects: Insects exhibit basic forms of intelligence, primarily driven by instinctual behaviors designed for survival and reproduction. Their cognitive capabilities are limited, focusing on direct responses to environmental stimuli.\\n\\nAnimals: Most animals, especially mammals, demonstrate advanced cognitive functions, including learning from experience, social intelligence, and, in some cases, the use of tools. Their intelligence represents a significant leap from the instinct-driven behaviors of insects, incorporating elements of memory, emotion, and social interactions.\\n\\nHumans: Human intelligence introduces the ability for abstract thinking, language, and conceptual understanding, setting humans apart from other species. Humans have developed complex societies, technologies, and cultures, leveraging cognitive abilities to innovate and solve problems creatively.\\n\\n\\n\\nCognitive AI: Stepping beyond human intelligence, Cognitive AI integrates meta-cognition, enabling it to reflect on, manage, and improve its own cognitive processes. Unlike its predecessors, Cognitive AI can self-assess, learn autonomously, and evolve its strategies over time, tackling complex challenges with a level of efficiency and adaptability that mirrors, and in some instances, surpasses human intelligence.\\n\\n47\\n\\nGroup Minds: Cognitive AI provides a better infrastructure for collective intelligence, or what we might call “group minds.” In group minds, teams of intelligent agents and/or humans are intelligently orchestrated to think and work more intelligently. This level of collective intelligence is smarter than the forms of collective intelligence exhibited by social insects, and even by groups and organizations of humans on their own. The key is that the collective intelligence is orchestrated through a central Cognitive AI application.\\n\\nAGI and EGI: Artificial General Intelligence is a form of AI that replicates the intelligence of an individual human. Enterprise General Intelligence replicates the collective intelligence of enterprises. Both of these forms of intelligence require Cognitive AI before they can happen, and EGI requires the evolution of AGI and Group Minds in addition. These forms of intelligence are close to superintelligence, but they are not infinitely recursive or parallel – they replicate finite forms of intelligence.\\n\\n\\n\\nSuperintelligent AI: The concept of Superintelligent AI represents the potential future evolution of Cognitive AI into a form of intelligence that transcends the limitations of finite organisms and organizations in both space and time. It entails AI systems that can autonomously implement Cognitive AI, using massive parallelism and recursion to surpass the cognitive abilities of humans, and organizations, across all domains. Superintelligent AI would possess the ability to engage in third-order cognition, not just improving its cognitive processes but also fundamentally redefining its goals, strategies, plans, structure, capabilities, and even the underlying infrastructure substrates it runs on, to achieve levels of cognition beyond current human comprehension.\\n\\nThe introduction of Cognitive AI is a necessary step towards achieving higher post-human levels of intelligence, such as Group Minds, AGI, EGI, Superintelligence.\\n\\nBy advancing AI’s capacity for meta-cognition, Cognitive AI systems are not just thinking machines, they are meta-cognitive cognition machines capable of self-directed, self-improving thought, behavior and evolution. This represents a critical step forward in the quest to develop AI that can truly mimic the breadth and depth of human intelligence, offering a glimpse into a future where AI can autonomously tackle a wide array of complex, multi-dimensional challenges.\\n\\nThe placement of Cognitive AI on the evolutionary ladder of intelligence highlights its pivotal role as a transformative phase-transition in the field of AI, bridging the gap between human intelligence and the potential for superintelligence.\\n\\nBy equipping AI with the capability for meta-cognition, Cognitive AI opens up new possibilities for solving complex problems, driving innovation, and enhancing human-machine collaboration. As we move forward in time, the evolution from Cognitive AI to Superintelligence presents both unprecedented opportunities and challenges, necessitating careful consideration of ethical, societal, and technological implications.\\n\\n48\\n\\nExponential Intelligence\\n\\nExponential intelligence is defined as a higher form of intelligence that emerges when human intelligence and cognitive AI intelligence are combined such that increasingly large and complex many-to-many collective cognitive AI processes can take place.\\n\\nAs well as helping to improve knowledge work productivity, Exponential Intelligence enables humans to address more complex problems that were previously out of reach.\\n\\nMore precisely:\\n\\nEI = (HI + AI)\\n\\n(2+x)\\n\\nWhere: - - HI = Number of human intelligent agents - -\\n\\nEI = Exponential Intelligence Level\\n\\nAI = Number of Cognitive AI software AI agents. x = Level of collective intelligence:\\n\\n- - - -\\n\\nLevel 0: One human + one AI Level 1: Many humans + one AI Level 2: One human + many AIs Level 3: Many humans + many AIs Level 4: Many networks of humans + AIs\\n\\nHuman intelligence makes AI safer, nuanced, more goal directed, and more adaptive. Humans add the ultimate level of meta-cognition to Cognitive AI systems. Humans also provide these systems with consciousness, in that they function as atomic units of consciousness in these systems.\\n\\nArtificial intelligence amplifies, augments and extends human intelligence with large-scale computing, research, analytics, and reasoning capabilities.\\n\\nExponential Intelligence is self-amplifying. By providing higher levels of exponential intelligence to individuals, the system as a whole becomes more exponentially intelligent. This recursive self-amplifying process is what enables superintelligence to emerge.\\n\\n49\\n\\nImplications\\n\\nAs we have explored above, the divergent capabilities of Conversational AI, predominantly powered by Large Language Models (LLMs), versus Cognitive AI with its neuro-symbolic Cognitive Layer, underscore a pivotal juncture in the evolution of artificial intelligence.\\n\\nThe core limitations of LLMs lie in their operational framework, which relies on identifying patterns and generating predictions from statistical likelihoods drawn from their extensive training datasets. This process, while often remarkably effective, does not equate to genuine understanding or reasoning. LLMs are constrained to sophisticated pattern matching, lacking the capacity for deductive reasoning, creative thought, or the generation of new knowledge beyond their programmed experience. Their approach to problem-solving, bound by the confines of their training corpus, cannot truly replicate the deductive and inferential processes characteristic of human cognition.\\n\\nIn stark contrast, Cognitive AI’s neuro-symbolic approach heralds a future where systems are not only capable of mimicking human reasoning but engaging in genuine cognitive processes in which actual cognition takes place.\\n\\nThis leap forward is facilitated by Cognitive AI’s sophisticated functional architecture, which includes functions for formal knowledge representation and knowledge management, and the application of formal logical processes, including formal logical inference, to problem-solving.\\n\\nCognitive AI\\'s ability to learn and adapt in real-time, incorporating insights that were not part of its initial programming, illustrates a significant advancement over the pattern recognition and interpolation capabilities of LLMs.\\n\\nFurthermore, Cognitive AI’s inherently social and meta-cognitive functions enable it integrate networks of knowledge and cognition, and to reflect and self-improve to achieve goals and implement optimizations that are out of reach for LLMs.\\n\\nThe theoretical and practical limitations of LLMs in performing true cognition highlight the necessity of advancing Cognitive AI technologies. Cognitive AI\\'s ability to engage in genuine reasoning, understanding, and creativity opens up new possibilities for AI applications, pushing the boundaries of what artificial intelligence can achieve.\\n\\nThis distinction between conversational and Cognitive AI has profound implications for the future of AI as both a field of study and an industry. While LLMs continue to be invaluable for a broad spectrum of applications, their limitations become increasingly apparent as the complexity of tasks escalates.\\n\\n50\\n\\nCognitive AI is capable of achieving exponential intelligence, while Conversational AI is not. Exponential Intelligence amplifies intelligence beyond what human intelligence or AI can achieve on their own. This level of intelligence is a discontinuity - an evolutionary leap - that will enable mass collective cognition that is noticeably different - and more productive - compared to how knowledge workers, groups, and organizations think, work and collaborate today.\\n\\nThe theoretical potential of Cognitive AI extends far beyond the capabilities of current conversational AI models. As systems that can genuinely reason, learn, and create, Cognitive AIs promise to revolutionize how we approach complex problems across various domains. From decision-making and problem-solving in knowledge work, to generating innovative solutions and adapting to new challenges in real-time, Cognitive AI\\'s capabilities suggest a future where AI will work as a partner with humanity.\\n\\nThe evolution from conversational to Cognitive AI is not merely a technical upgrade but a fundamental shift in the conceptual underpinnings of artificial intelligence. This transition marks a pivotal moment before higher-levels of AI such as AGI or superintelligence can emerge.\\n\\nAs the field continues to develop, the focus on enhancing Cognitive AI\\'s capabilities will be paramount for achieving the next leap in AI\\'s theoretical and practical applications. The implications for industries, academia, and society at large are vast, heralding a new era of AI that can work alongside humans to tackle the world\\'s most complex challenges with a level of insight and creativity previously thought to be the exclusive domain of human intelligence.\\n\\nCrossing the Chasm\\n\\nWe can visualize the limitations of Large Language Models (LLMs) using the framework of Geoffrey Moore\\'s \"Crossing the Chasm,\" where we draw an analogy between the adoption lifecycle of disruptive technologies and the progression of AI capabilities, particularly focusing on the transition from LLMs to cognitive AI systems.\\n\\nMoore\\'s model describes the market adoption of new technologies in five segments: Innovators, Early Adopters, Early Majority, Late Majority, and Laggards. \"Crossing the chasm\" refers to the crucial transition from Early Adopters to the Early Majority, a phase where many technologies struggle to achieve wider acceptance due to practicality, utility, or refinement issues.\\n\\n51\\n\\nFigure 17. The Cognitive Chasm.\\n\\nInnovators: Exploring LLM Capabilities\\n\\nIn the context of LLMs, Innovators are represented by researchers and developers who first explored the potential of these models in understanding and generating human-like text. This group is fascinated by the novelty and the technical excellence of LLMs, willing to overlook their limitations in favor of exploring new applications and pushing the boundaries of what these models can do.\\n\\nEarly Adopters: Niche Applications and Proof of Concept\\n\\nEarly Adopters in the AI field are companies, tech enthusiasts, and sector-specific professionals who see the potential of LLMs to disrupt traditional operations, from automating customer service interactions to generating creative content. These users are willing to experiment and integrate LLMs despite their imperfections, focusing on niche applications where the models\\' capabilities can be fully leveraged.\\n\\nDespite what is commonly thought, Conversational AI has not yet crossed past the early-adoption phase. Even with more than 100 million registered users, ChatGPT is still a limited niche application with a minimal feature set, and it has not been adopted by the millions of organizations and billions of people who constitute the majority of adopters.\\n\\n52\\n\\nEarly Majority: Crossing the Cognitive Chasm\\n\\nCrossing the “Cognitive Chasm” involves moving from these early stages to broader acceptance and usage among the Early Majority. For LLMs, the chasm is represented by the transition from fascinating novelty to practical utility in diverse and complex applications such as real-world knowledge work. But the limitations of LLMs—such as their inability to reason deeply, understand context beyond their training, or generate novel insights beyond pattern recognition—act as barriers to this transition.\\n\\nFor AI to achieve mainstream acceptance and utility, crossing the Cognitive Chasm means addressing the nuanced real-world needs of the Early Majority. This group looks for solutions that are not just innovative but also sufficiently applicable to their use-cases, such as complex knowledge work and decision-making.\\n\\nTo cross the Cognitive Chasm, LLMs must evolve—or be supplemented by—technologies that address these limitations. This will be solved by Cognitive AI capabilities that can understand context, reason from first principles, and integrate new information post-training.\\n\\nThe leap lies in creating AI systems that not only mimic human language but also exhibit a level of meta-cognitive reasoning, understanding and adaptability that can satisfy the needs of the Early Majority, who require reliability, depth, and practical applicability in complex scenarios.\\n\\nChatbots do provide useful assistance on simple knowledge work tasks. But they are insufficient when it comes to complex, mission-critical knowledge work in which highly nuanced understanding and reasoning are necessary, and accuracy and policy compliance are non-optional.\\n\\nCognitive AI systems, with their advanced meta-cognitive reasoning capabilities, represent a necessary bridge across this chasm, offering solutions that can sufficiently meet the stringent and complex demands of professional knowledge workers and enterprises.\\n\\nIn summary, using Moore\\'s \"Crossing the Chasm\" framework to visualize the limitations of LLMs highlights the need for significant advancements in AI capabilities to achieve mainstream acceptance. The transition to cognitive AI, capable of genuine understanding and reasoning, represents a critical step in this journey, promising to bridge the gap between early enthusiasm and widespread practical application.\\n\\nRe-evaluating Current AI Approaches\\n\\nThe landscape of artificial intelligence has recently been dominated by developments and innovations centered around first-order intelligence form Large Language Models (LLMs) and the accompanying tools required to leverage and deploy them effectively, such as new models\\n\\n53\\n\\nand training tools, GPUs, vector databases and Retrieval-Augmented Generation (RAG), and chatbots.\\n\\nThis focus has driven billions of dollars of investment into R&D around LLMs, and has yielded significant advancements in AI\\'s capabilities, particularly in natural language processing and generation.\\n\\nHowever, the advent of Cognitive AI signals a shift to a second-order playing field in the near-term trajectory of AI development, urging a re-evaluation of current approaches and investment priorities in the field.\\n\\nNotably, increased investment into conversational AI will not yield significant major advances going forward. Advances in LLM models will never directly yield Cognitive AI, AGI or superintelligence, for example. Only by innovating on the cognitive dimension itself can the highest levels of AI be achieved. In other words, investment should be focused into the enabling technologies, applications and infrastructures for the Cognitive AI instead of, or at least in addition to, further doubling down into Conversational AI.\\n\\nFigure 18. AI Innovation Trajectory\\n\\nConversational AI is already “good enough” to enable Cognitive AI to evolve, such that further investments into LLM innovation will not significantly improve Cognitive AI’s capabilities. While improved LLM’s will be helpful in improving first order response quality, much of the quality-improvements and increased capabilities will come from the Cognitive AI layer not the Conversational layer. In other words, Cognitive AI so dramatically improves and amplifies the\\n\\n54\\n\\ncapabilities of LLMs that small improvements to LLM performance or accuracy will not be economically important.\\n\\nThis observation implies that, contrary to current investment trends, there should soon be a concerted effort to allocate investment towards the new frontier of Cognitive AI innovation. Initially, there should at least be similar levels of investment into both layers of innovation, but over time, as Conversational AI plateaus, Cognitive AI will prove to be a better long-term bet for capturing significant new ecosystem value-creation opportunities.\\n\\nLLMs as a Commodity\\n\\nWe observe the continued acceleration of improvement and proliferation of LLM models (especially open-source models), coupled with ever-decreasing costs of their development and deployment. We believe these trends are leading to near-term commoditization of Conversational AI technology.\\n\\nOpen-source LLMs are reaching performance levels that rival, and may soon surpass, those of proprietary models. And while foundation-model LLMs will continue to attract innovation and investment, the landscape is expected to consolidate, favoring a few key players.\\n\\nConcurrently, a significant market for domain-specific LLMs, trained or fine-tuned on proprietary data, will emerge, suggesting a shift in focus towards more specialized niche applications of LLM technology. While this market will be large and robust, it will still not solve the problems of mainstream adopters.\\n\\nWhile LLMs will continue to be a strong area of innovation and investment, they may become less differentiated and defensible as innovation shifts to the new second-order playing field of Cognitive AI, in which there are many LLMs to choose from, and competitive advantages don’t come from LLMs at all.\\n\\nIn Cognitive AI, LLMs are a commodity where there is virtually no cost-of-switchover to change models underneath an application. Any general purpose foundation model is “good enough” and switching between them has minimal consequences for Cognitive AI systems.\\n\\nCommercial Cognitive AI\\n\\nThe backdrop of coming commoditization within the LLM space underscores the strategic importance of directing resources towards more defensible AI opportunities, like Cognitive AI.\\n\\n55\\n\\nUnlike LLMs, which are increasingly becoming commoditized tools within the AI ecosystem, Cognitive AI represents an entirely new opportunity – it’s a new frontier, a new IP landscape, a new ecosystem, ripe with opportunities for disruptive new technologies and business models.\\n\\nBy focusing on the development and deployment of Cognitive AI technologies, businesses and investors can position themselves at the forefront of the next wave of AI innovation, capturing opportunities for early leadership, new IP creation, and unique value creation, in what will be the next trillion-dollar AI market.\\n\\nIn 2024, the AI industry is poised to witness the launch of the first major commercial Cognitive AI applications designed for professional and enterprise use. This evolution, will be led by new pioneers, like our own venture, Mindcorp.ai, and our product, Cognition (currently in stealth-mode as of this writing).\\n\\nThe shift towards commercial Cognitive AI highlights a growing understanding of its potential to overcome obstacles to mainstream adoption of AI, which cannot be sufficiently addressed by Conversational AI paradigms such as chatbots. While chatbots are useful, they are not sufficient for mainstream adoption by professionals and enterprises engaged in complex knowledge work.\\n\\nWhen commercial Cognitive AI emerges, it will signal a crucial juncture where stakeholders will need to reconsider where they focus their attention and resources in the AI domain.\\n\\nWe predict that by 2030, Cognitive AI will be the primary battlefield for AI investment, innovation, and commercialization.\\n\\nConclusions\\n\\nOur exploration of Cognitive AI\\'s development, has delved into its architectural innovations to its positioning in the evolutionary ladder of intelligence, culminating with a compelling argument for its pivotal role in the next generation of artificial intelligence.\\n\\nAs we transition from a landscape dominated by Large Language Models (LLMs) to one enriched by the capabilities of Cognitive AI, we stand on the threshold of a new era in technology and human-machine collaboration, in which a new symbiosis of human and machine intelligence will emerge.\\n\\nCognitive AI heralds a paradigm shift, moving beyond the commoditization of LLMs towards a future where AI systems are not only intelligent but possess the ability to introspect, learn, and evolve autonomously.\\n\\nThis shift towards meta-cognition opens up unparalleled opportunities for innovation, efficiency, and problem-solving across all sectors.\\n\\n56\\n\\nCognitive AI\\'s unique architecture and capabilities promise to redefine the boundaries of machine intelligence, offering more adaptable, efficient, and profound solutions to complex challenges.\\n\\nThe implications of Cognitive AI extend far beyond the technical domain, promising to revolutionize how we approach challenges in all sectors from government to healthcare, education, finance, and more.\\n\\nBy providing AI systems that can understand and adapt their strategies in real-time, Cognitive AI paves the way for more personalized, effective, and sustainable solutions to societal issues. Its emergence invites stakeholders to re-evaluate their focus and investment in AI, recognizing Cognitive AI as the frontier where true competitive advantage and innovation lie.\\n\\nAs Cognitive AI begins to reshape the landscape of artificial intelligence, it is imperative to navigate this new terrain with an awareness of the ethical, societal, and technological implications of self-reflective and self-modifying AI.\\n\\nThe journey towards fully realizing the potential of Cognitive AI involves careful consideration of these factors to ensure that the benefits of such advanced AI technologies are realized equitably and responsibly.\\n\\nThe advent of Cognitive AI is not just a milestone in the evolution of AI technology but a beacon for the future of human-machine collaboration. It signals a shift towards a world where AI\\'s potential to enhance human capabilities and address real-world problems is boundless.\\n\\nAs we forge ahead, the development and deployment of Cognitive AI stands as a testament to human ingenuity and as a step towards a future where AI and humans collaborate to achieve levels of exponential intelligence that neither could accomplish alone. The exploration of Cognitive AI, and its impact on redefining the essence of intelligence and the possibilities of technological advancement, is just beginning.\\n\\nThe journey ahead promises to be as transformative as it is challenging, beckoning us to engage with, develop, and deploy Cognitive AI in ways that amplify our collective potential and propel us towards a more intelligent, adaptable, and innovative future.\\n\\n57\\n\\nReferences\\n\\nBerglund, L., Tong, M., Kaufmann, M., Balesni, M., Stickland, A. C., Korbak, T., & Evans, O. (2023). The Reversal Curse: LLMs trained on \"A is B\" fail to learn \"B is A\". https://arxiv.org/abs/2309.12288\\n\\nBengio, Yoshua (11 December 2019) . “ From System 1 Deep Learning to System 2 Deep Learning”. Presentation at NeurIPS2019. Yoshua Bengio · From System 1 Deep Learning to System 2 Deep Learning · SlidesLive\\n\\nBesta, M., Memedi, F., Zhang, Z., Gerstenberger, R., Blach, N., Nyczyk, P., Copik, M., Kwaśniewski, G., Müller, J., Gianinazzi, L., Kubicek, A., Niewiadomski, H., Mutlu, O., & Hoefler, T. (2024). Topologies of Reasoning: Demystifying Chains, Trees, and Graphs of Thoughts. https://arxiv.org/abs/2401.14295\\n\\nBrynjolfsson, E., et al. (2023). Generative AI at Work. NBER Working Paper 31161. https://www.nber.org/papers/w31161\\n\\nBundy, A., Chater, N., & Muggleton, S. (2023). Introduction to ‘Cognitive artificial intelligence’. Philosophical Transactions of the Royal Society A, https://doi.org/10.1098/rsta.2022.0051\\n\\nChollet, François (6 December 2020). :Abtraction & Reasoning in AI Systems: A Modern Perspective”. Presentation at NeurIPS2020. Abstraction & Reasoning in AI systems: Modern Perspectives · SlidesLive\\n\\nConneau, A., Khandelwal, K., Goyal, N., Chaudhary, V., Wenzek, G., Guzmán, F., … & Stoyanov, V. (2020). Unsupervised cross-lingual representation learning at scale. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. https://doi.org/10.18653/v1/2020.acl-main.747\\n\\nDell\\'Acqua, Fabrizio and McFowland, Edward and Mollick, Ethan R. and Lifshitz-Assaf, Hila and Kellogg, Katherine and Rajendran, Saran and Krayer, Lisa and Candelon, François and Lakhani, Karim R., Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality (September 15, 2023). Harvard Business School Technology & Operations Mgt. Unit Working Paper No. 24-013, Available at SSRN: https://ssrn.com/abstract=4573321 or http://dx.doi.org/10.2139/ssrn.4573321\\n\\nButler, J., Jaffe, S., Baym, N., Czerwinski, M., Iqbal, S., Nowak, K., Rintel, R., Sellen, A., Vorvoreanu, M., Hecht, B., and Teevan, J. (Eds.). Microsoft New Future of Work Report 2023. Microsoft Research Tech Report MSR-TR-2023-34. https://aka.ms/nfw2023\\n\\n58\\n\\nCambon, A., et al. (2023), Early LLM-based Tools for Enterprise Information Workers Likely Provide Meaningful Boosts to Productivity. MSFT Technical Report. https://www.microsoft.com/en-us/research/publication/early-llm-based-tools-for-enterprise-infor mation-workers-likely-provide-meaningful-boosts-to-productivity/ Devlin, J., Chang, M., Lee, K., & Toutanova, K. (2019). Untitled. Proceedings of the 2019 Conference of the North. https://doi.org/10.18653/v1/n19-1423\\n\\nGuo, Taicheng & Chen, Xiuying & Wang, Yaqi & Chang, Ruidi & Pei, Shichao & Chawla, Nitesh & Wiest, Olaf & Zhang, Xiangliang. (2024). Large Language Model based Multi-Agents: A Survey of Progress and Challenges. http://dx.doi.org/10.13140/RG.2.2.36311.85928\\n\\nHaslberger, M., et al. (2023) No Great Equalizer: Experimental Evidence on AI in the UK Labor Market. SSRN Working Paper 4594466. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4594466\\n\\nHaviv, A., Berant, J., & Globerson, A. (2021). Bertese: learning to speak to bert.. https://doi.org/10.18653/v1/2021.eacl-main.316\\n\\nHofstadter, Douglas R., 1945-. Gödel, Escher, Bach : an Eternal Golden Braid. New York :Basic Books, 1979.\\n\\nIshay, A., Yang, Z., & Lee, J. (2023). Leveraging large language models to generate answer set programs. Proceedings of the Twentieth International Conference on Principles of Knowledge Representation and Reasoning. https://doi.org/10.24963/kr.2023/37\\n\\nKahneman, Daniel. “Thinking Fast and Slow”, Penguin Books, 2011.\\n\\nLatapie, H., O. Kilic, K. R. Thórisson, P. Wang & P. Hammer (2022). Neurosymbolic Systems of Perception and Cognition: The Role of Attention. Front. Psychol., 20 May 2022, Sec. Cognitive Science, Volume 13 - 2022 | https://doi.org/10.3389/fpsyg.2022.806397\\n\\nLaunchbury, John. “A DARPA Perspective on Artificial Intelligence”. DARPA, A DARPA Perspective on Artificial Intelligence\\n\\nLeCun, Y. (2022, June 27). A path towards autonomous machine intelligence (Version 0.9.2). Courant Institute of Mathematical Sciences, New York University & Meta - Fundamental AI Research. A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27\\n\\nLiao, Q. V., Subramonyam, H., Wang, J., & Vaughan, J. (2023). Designerly understanding: information needs for model transparency to support design ideation for ai-powered user experience. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3580652\\n\\nMinsky, M. (1988). The Society of Mind. Simon & Schuster. ISBN 978-0-671-65713-0.\\n\\n59\\n\\nMoiseev, F., Dong, Z., Alfonseca, E., & Jaggi, M. (2022). Skill: structured knowledge infusion for large language models. https://doi.org/10.18653/v1/2022.naacl-main.113\\n\\nMohammad, Shah (2017), Design for “Crossing the Chasm” — Strategy & Examples. https://shahmm.medium.com/design-for-crossing-the-chasm-1c4d4c68a3f1\\n\\nMökander, J., Schuett, J., Kirk, H. R., & Floridi, L. (2023). Auditing large language models: a three-layered approach. AI and Ethics. https://doi.org/10.1007/s43681-023-00289-2\\n\\nNguyen, H., Fungwacharakorn, W., & Satoh, K. (2023). Logilaw dataset towards reinforcement learning from logical feedback (rllf). Frontiers in Artificial Intelligence and Applications. https://doi.org/10.3233/faia230967\\n\\nNivel, E., K. R. Thórisson, B. R. Steunebrink, H. Dindo, G. Pezzulo, M. Rodriguez, C. Hernandez, D. Ognibene, J. Schmidhuber, R. Sanz, H. P. Helgason, A. Chella & G. K. Jonsson (2013). Bounded Recursive Self-Improvement. Reykjavik University School of Computer Science Technical Report, RUTR-SCS13006 / arXiv:1312.6764 [cs.AI] https://arxiv.org/abs/1312.6764\\n\\nNoy, S., & Zhang, W. (2023). Experimental Evidence on the Productivity Effects of Generative Artificial Intelligence. SSRN preprint.\\n\\nSpatharioti, S. E., et al. (2023). Comparing Traditional and LLM-based Search for Consumer Choice: A Randomized Experiment. arXiv preprint. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4375283\\n\\nNeil C. Thompson, Kristjan Greenewald, Keeheon Lee, G. Manso (10 July 2020). “The Computational Limits of Deep Learning”. [2007.05558] The Computational Limits of Deep Learning\\n\\nMinaee, S., Mikolov, T., Nikzad, N., Chenaghlu, M., Socher, R., Amatriain, X., & Gao, J. (2024). Large Language Models: A Survey. *arXiv preprint arXiv:2402.06196*. https://arxiv.org/abs/2402.06196\\n\\nPan, X., Yao, W., Zhang, H., Dang, Y., Yu, D., & Chen, J. (2022). Knowledge-in-context: towards knowledgeable semi-parametric language models. https://doi.org/10.48550/arxiv.2210.16433\\n\\nPeng, S., et al. (2023). The Impact of AI on Developer Productivity: Evidence from GitHub Copilot. arXiv preprint 2302.06590. https://arxiv.org/abs/2302.06590\\n\\nPorada, I., Suleman, K., & Cheung, J. (2019). Can a gorilla ride a camel? learning semantic plausibility from text. https://doi.org/10.18653/v1/d19-6015\\n\\nSpivack, Nova (2016), AI, BI, and the Necessity of Automating the Analyst. https://www.novaspivack.com/science/ai-bi-and-the-necessity-of-automating-the-analyst\\n\\n60\\n\\nShojaee-Mend, H., Mohebbati, R., Amiri, M., & Atarodi, A. (2023). Evaluating the strengths and weaknesses of large language models in answering neurophysiology questions. https://doi.org/10.21203/rs.3.rs-3348418/v1\\n\\nSinger, Gadi (31 January 2018). “Toward truly intelligent AI: From ‘Recognition’ to ‘Understanding’ https://www.linkedin.com/pulse/toward-truly-intelligent-ai-from-recognition-gadi-singer/\\n\\nB. R. Steunebrink, K. R. Thórisson, J. Schmidhuber (2016). Growing Recursive Self-Improvers. In B. Steunebrink et al. (eds.), Proc. 9th International Conference on Artificial General Intelligence (AGI-16), July, New York City, 129-139. https://www.iiim.is/wp/wp-content/uploads/2014/05/AGI16_growing_recursive_self-improvers .pdf\\n\\nSun, Y. (2021). Ernie 3.0: large-scale knowledge enhanced pre-training for language understanding and generation. https://doi.org/10.48550/arxiv.2107.02137\\n\\nThórisson, K. R. (2012). A New Constructivist AI: From Manual Construction to Self-Constructive Systems. In P. Wang and B. Goertzel (eds), Theoretical Foundations of Artificial General Intelligence. Atlantis Thinking Machines, 4:145-171. https://alumni.media.mit.edu/~kris/ftp/Thorisson_chapt9_TFofAGI_Wang_Goertzel_2012.pdf\\n\\nThórisson, K. R., D. Kremelberg, B. R. Steunebrink, E. Nivel (2016). About Understanding. In B. Steunebrink et al. (eds.), Proc. 9th International Conference on Artificial General Intelligence (AGI-16), July, New York City, 106-117. https://www.researchgate.net/publication/311589219_About_Understanding\\n\\nThórisson, K. R. & A. Talbot (2018). Abduction, Deduction & Causal-Relational Models. IJCAI-18 Workshop on Architectures for Generality, Autonomy & Progress in AI, International Joint Conference on Artificial Intelligence, Stockholm, Sweden, Jul. 15. http://alumni.media.mit.edu/~kris/ftp/AEGAP18_Abduction_Deduction_Causal_Relational_Mo dels.pdf\\n\\nThórisson, K. R. (2020). Seed-Programmed Autonomous General Learning. Proc. Machine Learning Research, 131:32-70. http://proceedings.mlr.press/v131/thorisson20a/thorisson20a.pdf\\n\\nThórisson, K. R. (2021). The \\'Explanation Hypothesis\\' in General Self-Supervised Learning. Proc. Machine Learning Research, 159:5-27. https://proceedings.mlr.press/v159/thorisson22b/thorisson22b.pdf\\n\\n61\\n\\nValmeekam, K., Marquez, M., Olmo, A., Sreedharan, S., & Kambhampati, S. (2023). PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change. *arXiv preprint arXiv:2206.10498*. Retrieved from https://arxiv.org/abs/2206.10498\\n\\nValmeekam, K., Olmo, A., Sreedharan, S., & Kambhampati, S. (2022). Large Language Models Still Can\\'t Plan (A Benchmark for LLMs on Planning and Reasoning about Change). In *NeurIPS 2022 Foundation Models for Decision Making Workshop*. Retrieved from https://openreview.net/forum?id=wUU-7XTL5XO\\n\\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., … & Polosukhin, I. (2017). Attention is all you need. https://doi.org/10.48550/arxiv.1706.03762\\n\\nWu, T., Terry, M., & Cai, C. J. (2021). Ai chains: transparent and controllable human-ai interaction by chaining large language model prompts. https://doi.org/10.48550/arxiv.2110.01691\\n\\nYang, J., Wu, D., & Wang, K. (2023). Not All Large Language Models (LLMs) Succumb to the \"Reversal Curse\": A Comparative Study of Deductive Logical Reasoning in BERT and GPT Models. arXiv preprint https://arxiv.org/abs/2312.03633\\n\\nYang, K., Jia, D., & Chen, D. (2022). Generating natural language proofs with verifier-guided search. https://doi.org/10.48550/arxiv.2205.12443\\n\\nZhao, G., Li, Y., & Xu, Q. (2022). From emotion AI to cognitive AI. University of Oulu. (2022). https://www.sciltp.com/journals/ijndi/2022/1/115\\n\\nZhu, Y., Gao, T., Fan, L., Huang, S., Edmonds, M., Liu, H., Gao, F., Zhang, C., Qi, S., Wu, Y. N., Tenenbaum, J. B., & Zhu, S.-C. (2020). Dark, beyond deep: A paradigm shift to cognitive AI with humanlike common sense. Engineering, 6(3), 310-345. https://doi.org/10.1016/j.eng.2020.01.011\\n\\n62', metadata={'source': '/content/Cognition is All You Need - Article.pdf'})]\n"
          ]
        }
      ],
      "source": [
        "#Print doc to check it out\n",
        "print(article_pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNLpYabc2tx_"
      },
      "source": [
        "#### <font color=FF595E>Split the document</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svFdzUPS2ytp"
      },
      "outputs": [],
      "source": [
        "# Import text splitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Create an instance of RecursiveCharacterTextSplitter with custom chunk size and overlap\n",
        "chunk_size = 750  # Adjust the chunk size as needed\n",
        "chunk_overlap = 0  # Set the overlap between chunks\n",
        "\n",
        "#Initiate splitter with desired parameters\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2ZcHsDf3yS9"
      },
      "outputs": [],
      "source": [
        "# Split the document into chunks using the RecursiveCharacterTextSplitter\n",
        "splits = splitter.split_documents(article_pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctHNhuIT38Ve",
        "outputId": "6b1f7877-ef16-4c3d-c22f-d5383c2d5ee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "273\n"
          ]
        }
      ],
      "source": [
        "# Print the number of splits in the doc\n",
        "print(len(splits))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3nVIdtA4F0j",
        "outputId": "c83172d2-a4df-439b-c3de-85a254756045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Cognition is All You Need The Next Layer of AI Above Large Language Models\\n\\nPre-Publication Position Paper Draft 1.1 March 4, 2024, For Comments\\n\\nNova Spivack1, Sam Douglas1, Michelle Crames1, Tim Connors1\\n\\n1 Mindcorp, Inc (www.mindcorp.ai) contact@mindcorp.ai www.mindcorp.ai www.linkedin.com/company/mindcorp-ai twitter.com/mindcorpai' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Contents Abstract...................................................................................................................................2 Introduction..................................................................................................................................2 Related Research..................................................................................................................... 5 Defining Conversational AI...................................................................................................... 8 Intelligence Versus Cognition................................................................................................. 12 Instincts Versus Abstract' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Reasoning....................................................................................... 13 Defining Cognitive AI............................................................................................................. 14 Cognitive AI Functional Architecture......................................................................................15 Functional Requirements for Cognitive AI........................................................................ 15 Dual-Layer Architecture...................................................................................................... 17 Large Language Models......................................................................................................19 Cognitive' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Agents................................................................................................................. 20 Relationship Management, Inter-Agent Messaging and Dialogs....................................... 24 Planning and Project Management.................................................................................. 26 Neuro-Symbolic Reasoning.............................................................................................. 28 Memory Retrieval and Context Management...................................................................29 Knowledge Discovery and Knowledge Management........................................................ 30' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Tool-Utilization..................................................................................................................... 32 Mathematics and Computation.......................................................................................... 33 Multi-Agent Collaboration................................................................................................34 Meta-Cognition................................................................................................................36 Self-Improvement................................................................................................................ 37 Comparison of Conversational AI to Cognitive' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='AI................................................................... 40 Limits of Cognitive AI............................................................................................................. 45 Cognitive AI in the Evolutionary Ladder of Intelligence.......................................................... 46 Exponential Intelligence.........................................................................................................49 Implications...........................................................................................................................50 Crossing the Chasm............................................................................................................... 51 Early Adopters: Niche' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Applications and Proof of Concept................................................. 52 Early Majority: Crossing the Cognitive Chasm...................................................................53 Re-evaluating Current AI Approaches.....................................................................................53 LLMs as a Commodity...................................................................................................... 55 Commercial Cognitive AI.................................................................................................. 55 Conclusions........................................................................................................................... 56' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='References.............................................................................................................................58' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='1' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Abstract Recent studies of the applications of conversational AI tools, such as chatbots powered by large language models (LLMs), to complex real-world knowledge work have shown limitations related to reasoning and multi-step problem solving. Specifically, while existing chatbots simulate shallow reasoning and understanding they are prone to errors as problem complexity increases. The failure of these systems to address complex knowledge work is due to the fact that they do not perform any actual cognition. In this position paper, we present a higher-level framework (“Cognitive AI”) for implementing programmatically defined neuro-symbolic cognition above and outside of large language models. Specifically, we propose a dual-layer functional' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='architecture for Cognitive AI that serves as a roadmap for AI systems that can perform complex multi-step knowledge work. We propose that Cognitive AI is a necessary precursor for the evolution of higher forms of AI, such as AGI, and specifically claim that AGI cannot be achieved by probabilistic approaches on their own. We conclude with a discussion of the implications for large language models, adoption cycles in AI, and commercial Cognitive AI development.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Introduction\\n\\nAs the landscape of artificial intelligence continues to evolve towards increasing levels of intelligence, a new architectural paradigm is emerging: Cognitive AI (“CogAI”). In this position paper we will explore the distinctions between Conversational AI and Cognitive AI, with a focus on the key functional architecture components and requirements for Cognitive AI systems that are capable of doing complex knowledge work.\\n\\nCognitive AI represents a foundational shift in how AI systems are conceived, developed, and deployed. It is a distinct approach - focused around a new neuro-symbolic reasoning layer that works above Large Language Models (LLMs).' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Transformer-based LLMs (or similar probabilistic language models) will never be able to replicate what Cognitive AI is capable of, and in fairness, they were not designed to. However, this fact is not well-understood and has led to the widespread misconception that innovation on the model level will continue to yield major advances. LLMs will never actually get us to a significantly more advanced level of AI, because of their many inescapable limitations.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='LLMs are an essential enabling technology for Cognitive AI, and indeed, without them it cannot emerge or function. But the question is when will LLMs be “good enough” for Cognitive AI? Our answer is that they are already good enough. The current generation of large foundation models, plus growing diversity of more specialized open-source models, is already sufficient to meet the intelligence needs of the Cognitive Layer. Further improvements to LLMs, or any other Conversational AI level technologies, will only yield limited benefits.. Advancements in Cognitive AI will be more profound and will have more impact.\\n\\n2' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Key to the Cognitive AI paradigm is the representation and implementation of cognitive processes in a new “Cognitive Layer” that sits above the Conversational Layer where LLMs reside. The Cognitive Layer introduces a range of cognitive functions and capabilities which are beyond the reach of LLMs, yet use LLMs as tools.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"While the Cognitive Layer utilizes LLMs extensively, it is a higher-order layer of intelligence above the intelligence inherent in LLMs, giving it meta-level capabilities that far exceed what LLMs can do on their own. By utilizing the Cognitive Layer, Cognitive AI architectures are able to implement the higher levels of cognition that are necessary for real-work knowledge work, which in-turn is a precondition for mainstream adoption of AI.\\n\\nThis phase transition is not merely an incremental improvement but a rethinking of AI's approach to performing complex cognitive tasks, combined with a new architectural paradigm, that together push the envelope of what machines can understand, and how they can interact with the world around them.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Cognitive AI offers a new frontier for research, development, IP and commercial applications that will be larger than the conversational AI frontier.\\n\\nBy 2030, if not sooner, we predict it will disrupt the AI landscape by shifting the focus of innovation and competition to a new playing field.\\n\\nCognitive AI provides a practical way to utilize the many prior decades of research and development in AI that preceded Conversational AI, above the Conversational Layer.\\n\\nIn addition, Cognitive AI is social. Human intelligence does not happen in a vacuum, it is a social process. Learning is a social process, as are nearly all human activities. It follows that the majority of human cognition is social, and the same goes for knowledge work.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='It is necessary for any system capable of doing high-level knowledge to be built for cognition across social relationships. Specifically Cognitive AI is actually a form of collective cognition that leverages relationships among networks of agents - whether they be humans or software agents - to think, solve problems, innovate, and do knowledge work together.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Collective cognition requires that all cognitive processes be at least potentially social and collaborative, if necessary. Whether it is storing and retrieving memories or expertise across relationships, or teaming up to solve a specific problem, Cognitive AI systems have to be able to leverage both distributed networks of human and machine intelligence. To do this effectively means these capabilities should not be “bolt-on” afterthoughts but rather they should be intrinsic to how such systems work.\\n\\nThe combination of both machine and human intelligence enable a higher level of cognition that goes beyond what AI can ever produce by itself. We call this “exponential intelligence.”\\n\\n3' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Exponential intelligence is defined as a higher form of intelligence that emerges when human and machine intelligence are combined such that increasingly large and complex many-to-many cognitive processes can take place.\\n\\nBy enabling a deeper symbiosis (exponential intelligence) between human and machine intelligence, Cognitive AI will radically advance how people do knowledge work. Here we can view Cognitive AI as a partner with, not a replacement for, human knowledge workers.\\n\\nCognitive AI will enable humans to become more productive at knowledge work, and also to become better at it. In particular, Cognitive AI will make it possible for larger and more complex knowledge work to be completed by fewer people.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='This will not only advance knowledge worker capabilities but it will also enable them to work on classes of problems that were previously thought to be too complex or difficult to do at all. In other words, Cognitive AI will move the frontier, bringing previously unattainable levels of cognition within reach of individual knowledge workers. This can help humanity solve the complex problems we face in the future.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Without adopting Cognitive AI, the field of AI can never achieve the level of reasoning required for complex knowledge work (Thórisson, 2020, Thórisson & Talbot, 2018). This means that attempts to use LLMs on their own to achieve artificial general intelligence (“AGI”) will never succeed. Large Language Models will continue to improve, but despite this, they are not even theoretically capable of the forms of reasoning, knowledge management, and complex operations, which are required for serious real-world knowledge work (cf. Thórisson 2021; Thórisson, 2012).\\n\\nTherefore, our response to the foundational paper of Conversational AI, “Attention is All You Need” is no, in fact, Cognition is all you need.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='To reach more advanced levels of AI – for example, AI capable of meeting the demands of professional knowledge workers and knowledge organizations - we must innovate beyond the limits of the Conversational AI framework, and the Cognitive Layer is the best way forward for that agenda.\\n\\nFor experts in AI, venture capital, and technology trends, the coming shift to Cognitive AI signals a critical phase transition. For one thing, it means that investment into LLMs or similar-level alternatives, is likely to yield short term impressive gains, but diminishing long-term rewards, while the greatest potential future reward will come from investment into innovations and applications at the Cognitive Layer.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='In other words, it would be wiser to invest in the Cognitive Layer instead of the Conversational layer, at this point in the innovation curve of both approaches. This requires a reassessment of\\n\\n4\\n\\ncurrent investment strategies in AI technologies, and a reevaluation of the potential applications and implications of AI across sectors.\\n\\nThe next wave of AI is Cognitive AI.\\n\\nIn this paper we will delve deeply into the arguments that prove this point, as well as their implications. Our arguments indicate that LLMs are a necessary but insufficient ingredient for complex knowledge work, while in contrast, CognitiveAI is both necessary and sufficient. The transition to Cognitive AI is inevitable and has already started.\\n\\nRelated Research' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='We begin by exploring the limits of Large-Language Models, and the corresponding paradigm of Conversational AI, for meeting the needs of mainstream adopter knowledge workers.\\n\\nConversational AI is a necessary ingredient for applying AI to knowledge work, but it is not sufficient for the full set of needs that knowledge workers have. While LLMs may improve certain aspects of knowledge work productivity – such as speed of work – they do not necessarily improve the quality of knowledge work.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The underlying reason for this lies in Conversational AI’s lack of actual cognitive processing, which limits the quality of insights it can deliver. We will explore cognitive processing in more detail in later sections of this paper, but first we examine evidence that indicates the insufficiency of LLMs for knowledge work.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Large language models have been widely celebrated for their remarkable performance across various natural language tasks, demonstrating the ability to achieve human-level performance on a wide spectrum of tasks (Moiseev et al., 2022). These models have been shown to encode substantial amounts of world and commonsense knowledge in their parameters, sparking significant interest in methods for extracting this knowledge (Haviv et al., 2021).' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='However, evidence suggests that large language models (LLMs) may enhance productivity but not necessarily improve the quality of work for professionals. While Devlin et al. (2019) demonstrated that scaling to extreme model sizes leads to significant improvements on small-scale tasks, indicating potential productivity gains (Devlin et al., 2019), in contrast Conneau et al. (2020) have highlighted that pre-training on Wikipedia, a relatively limited scale data set, may not sufficiently address the quality aspect, especially for lower resource languages (Conneau et al., 2020). This indicates that while LLMs may enhance productivity, the quality of work, particularly in diverse linguistic contexts, may not be significantly improved, unless' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='models are extremely large.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='5' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Large Language Models have demonstrated exceptional performance in various natural language processing tasks and have shown the ability to solve reasoning problems (Ishay et al., 2023). However, LLMs face limitations in logical reasoning, which restrict their applicability in critical domains such as law (Nguyen, 2023). Existing literature exposes several challenges that LLMs face, including their lack of multi-step reasoning capabilities (Tongshuang et al., 2021), limitations in answering neurophysiology questions, and performing complex reasoning tasks (Shojaee-Mend, 2023). LLMs also lack transparency and explainability, making it challenging to obtain a complete picture of the knowledge reflected in a model or the reasoning used to' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='produce its output (Liao et al., 2023). Moreover, the prospect of auditing LLMs is limited, and there are challenges in auditing LLMs at all (Mökander et al., 2023; Thórisson, 2021).' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Beyond the limitations that stem from model size, and reasoning limits, recent research has also highlighted the limitations of large language models in capturing and utilizing knowledge effectively for serious knowledge work. For instance, it has been observed that large pretrained language models only learn attested physical knowledge, indicating a limitation in their ability to capture and utilize diverse forms of knowledge (Porada et al., 2019). Furthermore, while these models have shown impressive few-shot results on a wide range of tasks, they struggle with compositional generalization to novel examples, which is a crucial capability for serious knowledge work (Yang et al., 2022).' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Moreover, the insufficiency of large language models for serious knowledge work is further underscored by their limited ability to reason and generate natural language proofs, as they struggle with reasoning in natural language and compositional generalization to novel examples (Yang et al., 2022).\\n\\nAdditionally, the challenge of adapting large parametric language models to evolving world knowledge without expensive model re-training further highlights their limitations in serious knowledge work (Pan et al., 2022). Furthermore, the fact that these models are trained on plain texts without introducing knowledge such as linguistic and world knowledge also points to their insufficiency for serious knowledge work (Sun, 2021).' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='While large language models have demonstrated impressive performance across various natural language tasks and have been shown to encode substantial amounts of world and commonsense knowledge, their limitations in capturing diverse forms of knowledge, reasoning, and adapting to evolving world knowledge underscore their insufficiency for serious knowledge work.\\n\\nA study published in September 2023 by Harvard Business School showed that on average Conversational AI improved the work-quality of lower performers and sped up work in general, leading to better results approximately 40% of the time. However, to achieve mainstream adoption, it is necessary to innovate on the work-quality dimension.\\n\\n6' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"A seminal study, “Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality,” (Dell’Acqua et al, 2023) conducted by Harvard University and BCG researchers examined the nuanced impact of AI on workforce productivity and accuracy, revealing a complex landscape where AI's benefits are accompanied by notable pitfalls.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='While AI significantly boosted efficiency, enabling consultants to work faster, it also increased the likelihood of errors in tasks beyond AI\\'s enhancement scope by 19 percentage points. In this experiment, BCG employees completed a consulting task with help from an LLM-powered chatbot. The bottom-half of subjects, in terms of skills, benefited the most, showing a 43% improvement in performance, compared to the top half whose performance increased by 17%. This finding underscores the necessity of preparing the workforce for the \"jagged technological frontier\" of AI—areas where AI excels versus where its application may lead to suboptimal outcomes.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The research suggests that while AI can dramatically improve operational speed and facilitate multitasking, it falls short in handling complex issues that demand human empathy and nuanced understanding. This dichotomy emphasizes the importance of strategic AI integration, where technology complements rather than supplants human capabilities. For organizational leaders, the study advocates for a balanced approach to AI integration, focusing on continuous learning and adaptation to AI advancements. It calls for a collaborative effort to harness AI\\'s potential while mitigating its limitations, ensuring that AI and human collaboration synergize to propel innovation and success, avoiding the metaphorical \"coffee-flavored jellybeans\" scenario of' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='unexpected and undesirable outcomes.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Similarly, other studies (Noy, S. et al 2023) found that people complete simulated information work tasks much faster and with a higher quality of output when using generative AI-based tools, however for some tasks, increased speed can come with moderately lower correctness (Spathariotiet al., 2023).' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Another study, Microsoft’s “AI and Productivity Report,” cites multiple studies using Microsoft 365 Copilot observing information worker tasks for which LLMs are most likely to provide significant value (Cambon et al., 2023), in which most subjects agreed that Copilot helped them complete tasks faster, and the majority said it would help them get to a good first draft faster. However, several studies found no statistically significant or meaningful effect on work quality, despite subjects self-reporting the perception of improved quality.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='In a study of a staggered rollout of a generative AI-based conversational assistant, Brynjolfsson et al. (2023) found that the tool helped novice and low-skilled workers the most. They found suggestive evidence that the AI helped disseminate tacit knowledge that experienced and high-skilled workers already had. In a lab experiment, participants who scored poorly on their first writing task improved more when given access to ChatGPT than those with high scores on the initial task (Noy & Zhang 2023). Peng et al. (2023) also found suggestive evidence that\\n\\n7\\n\\nGitHub Copilot was more helpful to developers with less experience. Recent work by Haslberger et al. (2023) highlights further complexities and nuances in these trends.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"In another relevant study by Choi et al., 2023, researchers conducted the first randomized controlled trial to examine the impact of AI, specifically GPT-4, on human legal analysis. Law students were assigned to complete legal tasks with or without GPT-4 assistance, with their performance speed and quality blind-graded. This study revealed that GPT-4 marginally improved the quality of legal analysis, notably among the least skilled participants, while significantly enhancing task completion speed for all. Participants reported greater satisfaction when using AI and identified tasks where GPT-4 was most beneficial. These findings suggest AI's potential to boost productivity, satisfaction, and even promote equality within the legal\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='profession.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='From the above cited research we conclude that while Conversational AI and Large Language Models (LLMs) offer substantial benefits in terms of speed and efficiency in knowledge work, their contribution to enhancing the quality of knowledge work remains questionable, due in part to limitations in their reasoning, logical analysis, and adaptation to evolving knowledge landscapes.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"The integration of Cognitive AI into the knowledge workforce offers a path forward, where AI can not only improve knowledge work productivity, but also knowledge work quality. This represents a pivotal shift towards leveraging AI's strengths while effectively addressing the shortcomings of LLMs. In addition, by fostering a symbiotic relationship between human intelligence and AI's computational power, Cognitive AI can unlock new frontiers of collaborative innovation in knowledge work.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='In the sections below we will conduct technical and theoretical comparison of Conversational AI versus Cognitive AI, for the purpose of knowledge work. We will show that LLMs are neither practically or theoretically capable of meeting the needs of knowledge work. While they may contribute to knowledge work by simulating aspects of these cognitive processes, these simulations have inherent limitations that cannot be overcome. The solution we propose is Cognitive AI, which is a new evolution of AI that performs higher-level cognitive processing, by harnessing the benefits of LLMs without being limited by their weaknesses.\\n\\nDefining Conversational AI' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Conversational AI is a form of artificial intelligence based on conversations between agents. Here agents can be software agents or human agents. To be more precise, Conversational AI is a form of AI based on conversations which include at least two agents, where one is a software agent.\\n\\n8\\n\\nIn Conversational AI agents communicate through streams of tokens, using Large Language Models (LLMs) to mediate their interactions. LLMs use underlying probabilistic models to generate token strings in response to token strings.\\n\\nFigure 1. Token Streams\\n\\nThe fundamental units of Conversational AI are conversations or chats, which are streams of messages between agents.\\n\\nFigure 2. Chats' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The user-facing manifestation of Conversational AI is manifest as a “chatbot,” which is an application that executes a simple linguistic circuit between a software agent playing the role of the “bot” and a human user (or another software agent) that communicates with it.\\n\\nFigure 3. Chatbots.\\n\\n9\\n\\nBy adding additional components to these circuits, they can make use of external data in the form of vector embeddings, and queries against vector databases, to augment the training of the underlying model at runtime. This makes these circuits able to incorporate new information that is not in the original training of the underlying LLMs.\\n\\nFigure 4. Retrieval Augmented Generation (RAG).' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='It is also possible to create multi-agent systems in which LLM-powered agents can engage in dialogs with each other (and optionally also with humans).\\n\\nFigure 5. Multi-agent dialogs.\\n\\nThe process of Conversational AI, using state-of-the-art foundation models such as OpenAI’s GPT 4 plus vector embeddings, enables a surprisingly powerful level of interactive artificial intelligence which is capable of answering questions and generating useful content about an infinite range of topics and data.\\n\\n10\\n\\nHowever, while Conversational AI achieves virtually unlimited breadth on simple tasks, the depth of its intelligence on more complex tasks is limited.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Conversational AI is a form of “first-order intelligence” that generates responses using LLMs, without understanding, reasoning or reflecting on anything (Thórisson et al., 2016)\\n\\nUsing “prompts,” and “prompt-engineering” methodologies it is possible to use language to guide the behavior of LLMs, in order to cause them to generate more specific outputs for various kinds of inputs. Prompts, like all messages between agents and the LLM, are saved to a “chat transcript” for an interaction session.\\n\\nThe “chat transcript” is a history of messages between agents, along with any added external information.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Chatbots operate with finite history. The “context” of a chat is defined as the set tokens that an LLM is given as input in order to generate a completion as output. Context cannot be longer than the maximum number of tokens an LLM can accept in a single input. In a chatbot application, the interaction between agents and the LLM proceeds in a series of interleaved messages that constitute a “dialog.” Messages, and dialogs composed of them, can be any length under whatever token length constraints are in effect.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The “token window” is the maximum number of tokens that can be provided as context to an LLM. In a dialog that produces a stream of tokens that exceeds the maximum number of tokens that the LLM can read in a single input, the token window is a moving window in the transcript, and is provided to the LLM as context for each input.\\n\\nUsing these basic constraints, Chatbots can generate dialogs that appear to be the products of intelligence and reasoning. However, in such dialogs only the subset of messages by human agents (such as a human user) involve any reasoning. Messages produced by the chatbots, which are generated by the LLM model, are in fact purely probabilistic streams of guesses which do not involve any understanding or reasoning.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='It is a common misconception that chatbots understand what they say, or what users say, or what dialogs are about. In fact, for any given input such as a message from a human user, the chatbot simply uses the probabilistic weights in the underlying LLM to generate and return a stream of tokens that are correlated with the input above a certain probability threshold.\\n\\nInstead of reasoning, Conversational AI applications generate statistical responses that seem to be the products of cognition, but are in fact only the products of non-cognitive intelligence that emerges from probabilities based on the numeric weights of the underlying models, which in turn are a consequence of their training and the data they were trained on.\\n\\n11' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Conversational AI is essentially a form of advanced mimicry of the cognitive processes, based on probabilistic models. Inherent in this fact are many inescapable built-in limitations which we will explore later in this paper.\\n\\nIntelligence Versus Cognition\\n\\n“Intelligence” can be defined as the set of all systems that generate non-random output information in response to non-random input information. This is quite a broad definition, in which even physical processes and mathematical functions and formal systems can be considered to be forms of intelligence.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Within intelligence, the class of systems that are equivalent to Turing Machines conduct computations. Within the set of computations, machine learning systems exhibit the ability to make predictions based on learning. Likewise, computations that perform artificial intelligence generate outputs that more closely resemble those that humans can generate.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='“Cognition” is a specific subset of intelligence, where the processing that systems do to transform inputs to outputs closely mirrors human cognitive processing. Within the scope of cognition, there are a number of critical cognitive processes that can take place, including learning and self-improvement, sensing, self-reflection and introspection, language understanding and processing, memory and context management, knowledge representation, knowledge management, knowledge processing, research and exploration, reasoning, planning, decision making, project management, and task execution.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='LLMs produce outputs from inputs that seem to be the products of cognition. The linguistic (or visual, auditory, data) structures they generate are highly contextually relevant and appropriate responses to the meanings of the inputs they receive.\\n\\nFrom a “black box” perspective - without knowing how LLMs work - one might assume they understand, reason, and even can be creative. However no cognitive activity is actually taking place within LLMs. They have no understanding of what is being said and they do not think, they merely process probabilities. However, despite this, LLMs produce surprisingly good responses that appear to be the products of cognitive processing, in other words they do a good job of mimicking cognition.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='LLMs, and all Conversational AI systems, are classified as intelligent, but not cognitive, because they perform probabilistic natural language processing and response generation, but they do not actually perform higher level cognition.\\n\\n12\\n\\nInstincts Versus Abstract Reasoning' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The distinction between the operational mechanics of Large Language Models (LLMs) and the advanced functionalities of Cognitive AI highlights a fundamental divide between different forms of artificial intelligence: instinctual intelligence versus abstract cognitive reasoning. This divide not only characterizes the limitations and capabilities of these AI systems but also underscores the evolutionary trajectory from simple pattern recognition to complex cognitive processing.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='LLMs operate on what can be described as \"instinctual intelligence” in which responses are instinctual, meaning that they are provided automatically without any intermediate thinking or reasoning. Like instincts, which are innate, non-adaptive responses triggered by specific stimuli, LLMs respond to inputs based on patterns learned during their training phase. This process is inherently non-adaptive; LLMs cannot learn, reason, or change in real-time. Their responses, while sophisticated and often convincingly human-like, are limited by their training, lacking the capacity for live, on-the-fly learning or adaptation.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The interaction with an LLM, therefore, does not involve any genuine learning or memory integration. Responses generated during an LLM\\'s operation are the result of processing input patterns against a static model, with no new information retained or integrated into the model\\'s \"knowledge\" post-training. Even with the introduction of embeddings to augment LLM responses at runtime, the LLM processes these probabilistically, without engaging in actual learning or thought.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"In stark contrast, Cognitive AI embodies the principles of abstract reasoning and second-order learning, engaging in a continuous loop of learning and adaptation even during runtime. Unlike the static, instinctual responses of LLMs, Cognitive AI's architecture allows for the accumulation of new knowledge, adjustment of strategies based on live feedback, and genuine reasoning about the content it processes. This dynamic capability enables Cognitive AI to not just simulate reasoning but to actually reason, learn from interactions, and evolve its understanding and responses over time.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Cognitive AI's approach to problem-solving and interaction is underpinned by structured knowledge and reasoning algorithms, facilitating a level of analysis, decision-making, and creativity far beyond the capabilities of LLMs. This not only allows for more accurate and contextually relevant responses but also supports the system's ability to engage in genuine abstract reasoning, drawing inferences, and generating hypotheses beyond the immediate input patterns.\\n\\nIt is expected that all of the major foundation models will continue to evolve and develop higher levels of world knowledge, comprehension, reasoning, user interaction, tool utilization, and\\n\\n13\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='self-improvement. However, these capabilities will still be mimicry as opposed to actual cognition.\\n\\nWhile LLMs can offer powerful artificial intelligence capabilities through simulated reasoning, producing responses that are often surprisingly apt, the inherent limitations of this approach become apparent as the complexity of tasks increases. The inability to learn or adapt in real-time, coupled with a lack of genuine understanding or reasoning, places a ceiling on the intelligence that LLMs can achieve.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"In contrast, Cognitive AI's capacity for abstract reasoning, continuous learning, and dynamic adaptation represents a significant leap towards overcoming these limitations, pointing the way towards more sophisticated, versatile, and genuinely intelligent AI systems.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The evolution from the instinctual intelligence of LLMs to the abstract cognitive reasoning capabilities of Cognitive AI marks a pivotal shift in artificial intelligence. By transcending the bounds of pattern-based responses and embracing the complexities of genuine learning and reasoning, Cognitive AI paves the way for AI systems that can engage more deeply with the world, solve more complex problems, and, ultimately, approach the elusive goal of Artificial General Intelligence. This shift from simulated reasoning to genuine cognitive processing defines the next frontier in AI, promising advancements that could redefine our understanding of what machines are capable of achieving.\\n\\nDefining Cognitive AI' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Cognitive AI is a subset of artificial intelligence in which a cognitive layer executes neuro-symbolic cognitive processes that are modeled on individual and collective human cognition, by making use of a Cognitive Layer that uses a Conversational Layer.\\n\\nThe distinction between Conversational AI and Cognitive AI is precisely that Cognitive AI does not merely mimic cognition, rather it executes formal cognition outside of the underlying LLM models it uses. Therefore Cognitive AI is classified as both intelligent and cognitive.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"By implementing the cognitive processes of the human mind, as well as collective intelligences of groups of humans, Cognitive AI is capable of self-directed thought and the orchestration of its cognitive processes, essentially enabling it to manage its knowledge work autonomously.\\n\\nCognitive AI transcends traditional AI's focus on pattern recognition and probabilistic predictions by incorporating a second layer of intelligence: meta-cognition. This advanced cognitive layer enables the AI to engage in genuine reasoning and learning from experiences, allowing for strategic adaptations in real-time. Such capabilities enable Cognitive AI to tackle complex, dynamically changing problems far beyond the reach of current LLMs.\\n\\n14\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Figure 6. Conversational Versus Cognitive AI Quadrants.\\n\\nCognitive AI Functional Architecture\\n\\nCognitive AI represents a paradigm shift, moving beyond the confines of Conversational AI's reliance on probabilistic reasoning simulations to actual programmatic reasoning. This shift is embodied in a dual-layer architecture that elevates reasoning, self-improvement, and adaptability to second-order intelligence, fundamentally distinguishing Cognitive AI from its predecessors. Below we will discuss the functional architecture and formal requirements for Cognitive AI systems.\\n\\nFunctional Requirements for Cognitive AI\\n\\nTo qualify as Cognitive AI, a system must be architected to meet the following functional criteria:\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='1. Dual-Layer Cognitive Architecture. The system is organized into at least a dual-layer architecture, in which a Cognitive Layer that supports higher-level cognitive functions sits above a Conversational Layer that provides services equivalent to a general-purpose large language model.\\n\\n15\\n\\n2. Large Language Models. The system must provide and utilize one or more large language models (LLMS), or other similarly powerful and general alternative probabilistic models, in the Conversational layer, where at least one model is closely comparable to a large general purpose foundation model (such as GPT 4).' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='3. Cognitive Agents. The system must be architected with agentic design patterns and principles as an agentic application that provides intelligent cognitive agents which can operate semi-autonomously or fully autonomously, and where such agents are controlled and executed from outside of LLM transcripts, by an agent management function implemented as executable software.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='4. Relationship Management. The system must enable the formation, management and use of social relationships to connect agents (including humans and software agents) on a one-to-one and one-to-many basis. Inter-Agent Messaging. The system must enable natural language interactive messaging communication and the sharing of system objects (documents, knowledge, tools, data, agents, projects, plans, etc.) between agents that are directly or indirectly connected by mutual relationships.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='4. Relationship Management. The system must enable the formation, management and use of social relationships to connect agents (including humans and software agents) on a one-to-one and one-to-many basis. Inter-Agent Messaging. The system must enable natural language interactive messaging communication and the sharing of system objects (documents, knowledge, tools, data, agents, projects, plans, etc.) between agents that are directly or indirectly connected by mutual relationships.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='6. Dialogs. The system must utilize interactive internal and external dialogs between two or more agents, where agents can be software-based or humans, and where in any dialog there is at least one software agent, and where dialog formats and execution can be structured and controlled with conditional logic rules..\\n\\n7. Planning. The system must be able to generate, understand and respond to complex conditional workflows as plans in natural language.\\n\\n8. Project Management. The system must provide a project management function to orchestrate and manage execution of plans by one or more agents.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='9. Neuro-Symbolic Reasoning. The system must support generation of explicitly defined workflows for controlling both informal natural language reasoning and formal logical reasoning, where such workflows are executed and controlled from within the Cognitive Layer instead of from within the Conversational Layer.\\n\\n10. Memory Retrieval. The system must be able to utilize its own planning and reasoning mechanisms to intelligently guide strategies for locating and retrieving relevant information and knowledge for a given context, across internal knowledge bases, long-term memory, and external data sources including the Internet.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='11. Context Management. The system must manage context for agents and cognitive processes using a working memory to cache and swap relevant contextual information from long-term memory, in order to optimize relevancy of information in context against finite token windows of LLMs.\\n\\n12. Knowledge Discovery. The system must conduct intelligently guided natural language and Boolean search, as well as deeper research strategies guided by agents (such as intelligently guided spidering for relevant information) to locate relevant information and knowledge across heterogeneous data sources (internal knowledge bases, long-term memory stores, and external resources including the Internet and third-party APIs).\\n\\n16' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='13. Knowledge Management. The system must explicitly generate, learn, represent, store, retrieve and maintain formal data structures for representing knowledge that exist outside of LLMs.\\n\\n14. Tool-Utilization. The system must have the ability to design and use tools in the form of software applications, APIs, and internal and external data sources. Tool-utilization also applies to a system being able to self-referentially utilize its own functional components as tools, to design and implement new tools, and to improve tools.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='15. Mathematics and Computation. The system must have the ability to do mathematical and computational operations outside of LLMs, using software, data sets, and computing hardware and infrastructure. This also provides the system with advanced formal logical processing, scientific and financial calculation abilities, as well as data science and analytics and machine learning capabilities.\\n\\n16. Multi-Agent Collaboration. The system must have the ability to orchestrate collaborative processes between human agents and software agents. This includes one-to-one, one-to-many, many-to-one, and many-to-many collaborative processes.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='17. Meta-Cognition. The system must provide a meta-cognition function that can be utilized across all major cognitive functions of the system, and is capable of knowledge processing, introspection, meta-reasoning, reflection, learning, and self-optimization.\\n\\n18. Self-improvement. The system must be able to engage in recursive goal-directed self-improvement, if and when needed, across all major cognitive processes, to iteratively optimize reasoning, knowledge, projects, plan, dialogs, agents, documents and code, both asynchronously and during runtime execution.\\n\\nDual-Layer Architecture' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"At the core of Cognitive AI's functional architecture is an intelligence stack comprising two critical layers: a Cognitive Layer and a Conversational Layer.\\n\\nThe Conversational Layer operates on the principles familiar to LLMs (Large Language Models), processing and responding to linguistic inputs. Positioned above this, the Cognitive Layer introduces meta-cognition capabilities, extending the system's functionalities beyond mere linguistic processing to encompass higher-order cognitive processes.\\n\\n17\\n\\nFigure 7. Cognitive AI Functional Architecture\\n\\nThe above diagram illustrates the functional architecture of Mindcorp’s Cognition platform for Cognitive AI and can serve as general model for how Cognitive AI architectures are designed.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The Cognitive Layer is where Cognitive AI truly differentiates itself. It provides the system with the ability to engage in meta-cognition (also called meta-cognition), in which it can engage in introspection, enabling a deeper level of understanding and optimization of its own processes. This functional area allows Cognitive AI to critically assess its methodologies for learning, reasoning, planning, and decision-making, mirroring the cognitive functions of the human mind engaged in complex knowledge work.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Through meta-cognition, Cognitive AI can refine and adjust its strategies at runtime, responding dynamically to new information and challenges. This adaptability is crucial for applications requiring not just an understanding of data but also the capacity to apply strategic thinking and creativity to solve problems.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The integration of meta-cognition equips Cognitive AI systems with the unique ability to self-assess their thought processes and learn from their interactions. This self-assessment capability ensures that Cognitive AI can continually refine its operational strategies, enhancing its efficiency and effectiveness over time. By continuously learning from its actions and the outcomes of its decisions, Cognitive AI can evolve its approach to problem-solving, ensuring that it remains effective in the face of changing conditions and requirements.\\n\\n18' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The architectural distinction of Cognitive AI, characterized by its dual-layer approach in which meta-cognition plays an important role, marks a significant advancement in the field of artificial intelligence. This cognitive structure not only enables Cognitive AI to process information linguistically but also empowers it with the ability to reason, plan, and improve itself autonomously.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='By mirroring the cognitive processes of the human mind and incorporating the capacity for self-reflection and adaptation, Cognitive AI opens new avenues for solving complex problems, making it a powerful tool for real-world knowledge work and beyond. This architectural innovation lays the foundation for a new generation of AI systems capable of more sophisticated, adaptable, and effective problem-solving strategies, setting Cognitive AI apart from traditional Conversational AI technologies.\\n\\nLarge Language Models' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Large Language Models (LLM’s) are a class of probabilistic language models, generally based on an attention-based transformer algorithm for predicting next tokens from a stream of previous tokens. These models are trained to make predictions that correspond to the knowledge inherent in the training data sets and fine-tunings may also be added.\\n\\nFigure 8. Leading LLM Models. Source: Minaee, S., et al., (2024).' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The large foundation-level LLMs generate streams of tokens that contain sophisticated linguistic responses to streams of tokens. These responses are so similar to the kinds of intelligent responses that humans can generate, that the underlying LLM’s are also said to be highly intelligent. However, as this paper will make exceedingly clear, there is a difference between intelligence and cognition. LLMs may be highly intelligent, but they are not cognitive at all, and this ultimately is their weakness.\\n\\n19\\n\\nFigure 9. LLM Capabilities. Source: Minaee, S., et al., (2024).' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The above diagram illustrates the current and emerging state of LLM capabilities. The diagram shows the capabilities of LLMs projected to be advancing into comprehension, reasoning, tool-utilization, social interactions, and self-improvement.\\n\\nHowever it is important to note, and one of the main points of this paper, that within the context of LLMs, there is no actual comprehension, reasoning, tool-utilization, social interactions or self-improvement taking place. While the LLMs are very good at mimicking these processes to participate in simple conversations and generate basic documents, their ability to do so is shallow and falls apart quickly when problems get longer and/or multilayered and complex.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Despite the limitations of LLMs, they are the critical prerequisite for Cognitive AI. The language-level intelligence of LLMs is indispensable for Cognitive AI systems to function. However, in Cognitive AI systems the LLMs are not used to implement complex reasoning directly using language; instead complex reasoning and procedures are implemented on the Cognitive Layer, above the LLMs.\\n\\nCognitive Agents\\n\\nThe genesis of Cognitive AI can be traced back to the burgeoning interest in agentic applications that operate above the LLM layer. Chatbots are the most widely-known example of the agent paradigm in the context of AI, but there are many other kinds of agents that can use LLMs without necessarily chatting or communicating with end-users.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='20\\n\\nThese applications, characterized by their ability to complete tasks via one or more LLM-powered agents collaborating with a human and/or even with one another, mark the first steps towards transcending the limitations of LLM-driven models.\\n\\nWhile initial forays into agentic AI have been focused on relatively simple tasks such as chatbots and various iterations of agents built on them, including agents that conduct online research, engage in social media, and complete simple online tasks, they lay the groundwork for more sophisticated, intelligent systems capable of complex decision-making and problem-solving.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='As Cognitive AI begins to emerge, new agentic architectures and applications are forming above the LLM layer that do conduct rudimentary cognitive processing. In these platforms and applications, multi-agent systems provide agents that collaborate and/or compete to solve problems, using LLMs to think and converse within procedures that guide and channel this activity to perform forms of cognition.\\n\\nFigure 10. LLM-Based Multi-Agents. Source: Guo, Taicheng et al., 2024.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The diagram above illustrates the current state of the art in LLM-based multi-agent systems, where we observe a high degree of fragmentation across many competing approaches. This area of development is moving rapidly, but there is no common platform or any commonly accepted standards for agentic applications, inter-agent communication, or agents.\\n\\n21\\n\\nBelow we illustrate what a complex multi-agent application might look like, at a high-level, for an example agentic “IP monetization” application:\\n\\nFigure 11. Agent Collaboration Platform' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='In the above example, several teams of agents collaborate with individual humans and teams of hums to conduct an IP development process. This is a highly advanced scenario. Most agentic LLM applications involve a single human delegating to multiple agents (single human, multiple agents: “SHMA”), for simple and relatively low-level task-automation scenarios like Web research. However in our own work (not yet released publicly, at time of this writing), we have implemented and tested a new agentic platform that is tailored for more advanced multi-human-multi-agent (multiple human, multiple agents: “MHMA”) applications like this example.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Beneath this application are layers of modules, for example, the IP Development Agents team in the above diagram is a module that might function like the diagram below:\\n\\n22\\n\\nFigure 12. IP Development Team Module.\\n\\nAnd below this level, each agent is a module - for example, the IP Developer Agent:\\n\\nFigure 13. IP Developer Agent\\n\\nAnd below this layer there are skills or sub-capabilities of each agent, for example:\\n\\nFigure 14. Innovation Component\\n\\nBut while agentic architectures are highly modular and well-suited to leveraging the capabilities of Large Language Models (LLMs), not all agentic applications rise to the level of full Cognitive AI.\\n\\n23' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Only agentic applications, where agents are implemented outside of LLM transcripts, and where meta-cognition is utilized across all major cognitive functions, qualify as Cognitive AI.\\n\\nWhile LLMs themselves can mimic the behavior of individual agents and communities of agents, there is a difference between linguistically simulated agents that exist only as language within the transcript of an LLM chat, and programmatic intelligent agents that operate as executable code on a multi-agent platform above and outside of a chat transcript. The latter not only has more degrees of freedom in how they think and interact, but they can also make use of external code.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='In the paradigm of Cognitive AI, agents exist outside of LLMs, but use LLMs for their linguistic and basic intelligence functions. In this way they utilize, but are not bound by, the limitations of LLMs. They are free, for example, to use multiple models, including other forms of machine learning and reasoning when needed.\\n\\nThe coming technical breakthroughs that enable Cognitive AI will have profound implications for the deployment of AI across various sectors. By enabling systems to understand and adapt their strategies, Cognitive AI will open new possibilities for innovation and problem-solving.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='These adaptive capabilities ensure that Cognitive AI applications will continue to evolve and will remain relevant and effective in the face of changing data landscapes and problem sets, setting a new standard for what AI can achieve.\\n\\nRelationship Management, Inter-Agent Messaging and Dialogs\\n\\nCognitive AI thinks and reasons on at least two layers at once:\\n\\nThe Conversational Level simulates cognition linguistically against a trained probabilistic model.\\n\\nThe execution of explicit reasoning projects and plans by agents on the Cognitive Level constitutes programmable workflows that can model any informal or formal cognitive process.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='By combining these two modalities a more powerful and flexible level of cognitive processing is possible than can be achieved by either on its own.\\n\\nWhere these two modalities intersect is in the process of dialogs. In Cognitive AI, dialogs are turn-based natural language inter-agent messaging conversations which take place between two or more agents, in which at least one participant is a software agent. A necessary precondition for inter-agent messaging and dialogs is a means for agents to form and manage inter-agent relationships.\\n\\n24' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='There are two kinds of dialogs: external and internal dialogs. External dialogs take place between an agent and other agents that are external to its own private cognitive workspace. For example, a chat between a CTO Agent and a CFO Agent. Internal dialogs take place inside the scope of an agent’s private cognitive workspace.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='An internal dialog is a conversational process between two or more agents which takes place within a single agent’s mindsteam. Within the cognitive workspace of an agent, sub-agents can be instantiated as needed, to represent facets of the subconscious processing of that agent. This effectively enables an agent to \"talk to itself” and “cognitate internally” in order to self-reflect before generating a response or behavior. This form of internal discourse is critical for fostering deeper critical thinking, introspection, and analysis, within intelligent agents and across Cognitive AI architectures.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Through internal dialogs, Cognitive AI agents can meticulously develop, assess, and refine strategies and plans by applying dialectical processes between “subconscious agents” within its own virtual mind. This reflective and dialectical process enables a system to critique its own thinking, identify potential improvements, and iterate on its strategies before it puts them into practice as a response to some stimulus. Responses of this nature are far beyond the instinctive responses of LLMs. Internal dialogs, while not always required, can be used to ensure that responses are not only well-considered but also optimized for effectiveness and efficiency, embodying a level of strategic foresight comparable to human intelligence.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The process of internal dialogs for reasoning and adaptation in Cognitive AI is cyclical, constituting a continuous loop of self-improvement. This loop enables the system to evolve its problem-solving methodologies over time, ensuring that its approaches are not only effective but also increasingly sophisticated. By engaging in this ongoing process of introspection and self-modification, Cognitive AI systems can achieve a dynamic state of growth and learning, mirroring the evolutionary nature of human cognitive development.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The ability of Cognitive AI to evolve new and improved problem-solving strategies through introspective self-dialog and self-optimization, is critical for applications that require more than mere computational power. This capacity for sophisticated understanding and strategic planning, akin to human cognitive abilities, allows Cognitive AI to tackle complex tasks with a depth and efficiency that surpass the capabilities of Conversational AI.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Another key function of dialogs is group conversations. In Cognitive AI, group conversations are structured by plans that serve as their agendas, and they are facilitated by at least one software agent, for a group of two or more other agents. Cognitive AI agents are able to generate and leverage best-practices group processes for a variety of collective cognition tasks such as brainstorming, content development, research and analysis, strategic planning, design and development, innovation, feedback and reporting, and decision-making.\\n\\n25' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='One of the more powerful applications of group conversations is the use of groups of agents with diverse specializations and skills to model collaborative multi-disciplinary teams and their collective cognition. In Cognitive AI, the practice of applying multi-disciplinary teams of agents is a routinely used mechanism during execution of projects and plans.\\n\\nFor example, during a particular step of a plan in a market research project, a team of agents can be assembled to discuss a market segment, where each agent brings unique knowledge, heuristics, and skills to the table. The team can then engage in a structured conversation, where each agent represents its unique perspective, to arrive at a richer understanding together.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Planning and Project Management\\n\\nLLMs have been shown to have limited planning capabilities and in recent benchmarks they still have much room for improvement. (Valmeekam, K. et al., 2023). LLMs also fail at over-the-horizon reasoning, where there are long complex chains of potential solutions, only some of which are optimal or even solutions at all.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Kambhampati, S. et al. have argued persuasively that “LLM’s can’t plan” because, for example, LLMs can neither guarantee the generation of correct plans, nor the verification of correct plans. Planning with LLMs is not equivalent to exhaustively searching for valid optimal paths in a solution space, but instead is more like generating plans by borrowing from previously seen plans – an approach which is not systematic.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"The ability to strategize and plan thinking processes underpins a wide range of capabilities critical to Cognitive AI, including reasoning, research, analytics, decision-making, project management, and task orchestration. By embedding formal planning capabilities into the fabric of Cognitive AI's operations, these systems can tackle sophisticated challenges that require not only raw computational power but also nuanced, strategic thinking.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"At the core of Cognitive AI's planning function is the ability to generate plans which are formal conditional workflows for agents to participate in. These workflows guide the collective cognition and behavior of intelligent agents, and optionally human collaborators as well, by channeling their interactions and reasoning through structured processes that guide them towards goals. This capability is essential for orchestrating the efforts of multiple entities, ensuring that each contributes effectively to the task at hand, based on their unique strengths and capabilities.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='More specifically the plans generated by Cognitive AI may include formally specified plans, using a formal plan reasoning language such as PDDL. By integrating PDDL, or languages like it, into Cognitive AI systems, it becomes possible to conduct formal search, analysis, validation and optimization of plans, against formally specified problem domains, using first order predicate logic.\\n\\n26' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='By combining this level of formal reasoning about plans with the informal language understanding and generation of the LLMs, a more sophisticated form of plan generation and refinement becomes possible, where the LLM generates potential plans with natural language, which are then transformed into formal logic, and which are next formally evaluated and improved, in order to yield better plans, with are finally translated back into natural language.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The plans developed by Cognitive AI systems are not rigid scripts but adaptive strategies that respond to changing conditions and new information. By programmatically channeling the collective thinking processes of teams of agents and humans, Cognitive AI can navigate complex problem spaces with agility and precision. This approach allows for the optimization of cognitive resources, ensuring that tasks are approached in the most efficient and effective manner possible.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Supplementing its planning capabilities, Cognitive AI incorporates full project management functionalities. Project management allows a system to not only devise and initiate plans, but also to monitor their progress, adjust execution at runtime, and manage resources effectively. Through comprehensive project management, Cognitive AI can engage in complex, multi-step, and long-term or ongoing knowledge work.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"This integration of planning and project management enables Cognitive AI to orchestrate complex endeavors, from initial strategy formulation to the successful completion of objectives. It represents a holistic approach to tackling knowledge work, where the system's cognitive functions are leveraged to plan, manage, and execute projects with a level of sophistication and adaptability previously unattainable.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The planning and project management capabilities of Cognitive AI mark a significant advancement in artificial intelligence. By enabling dynamic, real-time strategizing, planning and execution, supplemented with comprehensive project management tools, Cognitive AI systems can effectively orchestrate complex collaborative knowledge work and knowledge-based business processes. This not only enhances the efficiency and effectiveness of cognitive work but also expands the possibilities for what AI can achieve, setting a new standard for intelligence in technology.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Cognitive AI's ability to integrate meta-cognition across planning and project management also enables a higher level of control and sophistication in reasoning and adaptation that is essential for complex problem-solving and knowledge work. Complex reasoning in Cognitive AI is the result of applying systems of agents to solve abstract problems, using projects and plans to do so. In other words, in Cognitive AI, complex reasoning is a cognitive process that uses projects and planning to control and manage multi-agent reasoning and behavior.\\n\\nIn Cognitive AI, planning and project management are central cognitive functions. These advanced AI capabilities are not only about creating, executing, and adapting strategies and\\n\\n27\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"plans in a static sense, but dynamically doing so in real time, as agents engage in cognitive processes. This dynamic planning capability is fundamental to the ability of agents to navigate and manage complex tasks, embodying a leap beyond traditional AI's capabilities.\\n\\nNeuro-Symbolic Reasoning\\n\\nIt has been argued above that LLM’s are not capable of complex reasoning, however even naive logical reasoning within LLMs is prone to failures. For example, they are prone to the “reversal curse” (Berglund, L., et al., 2023) where if told that “A is B”, they may fail to infer that “B is A”, and in addition they often fail on even simple set operations, such as three set logical unions (Yang, J. et al., 2023).\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='For larger, more complex reasoning processes that are longer than the context window or token limit, LLMs cannot natively mimic complex reasoning because they cannot maintain context or state beyond the limits of their token limits. Furthermore, because of their proactive nature, LLMs cannot reliably implement complex reasoning in a deterministic manner; they are prone to hallucinations and unpredictable outputs and they may or may not always follow plans they are given.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Cognitive AI addresses these challenges by offering a neuro-symbolic solution that combines deterministic and programmatic control of reasoning and planning, which are executed outside the token window of an LLM, with the non-deterministic, probabilistic conversations that take place inside the token window.\\n\\nFurthermore Cognitive AI can generate, validate, and optimize these external reasoning flows using formal symbolic processing and computation. In other words, Cognitive AI systems combine the “neuro” capabilities of LLMs with the “symbolic” capabilities of pre-LLM generations of AI, such as formal symbolic logic process, solvers, formal planners, formal reasoning engines and non-axiomatic reasoning methods (cf. Latapie et al., 2023).' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='This hybrid approach enables Cognitive AI systems to navigate complex reasoning tasks with greater precision and reliability. By integrating both deterministic and non-deterministic methodologies, Cognitive AI can leverage the strengths of each, resulting in a reasoning capability that is more powerful and versatile than either approach alone.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Unlike LLMs, which rely on language simulation to approximate thinking, Cognitive AI systems employ programmatically structured, organized, and managed thought processes. This programmatic control extends to the execution of projects and plans, allowing Cognitive AI to engage in complex autonomous reasoning. This structured approach to thinking and reasoning enables Cognitive AI systems to process and analyze information in a manner that aligns more closely with the requirements of sophisticated cognitive tasks.\\n\\n28' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Cognitive AI further enhances its reasoning capabilities by channeling conversational AI through agents that employ projects and plans to control their behaviors. This enables the collaborative and complex autonomous reasoning necessary for high-level knowledge work. By combining deterministic programmatic control with the flexibility and adaptability of non-deterministic conversational AI, Cognitive AI can tackle complex problems with both precision and creativity.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Another important aspect of reasoning in Cognitive AI is the capacity to construct and reason about formally defined systems of rules. These systems of logical rules can be processed with first-order predicate logic in symbolic processing modules, such as theorem provers, graph search algorithms, and reasoning engines.\\n\\nAgents in Cognitive AI systems can execute, manage and improve, goal-directed projects and actions, under formal systems of rules. This enables such systems to intelligently, discover, reason about, and improve their own solution paths as they work, and adapt to change.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"The reasoning capabilities of Cognitive AI represent a significant advancement over traditional conversational AI systems. Through the integration of reflection, planning, and programmatic control, Cognitive AI can navigate complex cognitive tasks with a level of sophistication and effectiveness unmatched by LLMs alone.\\n\\nThis approach to reasoning not only enhances the system's ability to perform complex problem-solving but also positions Cognitive AI as a critical tool for advancing knowledge work and other applications requiring nuanced, intelligent analysis and decision-making.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Cognitive AI's unique combination of deterministic and non-deterministic reasoning processes establishes a new benchmark for what artificial intelligence systems can achieve in terms of autonomous reasoning and cognitive collaboration.\\n\\nMemory Retrieval and Context Management\\n\\nA defining feature of Cognitive AI, distinguishing it from Conversational AI, is its advanced capability for contextual understanding and memory, enriched by the integration of concepts akin to human working memory and long-term memory. This sophisticated memory system enables Cognitive AI to handle information dynamically and strategically, offering a substantial edge in complex problem-solving and nuanced decision-making.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Traditional Conversational AI processes each interaction in isolation, limiting its ability to recognize the continuity in ongoing dialogues or projects. Cognitive AI, however, boasts a contextual memory that spans interactions, acting as a dynamic repository of context, insights, and understanding. This system allows it to build upon previous conversations, adapting to context changes over time, and making more informed decisions and responses.\\n\\n29' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Central to how Cognitive AI handles memory is the process of context management, whereby it is able to provide relevant contextual information within finite token windows of LLMs. Context management is encapsulated in a working memory buffer that temporarily holds and manages information that is immediately relevant to the task at hand, akin to human working memory. This feature is crucial for maintaining the context of ongoing interactions, allowing for real-time analysis, reasoning, and the dynamic adjustment of strategies based on immediate feedback. Through working memory, Cognitive AI can juggle multiple pieces of information, drawing on recent data for predictions, problem-solving, or strategy adjustments.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Long-term memory in Cognitive AI mirrors the human capacity to store and retrieve information over extended periods. It enables the AI to accumulate knowledge and experiences, applying historical data to inform future decisions. This capability allows Cognitive AI to recognize patterns, learn from past interactions, and adapt its operational strategies, providing a depth of understanding and strategic foresight that traditional Conversational AI cannot achieve.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The dual-approach to memory—combining working memory and long-term memory—affords Cognitive AI a clear advantage over Conversational AI. While Conversational AI might access databases or follow scripted responses, it lacks the dynamic, context-aware integration of information that Cognitive AI offers. This system not only ensures more accurate, relevant responses in the moment but also enables deeper strategic thinking and learning over time.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Cognitive AI's memory system facilitates anticipation of needs, adaptation to contextual changes, and the delivery of solutions informed by both immediate and historical perspectives. This nuanced approach, mirroring human cognitive processes, allows Cognitive AI to navigate complex interactions and problem spaces with unprecedented depth of understanding and adaptability.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The integration of contextual understanding and memory, incorporating working memory and long-term memory, into Cognitive AI systems marks a significant evolution in artificial intelligence. This advancement allows Cognitive AI to operate with sophistication and adaptability, navigating complex challenges with strategic insight and efficiency. By leveraging both immediate and accumulated knowledge, Cognitive AI sets a new standard for AI-driven applications, offering sophisticated, adaptable, and effective solutions that far surpass the capabilities of traditional Conversational AI.\\n\\nKnowledge Discovery and Knowledge Management' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='A foundational element distinguishing Cognitive AI from conventional Conversational AI is its approach to knowledge representation and knowledge management (KM). This functional area transcends the capabilities of Large Language Models (LLMs) in handling knowledge, by explicitly creating, managing, and enhancing structured knowledge representations such as knowledge bases, knowledge objects, knowledge catalogs, knowledge graphs, taxonomies and\\n\\n30\\n\\nontologies. These knowledge representation components are pivotal for the sophisticated operation of Cognitive AI, enabling it to process, understand, and interact with information in a more nuanced and contextually relevant manner.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Unlike LLMs, which rely on pattern recognition and data-driven learning without an explicit structure for organizing knowledge, Cognitive AI systems are meticulously designed to construct and utilize knowledge representations, which are data structures not merely streams of natural language. The ability to process knowledge representations mirrors human cognitive processes, facilitating the AI's ability to draw connections, identify patterns, and efficiently access relevant knowledge.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Cognitive AI incorporates LLMs not as standalone entities but as integral tools that enrich the Knowledge Management process. LLMs are employed to understand, summarize, expand, and filter knowledge within Cognitive AI's knowledge bases. This symbiotic relationship between LLMs and Cognitive AI's structured Knowledge Management functions allows for the generation of rich metadata, the improvement of searchability, and the discovery and creation of new knowledge representations, which are processes that LLMs alone cannot replicate. By utilizing LLMs in this capacity, Cognitive AI systems can maintain a dynamic and ever-evolving knowledge base.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"At the core of Cognitive AI's Knowledge Management is the function of knowledge discovery and improvement, a process that involves the active location, extraction and discovery of new insights based on accumulated information. As information (including raw data and information, and knowledge structures themselves) is added, additional knowledge can be extracted or inferred, including new metadata, new knowledge representations, and new relationships between existing representations. This function signifies Cognitive AI's ability to not only organize existing knowledge but also to continuously refine and expand its understanding through the integration of newly sourced data. The strategic use of LLMs in this context enhances Cognitive AI's\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='capability for complex problem-solving and informed decision-making.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The capacity for research and information exploration marks another critical aspect of Knowledge Management in Cognitive AI. Beyond mere keyword matching, Cognitive AI systems deploy advanced algorithms to delve into queries against multimodal datasets, using their understanding of contexts, goals and intent, to retrieve contextually relevant information. This capability is crucial for tasks requiring domain-specific expertise or the navigation of vast data pools to uncover precise insights or solutions.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Knowledge Management within Cognitive AI architectures is a testament to the sophisticated nature of these systems, enabling them to effectively manage and leverage complex datasets and information structures far beyond the capabilities of LLMs. The integration of LLMs enhances Cognitive AI's ability to organize, access, and evolve its knowledge base, ensuring continuous improvement and relevance.\\n\\n31\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"This comprehensive approach to Knowledge Management not only underscores Cognitive AI's transformative impact on artificial intelligence but also its indispensable role in facilitating complex decision-making, problem-solving, and innovation in various domains. Through its structured yet dynamic Knowledge Management system, Cognitive AI represents a significant leap forward in the pursuit of more intelligent, adaptable, and effective AI solutions.\\n\\nTool-Utilization\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Cognitive AI architectures are designed to support and integrate tool-utilization, which is the capacity for an intelligent system to use, and even create, tools . The cognitive approach to tool-utilization, also called tool-use, represents a significant point of differentiation between traditional conversational AI and the more advanced Cognitive AI systems. While conversational AI can simulate or script the control of tools, it lacks the inherent capacity to truly understand or directly interact with these tools. Cognitive AI, however, embodies tool-use as a core capability, reflecting a deeper layer of intelligence and functionality.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Conversational AI's approach to tool-use is essentially indirect. It can generate scripts or commands that control tools, such as computer programs, but any actual tool interaction must be executed externally. The AI itself remains disconnected from the tangible effects of these tools; it cannot perceive the tool or the results of its use directly. This limitation confines conversational AI to a role of an intermediary rather than an active and aware participant in tool-use.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"In contrast, Cognitive AI is inherently designed for tool interaction. This design extends from the ability to reflexively use its own internal cognitive agents, processes, projects, and plans, treating them as tools within its operational framework. Furthermore, Cognitive AI's capacity for tool-use expands externally, enabling it to utilize a wide array of tools, from Large Language Models (LLMs) to various functions and APIs, effectively extending its capabilities and enhancing its operational efficiency.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='It’s particularly interesting to point out that Cognitive AI can intelligently use external data analytics and machine learning tools to analyze data, make predictions, and generate insights. This even extends to the ability for Cognitive AI to develop or fine-tune LLM models if necessary.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Cognitive AI can, if it needs software it cannot source from elsewhere, is capable of developing its own software tools. It can design, build and execute programs, create datasets, and even operate software-as-a-Service (SaaS) to meet the needs of its projects and tasks. AI code-generation and coding co-pilots already offer dramatic productivity gains for software engineers. However by using a cognitive layer above such tools, it becomes possible to go beyond them – Cognitive AI will be able to autonomously design, build, test, improve, operate and maintain SaaS applications.\\n\\n32' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The tool-use in Cognitive AI involves two critical aspects: the ability to interact with and control the tool and the ability to observe both the tool and the environment to make real-time adjustments. This dual capability allows Cognitive AI systems to engage in a form of meta-tool-use, where they not only utilize tools but also understand and optimize their use based on ongoing feedback and environmental conditions.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Unlike conversational AI, which operates on predefined instructions without the capacity to observe or adjust its actions, Cognitive AI systems possess the autonomy to manage tools actively. They can assess the effectiveness of a tool in real time, adapt their strategies to optimize its use, and even switch between tools as necessary to achieve their objectives. This level of operational adaptability and awareness enables Cognitive AI to perform complex tasks with a degree of precision and efficiency that conversational AI cannot match.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Cognitive AI's ability to utilize external tools, such as LLMs and APIs, signifies a substantial expansion of its operational domain. By integrating these external resources, Cognitive AI can enhance its problem-solving capabilities, access a broader range of information and functionalities, and execute tasks that are beyond the reach of its internal resources alone. This external tool-use not only amplifies the system's capabilities but also demonstrates the system's ability to operate within and contribute to a larger ecosystem of technologies and services.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Tool-use is not just an additional feature of Cognitive AI but a fundamental aspect of its design and functionality. It exemplifies the system's advanced level of intelligence, showcasing its ability to interact with, control, and adapt the use of both internal and external tools in the pursuit of its objectives.\\n\\nTool utilization distinguishes Cognitive AI from conversational AI, highlighting its potential to revolutionize how artificial intelligence systems engage with the world and accomplish tasks. Through integrated tool-use, Cognitive AI sets a new standard for autonomy, adaptability, and functionality in the AI domain, promising to redefine the boundaries of what artificial intelligence can achieve.\\n\\nMathematics and Computation\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='A special area of tool utilization in Cognitive AI systems is the ability to use mathematical software and computing infrastructure as tools.\\n\\nCognitive AI systems must be capable of performing mathematical and computing operations, including writing software and then using that software to execute arbitrarily complex computations. They can also access and utilize any needed external IT infrastructure and data for which they have credentials. These capabilities do not come from the Conversational Layer, but instead are executed using dedicated code or applications for these purposes that either is built-into, or is called from, the Cognitive Layer.\\n\\n33' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='By virtue of this, Cognitive AI systems are able to do arbitrary computations on an as-needed basis, and they can either use existing external tools and services for this, or they can develop software for tools they need.\\n\\nUsing mathematical and computational tools, Cognitive AI systems are capable of harnessing machine learning and data analytics, predictive analytics, financial analysis and modeling, formal reasoning, and mathematical and scientific computing.\\n\\nMulti-Agent Collaboration\\n\\nCognitive AI is inherently collaborative. The ability to interact, communicate and collaborate to conduct knowledge work with other individuals and groups is a key defining factor of higher-order intelligence on the evolutionary ladder.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Drawing inspiration from Marvin Minsky’s “Society of Mind” approach, Cognitive AI's groundbreaking approach to artificial intelligence emphasizes the critical role of social collaboration in cognition, not just as a feature set but as a core mechanism driving many cognitive processes.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Cognitive AI systems enable collaboration between humans and software agents, as well as between software agents and other software agents, in natural language. This is a significant advance from previous pre-LLM agent paradigms where communication between agents was largely programmatic and incomprehensible to non-programmer humans. In Cognitive AI, collaboration between humans and agents requires similar social infrastructure to collaboration between humans – there must be a way for them to message each other and communicate in dialogs, and there must be a way to organize their interactions into topics, projects and plans. The Project Manager function of a Cognitive AI architecture is the intersection where collaboration is organized,' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='managed and executed.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Cognitive AI extends beyond human-AI interactions, encompassing the dynamics between agents, among individuals, and across groups that include both agents and people. By harnessing social interaction and collaboration, Cognitive AI taps into the power of collective intelligence, which is inherently social and collaborative at its core.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"In Cognitive AI, both AI and human agents interact with one another to share knowledge, negotiate tasks, and collaboratively solve problems. These interactions are not merely transactional but can be built upon complex social and reporting mechanisms that allow agents to understand and predict each other's behaviors, seek appropriate approvals, work towards common goals, and optimize collective outcomes. This ability to engage in sophisticated social negotiations, reporting structures and collaborations enhances the agents' effectiveness and contributes to the development of a more nuanced and dynamic form of collective intelligence.\\n\\n34\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Cognitive AI also plays a pivotal role in facilitating and enriching human-to-human interaction. By offering insights derived from its processing capabilities and its understanding of social dynamics, Cognitive AI can facilitate group processes to help human teams communicate more effectively, brainstorm or innovate more effectively, overcome misunderstandings, and make decisions more efficiently. It acts as a mediator and enhancer of human collaboration, leveraging its understanding of group process and group dynamics to foster a more cohesive and productive working environment.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"The interaction between Cognitive AI agents and humans is a hallmark of its social intelligence. Cognitive AI is designed to understand and adapt to human social cues, enabling it to participate in conversations and collaborative efforts as a proactive and responsive partner. This seamless integration of AI into human social contexts allows for a symbiotic relationship where both agents and humans learn from and complement each other's strengths, leading to enhanced creative problem-solving and innovation.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Perhaps most significantly, Cognitive AI facilitates and thrives in mixed groups comprising both AI agents and humans. In these settings, Cognitive AI leverages its social intelligence to navigate the complexities of group dynamics, ensuring that contributions from both AI agents and humans are valued and integrated. This collaborative environment maximizes the benefits of collective intelligence, where diverse perspectives and capabilities are brought together to tackle challenges more effectively than any individual or homogeneous group could.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='At its core, Cognitive AI is built around the concept of collective intelligence, recognizing that the most profound insights and solutions often emerge from collaborative efforts. This collective intelligence is inherently social and collaborative, drawing on the diverse experiences and knowledge bases of its participants. By facilitating and actively participating in this collaborative process, Cognitive AI not only enhances its own cognitive capabilities but also contributes to the collective wisdom of the group.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The integration of social interaction into Cognitive AI represents a transformative advancement in AI technology. By embracing the complexities of social dynamics across various interaction modalities—agent-to-agent, human-to-human, agent-to-human, and in mixed groups—Cognitive AI elevates the potential for collective intelligence.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='This approach acknowledges that the future of intelligence, both artificial and human, lies not just in individual brilliance but in our capacity to collaborate, share, and innovate together. Cognitive AI, with its emphasis on social interaction and collective intelligence, is leading the way toward a future where AI is an integral and enhancing component of the social fabric, propelling us towards more collaborative, intelligent, and creative outcomes.\\n\\n35\\n\\nMeta-Cognition\\n\\nMeta-cognition encompasses a particular set of advanced functions within an intelligent system, whereby the system is able to sense and react to itself through a process of self-reflective introspective reasoning.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='In self-reflective reasoning, the thinking and behavior (including both the internal state and the output) of a meta-cognitive system is sensed by that system, and taken as input for further intelligent processing by that same system about itself. In other worlds, the system thinks about itself and what it is doing in order to improve its composition or behavior.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Implementing meta-cognition across agentic applications is technically difficult and is not a fully-implemented construct in existing agent development frameworks. While such platforms can be used for simple agent introspection and execution planning, they don’t make a higher-order meta-cognitive architecture concrete. To solidify this at a platform level requires new IP, new tools, and new application paradigms. This is both the challenge and the opportunity of Cognitive AI today.\\n\\nMeta-cognition has several fundamental capabilities:' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Knowledge processing - The ability of an intelligent system to detect, transform and generate formal data structures and procedures to represent and reason about knowledge. Introspection - The ability of an intelligent system to detect, transform and conduct knowledge processing on representations of its own composition, state, context, and behavior.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Meta-reasoning - The ability of an intelligent system to use introspection and knowledge processing to represent, transform and generate knowledge about knowledge, and reasoning about reasoning. Reflection - The ability of an intelligent system to apply meta-reasoning during the process of introspection in order to conduct reasoning and/or meta-reasoning about its own composition, state, context and behavior. Learning -The ability of an intelligent system to improve or generate future potential knowledge and/or responses, based on analyzing the utility of previous patterns of knowledge and/or responses for specific goals. Self-optimization - The ability of an intelligent system to employ Learning and Reflection to transform its own' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='composition, state, context or behavior in order to improve fitness for specific goals and criteria.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The core innovation within Cognitive AI lies in a dual-layer architecture which enables meta-cognition to take place above the intelligence of LLMs. This architecture enables Cognitive AI to not only analyze and respond to data but also to introspect, reflect and dynamically optimize its strategies based on ongoing experiences. Such self-reflective intelligence allows\\n\\n36\\n\\nCognitive AI to evaluate and enhance its decision-making processes in real-time, leading to improved efficiency and outcomes.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Meta-cognition, or intelligence about intelligence, equips Cognitive AI with the ability to perform abstract reasoning, a hallmark of human cognition. Whereas LLMs may simulate abstract reasoning in straightforward scenarios, they falter as task complexity increases.\\n\\nCognitive AI's meta-cognition architecture facilitates a level of introspection and adaptive reasoning and learning that surpasses what is possible with first-order intelligent systems, enabling it to navigate and solve intricate, multi-faceted highly complex problems.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"The transition towards Cognitive AI signifies a fundamental transformation in the field of artificial intelligence, moving from a reliance on basic pattern recognition to a more sophisticated, introspective, and adaptable intelligence model. This evolution not only redefines our conceptual understanding of AI but also marks a significant milestone in the technology's development, paving the way for future innovations that more closely mimic human cognitive processes.\\n\\nSelf-Improvement\\n\\nCognitive AI also distinguishes itself from Conversational AI through self-improvement. This distinction is not merely theoretical but operational, impacting how these systems approach and solve problems.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"At the heart of Cognitive AI's operational framework lies the principle of continuous loops of self-improvement (“recursive self-improvement”, cf. Steunebrink et al., 2016; Nivel et al. 2013) achieved through an iterative loop of goal-directed learning, cognition, and adaptation. This iterative process allows Cognitive AI systems to recursively analyze their outputs, and use this analysis for self-reflection and iterative improvement of their solutions, strategies, plans and responses.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Unlike Conversational AI, which primarily generates responses based on the immediate statistical likelihoods derived from training data, Cognitive AI engages in a dynamic process of self-evaluation and enhancement, enabling complex problem-solving that incorporates meta-level strategic thinking and creativity – and it often does this before generating a response. This capacity for recursive self-improvement allows Cognitive AI to adapt to new challenges and changing environments, continuously enhancing its capabilities beyond its initial programming.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='One of the most important differentiating cognitive features of higher-intelligent lifeforms on Earth is the ability to form goals and execute complex multi-step plans to achieve them. Humans and a few other species are capable of this level of conceptual thinking. To form,\\n\\n37\\n\\nmaintain and execute plans requires a high level of abstract reasoning. Cognitive AI is able to model arbitrary types of plans with conditional logic workflows that both humans and agents can collaborate with.\\n\\nIn more concrete terms, recursive self-improvement is implemented in Cognitive AI architectures as a goal-directed process across one or more cognitive functions, where at least one must be a planning function.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='A Planner makes plans for accomplishing goals. Plans can be thought of as strategies for goal-directed thinking and behavior. Plans are scripts that are created to guide actions for specific objectives and criteria. But plans can also be used to structure and guide the “internal actions” of an agent or a team as well as their external behaviors. When plans are applied to the internal cognitive processing of AI systems, they guide their reasoning. problem-solving, innovation, decision-making or strategic thinking process.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Previous generations of AI developed plans using algorithms to compose, optimize and utilize graphs and other data structures to represent plans for solving problems, and to manage state during problem solving processes. But these systems lacked the language processing capabilities that LLMs now provide. When LLMs are applied to generating and improving plans they do so in an entirely different manner - instead of algorithms and mathematical operations, they use natural language. The plans they generate are not formal logic processes, they are human-readable text that can be utilized both by agents and by humans alike, for collaborating on complex knowledge work - such as developing a new drug from start through clinical trials. Within' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='these human-readable plans, there can be steps that utilize formal logic, graph search, computation and machine learning to search for particular potential solutions (such as drug candidates), and then construct or reconfigure plans based on findings. But the key point is that while formal computational plans are not imposed on everyone, they are confined to laser-focused tasks that really need to be implemented this way. In other words, in Cognitive AI systems, planning is democratized - it’s a process that both agents and humans can potentially collaborate in, using the same language - natural language.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The additional benefit of natural language plans is that LLMs can read and respond to them with the full power of their models and training. Using this capability, Cognitive AI systems can then apply the Cognitive Layer to formally construct and reason about plans, while the Conversational Layer can be used to read, write, respond to and interpret plans. The combination of these two layers in the context of planning yields rich and robust human-level plans that would be extremely difficult to produce with previous generations of AI, and which also can be iteratively self-improved by the agents and humans that participate in them.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Plans function as the cognitive DNA of Cognitive AI systems. They are used both by the intelligent agents and any human participants, to channel how they work through a knowledge work process, where a combination of thinking and actions have to be orchestrated in a logical sequence. The Planner function in such systems designs, develops and implements plans.\\n\\n38\\n\\nBy adding a Recursive Self-Improver loop around a Planner, a Cognitive AI system can introspect on its plans and improve them, both at runtime and in the background. Plans can be recursively self-improved either through internal dialogs among agents, or through improving them when certain events trigger (such as a dependency having a delay or getting blocked).' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='With the ability to form and improve goal-directed plans in response to internal and external feedback, Cognitive AI systems can then engage in goal-driven, adaptive self-improvement and optimization. These capabilities in turn enable these systems to develop and optimize plans that in turn seek to develop and optimize solutions to a problem.\\n\\nCognitive AI systems can develop and optimize solutions faster than predecessor forms of AI by optimizing on two levels at once – the solution-finding process (the plan) and the solutions for making the solution-finding process better (the recursive self-improvement loop around the Planner).' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='When it comes to optimization and innovation, Cognitive AI transcends the limitations inherent in LLMs and their probabilistic models. LLMs, even those enhanced with advanced learning algorithms like Q*, are confined to generating outputs based on pattern recognition within their training datasets. Q* based approaches are designed for generating responses that are likely correct within a closely related set of data but struggle with the broader, more intricate challenges of optimization that require navigating long, nested plans and decision trees.\\n\\nCognitive AI, by contrast, is equipped with the architecture to engage in deep reasoning and strategic planning, necessary for tackling complex optimization and innovation tasks. It can:' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='1. Utilize structured knowledge and reasoning algorithms to navigate complex decision-making processes, identifying the most effective paths through intricate, multi-layered problems.\\n\\n2. Map out comprehensive strategies that consider a wide array of factors, including long-term goals and objectives, budgets, criteria, and potential obstacles, ensuring optimization across diverse problem spaces.\\n\\n3. Generate innovative ideas and solutions, leveraging creative problem-solving capabilities to explore new approaches and push the boundaries of existing knowledge. 4. Learn and adapt from outcomes, integrating new information to continuously refine and\\n\\nenhance problem-solving strategies in response to evolving challenges.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Recursive self-improvement can be applied across all cognitive AI processes, not only the planning function. It can be applied at the micro level and the macro level, from improving execution strategies at runtime, to improving knowledge bases, to improving and guiding search strategies and Web crawling, to optimizing large collaborative projects in enterprises in response to changes in their environments over time.\\n\\n39\\n\\nThe ability of Cognitive AI to engage in recursive self-improvement highlights the gap in reasoning capabilities between Cognitive AI and LLMs. While LLMs simulate aspects of intelligence, Cognitive AI embodies a form of intelligence that can reason, plan, innovate, and adapt in ways that mirror human cognitive processes.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Comparison of Conversational AI to Cognitive AI\\n\\nConversational AI, with its reliance on LLMs for intelligence and simulated cognition, cannot replicate the advanced cognitive capabilities of Cognitive AI architectures, but it’s important to note that Cognitive AI cannot emerge without Conversational AI as an underlying tool.\\n\\nLLMs generate probabilistic responses based on patterns learned from vast amounts of text data. These models:' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Replicate patterns of reasoning they've been exposed to in the data, which means they can produce text that often appears logically consistent with the input prompt. Lack genuine understanding or the ability to independently verify the information or apply novel reasoning techniques not present in their training data.\\n\\nAre constrained by their training, meaning they can't conceptualize beyond what they've been taught or incorporate new information post-training.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='For example, when given a math problem, an LLM can solve it if it mirrors problems seen during training, using similar steps and logic. However, it does so by matching patterns probabilistically rather than understanding or applying abstract mathematical principles. It is also worth noting that LLMs cannot natively perform mathematical operations, they can merely mimic them, which often leads to plausible but incorrect answers (“mathematical hallucinations”).\\n\\nCognitive AI, on the other hand, can go beyond pattern matching to actual reasoning and mathematics, powered by meta-cognition and a host of other cognitive functions:' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Conduct reasoning against knowledge by executing programmable reasoning strategies using plans and formal knowledge representations.\\n\\nUse tools via function calls and APIs to integrate external applications and data. Perform mathematical operations by utilizing tools for mathematics, scientific - computing, machine learning, data analytics, predictive modeling, and even formal logic and inferencing.\\n\\nGenerate novel insights by reasoning from first principles or by applying learned\\n\\n\\n\\nconcepts in new ways, independent of specific examples in training data. Incorporate new information post-training, adjusting its reasoning processes based on new data or changing contexts.\\n\\n40' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Engage in meta-reasoning, reflecting on its reasoning processes, evaluating them, and adjusting reasoning strategies to optimize problem-solving.\\n\\nCognitive AI could, for example, devise a new mathematical proof or strategy for solving a problem by integrating new research findings, by reasoning about a problem or goal, exploring and testing hypothesis, deriving new knowledge, refining its approach as it learns from experience, and abstracting principles from one domain and applying them to another.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='While Conversational AI is purely linguistic and probabilistic, Cognitive AI can apply non-probabilistic formal reasoning and mathematics as well as linguistic and probabilistic approaches, enabling it to deterministically control non-deterministic processes.\\n\\nThis “hybrid reasoning” approach makes Cognitive AI programmable and controllable in a way that prompt-engineering can only approximate, while also enabling it to harness and channel the non-deterministic conversations of LLMs.\\n\\nWhile prompt-engineering methodologies in Conversational AI approaches can simulate and approximate simple formal reasoning and programming, they are inherently non-deterministic, prone to errors, hallucinations, and unpredictable behaviors.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The distinction between Conversational AI, driven by Large Language Models (LLMs), and Cognitive AI becomes starkly evident when examining their respective approaches to handling knowledge. This difference highlights the limitations of LLMs and underscores the advanced capabilities of Cognitive AI, particularly through the integration of a cognitive layer that elevates its operational intelligence and knowledge management.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='In Conversational AI, knowledge is not formally represented or stored. Instead, Conversational AI operates on probabilities derived from patterns recognized in vast external datasets during the training phase. The training phase transforms the explicit and implicit knowledge in vast amounts of training data in numerical weights in a complex multidimensional model. There is no way to isolate a particular “piece of knowledge” in these networks, instead knowledge is spread across models in amorphous fields of numbers.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='This probabilistic approach means that while LLMs can generate responses that seem knowledgeable, they do not \"know\" anything or retrieve any knowledge in the traditional sense. Their responses are guesses, albeit often highly educated ones, based on the data they have been trained on. This mechanism limits Conversational AI\\'s ability to provide reliable, consistent, and contextually accurate knowledge beyond the scope of its training data.\\n\\nUnlike the probabilistic nature of Conversational AI, Cognitive AI can concretely represent, store and retrieve data structures that encapsulate knowledge objects, world models, knowledge bases, and knowledge structures, alongside reasoning strategies. These explicit knowledge\\n\\n41' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"constructs allow for knowledge management and knowledge processing at runtime, significantly enhancing the AI's ability to interact with and utilize formal knowledge.\\n\\nCognitive AI's approach to knowledge is multifaceted and dynamic, encompassing:\\n\\nConversational Layer Knowledge: Here, probabilistic knowledge is derived using prompts against the model, supplemented with embeddings to generate responses that are informed by recognized patterns in data.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Cognitive Layer Knowledge: This layer houses formally specified knowledge objects stored in databases, which describe, reference, and link to contextual knowledge. Knowledge catalogs organize these objects taxonomically, while knowledge graphs connect them through various relational types, enabling a comprehensive and interconnected knowledge management system.\\n\\nKnowledge management empowers Cognitive AI to capture and store knowledge efficiently, navigate and search through complex datasets, generate new insights, and continuously improve knowledge bases. This ongoing process of learning, improvement, and knowledge generation is adaptive, ensuring that Cognitive AI remains relevant and insightful across various contexts and applications.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"The contrast between the probabilistic knowledge of Conversational AI and the formal, structured knowledge management of Cognitive AI highlights the advanced capabilities of the latter.\\n\\nCognitive AI's ability to concretely represent and utilize knowledge through its cognitive layer not only addresses the limitations of LLMs but also opens up new avenues for AI's application in complex problem-solving, decision-making, and innovation. By leveraging formal knowledge representation, Cognitive AI sets a new standard for artificial intelligence, bridging the gap between data-driven predictions and genuine understanding.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"The ability to tackle complex challenges is a critical measure of an AI system's capabilities, and it is in this arena that the distinction between Cognitive AI and Conversational AI becomes most apparent.\\n\\nCognitive AI's superiority in addressing intricate problems lies in its foundational architecture, which enables deterministic programming and sophisticated problem-solving approaches, transcending the limitations of probabilistic mimicry inherent in Conversational AI.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Conversational AI's strength in generating human-like text becomes a hindrance in situations that require precise, algorithmic reasoning and multi-step logical operations. As the complexity of the problem escalates, Conversational AI's ability to deliver quality results plateaus and then\\n\\n42\\n\\ndiminishes, constrained by its probabilistic nature and the lack of deterministic programming capabilities.\\n\\nFigure 15. Response Quality vs. Problem Complexity\\n\\nConversational AI plateaus and then quickly becomes less able to deliver quality results as problem complexity increases, while Cognitive AI continues to gain in quality.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"The performance disparity between Cognitive AI and Conversational AI becomes increasingly evident as the complexity of challenges grows. While Conversational AI struggles to maintain efficacy in the face of intricate, multi-dimensional tasks, Cognitive AI thrives, leveraging its robust computational framework to dissect and address each component of the problem systematically. This distinction underscores Cognitive AI's ability to not only match but exceed the problem-solving capacities of Conversational AI, offering a more reliable, effective solution for complex challenges.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The distinction between Cognitive AI and Conversational AI, illustrated through their respective approaches to problem complexity, highlights the advanced capabilities of Cognitive AI in deterministic problem-solving.\\n\\nUnlike Conversational AI, which is constrained by its probabilistic, language-dependent framework, Cognitive AI can engage in deep, algorithmic reasoning and execute sophisticated computational strategies. This ability to navigate and solve complex, multi-layered problems with precision and efficiency underscores the potential of Cognitive AI to revolutionize the field of artificial intelligence, pushing the boundaries of what AI systems can achieve in terms of complexity, reliability, and overall performance.\\n\\n43' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Cognitive AI's approach to problem-solving represents a significant departure from the capabilities of traditional conversational AI, such as LLMs. Where conversational AI is constrained by its reliance on probabilistic intelligence and the limitations of processing language-based inputs, Cognitive AI introduces a multi-faceted, algorithmically driven problem-solving framework. This framework is particularly adept at tackling complex, nested problems typical of knowledge work, which require sophisticated reasoning and the ability to adapt strategies in response to evolving information and multiple layers of dependencies.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='LLMs operate on a first-order level, employing probabilistic intelligence against streams of tokens to simulate understanding and generate responses. This method, while effective for generating language-based outputs, falls short in complex problem-solving scenarios that necessitate executable control flow, mathematical operations, and strategic reasoning. LLMs are inherently unable to engage in sophisticated problem-solving processes such as recursive operations, tree searches, curve fitting, or optimization, limiting their effectiveness to what can be simulated through language alone.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Cognitive AI transcends these limitations through its advanced architectural design, which incorporates a cognitive layer equipped with capabilities for formal knowledge representation, management, discovery, and reasoning against knowledge bases. This layer enables Cognitive AI to engage in multi-layered reasoning, simultaneously maintaining, adjusting, and managing reasoning states and strategies across various levels of thought. This is particularly crucial for solving nested problems, where a primary issue encompasses multiple sub-problems, each with its own set of challenges.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Cognitive AI systems are designed with the flexibility to implement advanced computational strategies, such as recursion, parallel computing, and asynchronous computing. This capability allows them to efficiently address multi-layered, multi-step problems by deterministically running through any number of nested operations.\\n\\nFor instance, Cognitive AI can be programmed to execute complex algorithms that involve recursive functions, enabling it to solve problems that unfold across several levels of complexity. This deterministic approach ensures that Cognitive AI can maintain a high level of accuracy and reliability, even as the complexity of tasks increases.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Conversational AI, on the other hand, operates primarily on probabilistic outputs generated from patterns recognized within its training data. Its reliance on natural language processing as the basis for all operations introduces inherent limitations, particularly when faced with complex problem-solving scenarios.\\n\\nBy leveraging sophisticated algorithms, Cognitive AI can execute complex problem-solving tasks that are beyond the reach of conversational AI. This includes engaging in mathematical and logical operations, executing recursive functions, and conducting exhaustive searches—all integral to addressing the multifaceted nature of real-world problems. Moreover, Cognitive AI's\\n\\n44\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"ability to dynamically adapt its strategies in real-time allows it to respond effectively to new challenges, dependencies, and changing conditions within a problem space.\\n\\nAt the heart of Cognitive AI's problem-solving capability is its integrated knowledge management system, which harnesses knowledge catalogs, graphs, and metadata taxonomies. This system not only organizes information but also facilitates the discovery of new knowledge, which Cognitive AI can then apply to its reasoning processes. The ability to access and utilize a comprehensive knowledge base enhances Cognitive AI's problem-solving capacity, enabling it to draw on a wide range of information sources to inform its strategies and solutions.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Problem-solving in Cognitive AI architectures represents a paradigm shift in artificial intelligence's approach to complex challenges. Unlike conversational AI, which is limited to language-based simulations, Cognitive AI combines structured knowledge management with advanced algorithmic processing to tackle nested problems with unparalleled depth and efficiency. Its capacity for dynamic strategy adaptation and sophisticated reasoning ensures that Cognitive AI can navigate the complexities of knowledge work, making it an invaluable asset for fields requiring nuanced analysis, strategic planning, and the integration of diverse information sources.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Through its comprehensive problem-solving framework, Cognitive AI not only addresses the limitations of traditional AI models but also sets a new standard for intelligence and adaptability in tackling the world's most complex challenges.\\n\\nLimits of Cognitive AI\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='While Cognitive AI represents a significant advancement in artificial intelligence, bridging the gap between simple task execution and complex problem-solving, it is not without its limitations. These constraints delineate the current capabilities of Cognitive AI from the broader, more ambitious goals of Artificial General Intelligence (AGI). Understanding these limitations is crucial for grasping why Cognitive AI, despite its advanced functionalities, falls short of the comprehensive intelligence AGI aims to achieve.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Cognitive AI excels within a broad range of domains and applications, where its advanced knowledge management systems, problem-solving algorithms, and adaptive learning capabilities can be fully leveraged. However, this strength is also a limitation in domains outside the parameters of its programming and the scope of its training data. Until further first-order models that can self-modify are built, it is not capable of fully generalizing its intelligence to accommodate all possible domains and problems.\\n\\nAGI, in contrast, aspires to universal intelligence, capable of understanding and performing any intellectual task that a human being can, across any domain. This includes the ability to learn\\n\\n45' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"from entirely new experiences without prior examples (zero-shot learning), a flexibility that Cognitive AI currently cannot match.\\n\\nCognitive AI's problem-solving is driven both by conversational language intelligence and by sophisticated algorithms that can execute certain aspects of human reasoning. AGI's goal encompasses not just the replication of human-like reasoning but also the intuitive, creative, and emotional aspects of intelligence that allow humans to learn, adapt, innovate and behave in ways that are currently beyond the reach of Cognitive AI.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='While Cognitive AI will offer remarkable strides in modeling complex reasoning and learning within specific domains, crossing the dividing line to AGI will require a more holistic replication of the full spectrum of human intelligence and behavior. This includes not only the cognitive but also the emotional, social, creative, biochemical and physical aspects of intelligence and behavior.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Bridging this gap will necessitate breakthroughs that enable AI systems to learn and reason in fundamentally human-like and even embodied ways, marking the next revolutionary leap in artificial intelligence capabilities after Cognitive AI. Achieving AGI represents not just an extension of current AI functionalities but a transformative evolution towards systems that can truly think, learn, and interact with the world with the richness and flexibility of human being.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Today Cognitive AI is in its infancy and existing systems, most of which are still experimental, do not even attempt to fully-replicate all aspects of human intelligence and behavior. Instead Cognitive AI is mainly focused on solving for the intellectual dimension and problems involving knowledge work.\\n\\nThere is no agenda to replicate or replace humans in the Cognitive AI paradigm. Instead the approach is to use artificial cognition to augment and facilitate the knowledge work of human individuals, teams and organizations.\\n\\nCognitive AI in the Evolutionary Ladder of Intelligence' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The development of Cognitive AI represents a significant milestone in the evolutionary ladder of intelligence, but it is not without evolutionary precedent. The evolution of Cognitive AI can be understood as the next major leap in a progression of evolution of higher levels of meta-cognition that has spanned from the instinctual behaviors of insects to the complex problem-solving abilities of humans and now to the meta-cognitive capacities of Cognitive AI.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Each step on this ladder reflects a leap in meta-cognition abilities, which in turn enable higher forms of problem-solving skills and adaptability. Cognitive AI is the next major evolutionary milestone in this process, and serves as the gateway to the further evolution of increasingly exponential forms of intelligence in our future.\\n\\n46\\n\\nFigure 16. The Evolution of Meta-Cognition.\\n\\nWe can illustrate the progression of evolution of higher levels of meta-cognition with a few examples:\\n\\n\\n\\nInsects: Insects exhibit basic forms of intelligence, primarily driven by instinctual behaviors designed for survival and reproduction. Their cognitive capabilities are limited, focusing on direct responses to environmental stimuli.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Animals: Most animals, especially mammals, demonstrate advanced cognitive functions, including learning from experience, social intelligence, and, in some cases, the use of tools. Their intelligence represents a significant leap from the instinct-driven behaviors of insects, incorporating elements of memory, emotion, and social interactions.\\n\\nHumans: Human intelligence introduces the ability for abstract thinking, language, and conceptual understanding, setting humans apart from other species. Humans have developed complex societies, technologies, and cultures, leveraging cognitive abilities to innovate and solve problems creatively.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Cognitive AI: Stepping beyond human intelligence, Cognitive AI integrates meta-cognition, enabling it to reflect on, manage, and improve its own cognitive processes. Unlike its predecessors, Cognitive AI can self-assess, learn autonomously, and evolve its strategies over time, tackling complex challenges with a level of efficiency and adaptability that mirrors, and in some instances, surpasses human intelligence.\\n\\n47' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Group Minds: Cognitive AI provides a better infrastructure for collective intelligence, or what we might call “group minds.” In group minds, teams of intelligent agents and/or humans are intelligently orchestrated to think and work more intelligently. This level of collective intelligence is smarter than the forms of collective intelligence exhibited by social insects, and even by groups and organizations of humans on their own. The key is that the collective intelligence is orchestrated through a central Cognitive AI application.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='AGI and EGI: Artificial General Intelligence is a form of AI that replicates the intelligence of an individual human. Enterprise General Intelligence replicates the collective intelligence of enterprises. Both of these forms of intelligence require Cognitive AI before they can happen, and EGI requires the evolution of AGI and Group Minds in addition. These forms of intelligence are close to superintelligence, but they are not infinitely recursive or parallel – they replicate finite forms of intelligence.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Superintelligent AI: The concept of Superintelligent AI represents the potential future evolution of Cognitive AI into a form of intelligence that transcends the limitations of finite organisms and organizations in both space and time. It entails AI systems that can autonomously implement Cognitive AI, using massive parallelism and recursion to surpass the cognitive abilities of humans, and organizations, across all domains. Superintelligent AI would possess the ability to engage in third-order cognition, not just improving its cognitive processes but also fundamentally redefining its goals, strategies, plans, structure, capabilities, and even the underlying infrastructure substrates it runs on, to achieve levels of cognition beyond' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='current human comprehension.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The introduction of Cognitive AI is a necessary step towards achieving higher post-human levels of intelligence, such as Group Minds, AGI, EGI, Superintelligence.\\n\\nBy advancing AI’s capacity for meta-cognition, Cognitive AI systems are not just thinking machines, they are meta-cognitive cognition machines capable of self-directed, self-improving thought, behavior and evolution. This represents a critical step forward in the quest to develop AI that can truly mimic the breadth and depth of human intelligence, offering a glimpse into a future where AI can autonomously tackle a wide array of complex, multi-dimensional challenges.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The placement of Cognitive AI on the evolutionary ladder of intelligence highlights its pivotal role as a transformative phase-transition in the field of AI, bridging the gap between human intelligence and the potential for superintelligence.\\n\\nBy equipping AI with the capability for meta-cognition, Cognitive AI opens up new possibilities for solving complex problems, driving innovation, and enhancing human-machine collaboration. As we move forward in time, the evolution from Cognitive AI to Superintelligence presents both unprecedented opportunities and challenges, necessitating careful consideration of ethical, societal, and technological implications.\\n\\n48\\n\\nExponential Intelligence' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Exponential intelligence is defined as a higher form of intelligence that emerges when human intelligence and cognitive AI intelligence are combined such that increasingly large and complex many-to-many collective cognitive AI processes can take place.\\n\\nAs well as helping to improve knowledge work productivity, Exponential Intelligence enables humans to address more complex problems that were previously out of reach.\\n\\nMore precisely:\\n\\nEI = (HI + AI)\\n\\n(2+x)\\n\\nWhere: - - HI = Number of human intelligent agents - -\\n\\nEI = Exponential Intelligence Level\\n\\nAI = Number of Cognitive AI software AI agents. x = Level of collective intelligence:\\n\\n- - - -' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Level 0: One human + one AI Level 1: Many humans + one AI Level 2: One human + many AIs Level 3: Many humans + many AIs Level 4: Many networks of humans + AIs\\n\\nHuman intelligence makes AI safer, nuanced, more goal directed, and more adaptive. Humans add the ultimate level of meta-cognition to Cognitive AI systems. Humans also provide these systems with consciousness, in that they function as atomic units of consciousness in these systems.\\n\\nArtificial intelligence amplifies, augments and extends human intelligence with large-scale computing, research, analytics, and reasoning capabilities.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Exponential Intelligence is self-amplifying. By providing higher levels of exponential intelligence to individuals, the system as a whole becomes more exponentially intelligent. This recursive self-amplifying process is what enables superintelligence to emerge.\\n\\n49\\n\\nImplications\\n\\nAs we have explored above, the divergent capabilities of Conversational AI, predominantly powered by Large Language Models (LLMs), versus Cognitive AI with its neuro-symbolic Cognitive Layer, underscore a pivotal juncture in the evolution of artificial intelligence.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The core limitations of LLMs lie in their operational framework, which relies on identifying patterns and generating predictions from statistical likelihoods drawn from their extensive training datasets. This process, while often remarkably effective, does not equate to genuine understanding or reasoning. LLMs are constrained to sophisticated pattern matching, lacking the capacity for deductive reasoning, creative thought, or the generation of new knowledge beyond their programmed experience. Their approach to problem-solving, bound by the confines of their training corpus, cannot truly replicate the deductive and inferential processes characteristic of human cognition.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"In stark contrast, Cognitive AI’s neuro-symbolic approach heralds a future where systems are not only capable of mimicking human reasoning but engaging in genuine cognitive processes in which actual cognition takes place.\\n\\nThis leap forward is facilitated by Cognitive AI’s sophisticated functional architecture, which includes functions for formal knowledge representation and knowledge management, and the application of formal logical processes, including formal logical inference, to problem-solving.\\n\\nCognitive AI's ability to learn and adapt in real-time, incorporating insights that were not part of its initial programming, illustrates a significant advancement over the pattern recognition and interpolation capabilities of LLMs.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Furthermore, Cognitive AI’s inherently social and meta-cognitive functions enable it integrate networks of knowledge and cognition, and to reflect and self-improve to achieve goals and implement optimizations that are out of reach for LLMs.\\n\\nThe theoretical and practical limitations of LLMs in performing true cognition highlight the necessity of advancing Cognitive AI technologies. Cognitive AI's ability to engage in genuine reasoning, understanding, and creativity opens up new possibilities for AI applications, pushing the boundaries of what artificial intelligence can achieve.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='This distinction between conversational and Cognitive AI has profound implications for the future of AI as both a field of study and an industry. While LLMs continue to be invaluable for a broad spectrum of applications, their limitations become increasingly apparent as the complexity of tasks escalates.\\n\\n50' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Cognitive AI is capable of achieving exponential intelligence, while Conversational AI is not. Exponential Intelligence amplifies intelligence beyond what human intelligence or AI can achieve on their own. This level of intelligence is a discontinuity - an evolutionary leap - that will enable mass collective cognition that is noticeably different - and more productive - compared to how knowledge workers, groups, and organizations think, work and collaborate today.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"The theoretical potential of Cognitive AI extends far beyond the capabilities of current conversational AI models. As systems that can genuinely reason, learn, and create, Cognitive AIs promise to revolutionize how we approach complex problems across various domains. From decision-making and problem-solving in knowledge work, to generating innovative solutions and adapting to new challenges in real-time, Cognitive AI's capabilities suggest a future where AI will work as a partner with humanity.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"The evolution from conversational to Cognitive AI is not merely a technical upgrade but a fundamental shift in the conceptual underpinnings of artificial intelligence. This transition marks a pivotal moment before higher-levels of AI such as AGI or superintelligence can emerge.\\n\\nAs the field continues to develop, the focus on enhancing Cognitive AI's capabilities will be paramount for achieving the next leap in AI's theoretical and practical applications. The implications for industries, academia, and society at large are vast, heralding a new era of AI that can work alongside humans to tackle the world's most complex challenges with a level of insight and creativity previously thought to be the exclusive domain of human intelligence.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Crossing the Chasm\\n\\nWe can visualize the limitations of Large Language Models (LLMs) using the framework of Geoffrey Moore\\'s \"Crossing the Chasm,\" where we draw an analogy between the adoption lifecycle of disruptive technologies and the progression of AI capabilities, particularly focusing on the transition from LLMs to cognitive AI systems.\\n\\nMoore\\'s model describes the market adoption of new technologies in five segments: Innovators, Early Adopters, Early Majority, Late Majority, and Laggards. \"Crossing the chasm\" refers to the crucial transition from Early Adopters to the Early Majority, a phase where many technologies struggle to achieve wider acceptance due to practicality, utility, or refinement issues.\\n\\n51' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Figure 17. The Cognitive Chasm.\\n\\nInnovators: Exploring LLM Capabilities\\n\\nIn the context of LLMs, Innovators are represented by researchers and developers who first explored the potential of these models in understanding and generating human-like text. This group is fascinated by the novelty and the technical excellence of LLMs, willing to overlook their limitations in favor of exploring new applications and pushing the boundaries of what these models can do.\\n\\nEarly Adopters: Niche Applications and Proof of Concept' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Early Adopters in the AI field are companies, tech enthusiasts, and sector-specific professionals who see the potential of LLMs to disrupt traditional operations, from automating customer service interactions to generating creative content. These users are willing to experiment and integrate LLMs despite their imperfections, focusing on niche applications where the models' capabilities can be fully leveraged.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Despite what is commonly thought, Conversational AI has not yet crossed past the early-adoption phase. Even with more than 100 million registered users, ChatGPT is still a limited niche application with a minimal feature set, and it has not been adopted by the millions of organizations and billions of people who constitute the majority of adopters.\\n\\n52\\n\\nEarly Majority: Crossing the Cognitive Chasm' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Crossing the “Cognitive Chasm” involves moving from these early stages to broader acceptance and usage among the Early Majority. For LLMs, the chasm is represented by the transition from fascinating novelty to practical utility in diverse and complex applications such as real-world knowledge work. But the limitations of LLMs—such as their inability to reason deeply, understand context beyond their training, or generate novel insights beyond pattern recognition—act as barriers to this transition.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='For AI to achieve mainstream acceptance and utility, crossing the Cognitive Chasm means addressing the nuanced real-world needs of the Early Majority. This group looks for solutions that are not just innovative but also sufficiently applicable to their use-cases, such as complex knowledge work and decision-making.\\n\\nTo cross the Cognitive Chasm, LLMs must evolve—or be supplemented by—technologies that address these limitations. This will be solved by Cognitive AI capabilities that can understand context, reason from first principles, and integrate new information post-training.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='The leap lies in creating AI systems that not only mimic human language but also exhibit a level of meta-cognitive reasoning, understanding and adaptability that can satisfy the needs of the Early Majority, who require reliability, depth, and practical applicability in complex scenarios.\\n\\nChatbots do provide useful assistance on simple knowledge work tasks. But they are insufficient when it comes to complex, mission-critical knowledge work in which highly nuanced understanding and reasoning are necessary, and accuracy and policy compliance are non-optional.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Cognitive AI systems, with their advanced meta-cognitive reasoning capabilities, represent a necessary bridge across this chasm, offering solutions that can sufficiently meet the stringent and complex demands of professional knowledge workers and enterprises.\\n\\nIn summary, using Moore\\'s \"Crossing the Chasm\" framework to visualize the limitations of LLMs highlights the need for significant advancements in AI capabilities to achieve mainstream acceptance. The transition to cognitive AI, capable of genuine understanding and reasoning, represents a critical step in this journey, promising to bridge the gap between early enthusiasm and widespread practical application.\\n\\nRe-evaluating Current AI Approaches' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"The landscape of artificial intelligence has recently been dominated by developments and innovations centered around first-order intelligence form Large Language Models (LLMs) and the accompanying tools required to leverage and deploy them effectively, such as new models\\n\\n53\\n\\nand training tools, GPUs, vector databases and Retrieval-Augmented Generation (RAG), and chatbots.\\n\\nThis focus has driven billions of dollars of investment into R&D around LLMs, and has yielded significant advancements in AI's capabilities, particularly in natural language processing and generation.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='However, the advent of Cognitive AI signals a shift to a second-order playing field in the near-term trajectory of AI development, urging a re-evaluation of current approaches and investment priorities in the field.\\n\\nNotably, increased investment into conversational AI will not yield significant major advances going forward. Advances in LLM models will never directly yield Cognitive AI, AGI or superintelligence, for example. Only by innovating on the cognitive dimension itself can the highest levels of AI be achieved. In other words, investment should be focused into the enabling technologies, applications and infrastructures for the Cognitive AI instead of, or at least in addition to, further doubling down into Conversational AI.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Figure 18. AI Innovation Trajectory\\n\\nConversational AI is already “good enough” to enable Cognitive AI to evolve, such that further investments into LLM innovation will not significantly improve Cognitive AI’s capabilities. While improved LLM’s will be helpful in improving first order response quality, much of the quality-improvements and increased capabilities will come from the Cognitive AI layer not the Conversational layer. In other words, Cognitive AI so dramatically improves and amplifies the\\n\\n54\\n\\ncapabilities of LLMs that small improvements to LLM performance or accuracy will not be economically important.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='This observation implies that, contrary to current investment trends, there should soon be a concerted effort to allocate investment towards the new frontier of Cognitive AI innovation. Initially, there should at least be similar levels of investment into both layers of innovation, but over time, as Conversational AI plateaus, Cognitive AI will prove to be a better long-term bet for capturing significant new ecosystem value-creation opportunities.\\n\\nLLMs as a Commodity' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='We observe the continued acceleration of improvement and proliferation of LLM models (especially open-source models), coupled with ever-decreasing costs of their development and deployment. We believe these trends are leading to near-term commoditization of Conversational AI technology.\\n\\nOpen-source LLMs are reaching performance levels that rival, and may soon surpass, those of proprietary models. And while foundation-model LLMs will continue to attract innovation and investment, the landscape is expected to consolidate, favoring a few key players.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Concurrently, a significant market for domain-specific LLMs, trained or fine-tuned on proprietary data, will emerge, suggesting a shift in focus towards more specialized niche applications of LLM technology. While this market will be large and robust, it will still not solve the problems of mainstream adopters.\\n\\nWhile LLMs will continue to be a strong area of innovation and investment, they may become less differentiated and defensible as innovation shifts to the new second-order playing field of Cognitive AI, in which there are many LLMs to choose from, and competitive advantages don’t come from LLMs at all.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='In Cognitive AI, LLMs are a commodity where there is virtually no cost-of-switchover to change models underneath an application. Any general purpose foundation model is “good enough” and switching between them has minimal consequences for Cognitive AI systems.\\n\\nCommercial Cognitive AI\\n\\nThe backdrop of coming commoditization within the LLM space underscores the strategic importance of directing resources towards more defensible AI opportunities, like Cognitive AI.\\n\\n55' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Unlike LLMs, which are increasingly becoming commoditized tools within the AI ecosystem, Cognitive AI represents an entirely new opportunity – it’s a new frontier, a new IP landscape, a new ecosystem, ripe with opportunities for disruptive new technologies and business models.\\n\\nBy focusing on the development and deployment of Cognitive AI technologies, businesses and investors can position themselves at the forefront of the next wave of AI innovation, capturing opportunities for early leadership, new IP creation, and unique value creation, in what will be the next trillion-dollar AI market.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='In 2024, the AI industry is poised to witness the launch of the first major commercial Cognitive AI applications designed for professional and enterprise use. This evolution, will be led by new pioneers, like our own venture, Mindcorp.ai, and our product, Cognition (currently in stealth-mode as of this writing).\\n\\nThe shift towards commercial Cognitive AI highlights a growing understanding of its potential to overcome obstacles to mainstream adoption of AI, which cannot be sufficiently addressed by Conversational AI paradigms such as chatbots. While chatbots are useful, they are not sufficient for mainstream adoption by professionals and enterprises engaged in complex knowledge work.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"When commercial Cognitive AI emerges, it will signal a crucial juncture where stakeholders will need to reconsider where they focus their attention and resources in the AI domain.\\n\\nWe predict that by 2030, Cognitive AI will be the primary battlefield for AI investment, innovation, and commercialization.\\n\\nConclusions\\n\\nOur exploration of Cognitive AI's development, has delved into its architectural innovations to its positioning in the evolutionary ladder of intelligence, culminating with a compelling argument for its pivotal role in the next generation of artificial intelligence.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='As we transition from a landscape dominated by Large Language Models (LLMs) to one enriched by the capabilities of Cognitive AI, we stand on the threshold of a new era in technology and human-machine collaboration, in which a new symbiosis of human and machine intelligence will emerge.\\n\\nCognitive AI heralds a paradigm shift, moving beyond the commoditization of LLMs towards a future where AI systems are not only intelligent but possess the ability to introspect, learn, and evolve autonomously.\\n\\nThis shift towards meta-cognition opens up unparalleled opportunities for innovation, efficiency, and problem-solving across all sectors.\\n\\n56' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Cognitive AI's unique architecture and capabilities promise to redefine the boundaries of machine intelligence, offering more adaptable, efficient, and profound solutions to complex challenges.\\n\\nThe implications of Cognitive AI extend far beyond the technical domain, promising to revolutionize how we approach challenges in all sectors from government to healthcare, education, finance, and more.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='By providing AI systems that can understand and adapt their strategies in real-time, Cognitive AI paves the way for more personalized, effective, and sustainable solutions to societal issues. Its emergence invites stakeholders to re-evaluate their focus and investment in AI, recognizing Cognitive AI as the frontier where true competitive advantage and innovation lie.\\n\\nAs Cognitive AI begins to reshape the landscape of artificial intelligence, it is imperative to navigate this new terrain with an awareness of the ethical, societal, and technological implications of self-reflective and self-modifying AI.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"The journey towards fully realizing the potential of Cognitive AI involves careful consideration of these factors to ensure that the benefits of such advanced AI technologies are realized equitably and responsibly.\\n\\nThe advent of Cognitive AI is not just a milestone in the evolution of AI technology but a beacon for the future of human-machine collaboration. It signals a shift towards a world where AI's potential to enhance human capabilities and address real-world problems is boundless.\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='As we forge ahead, the development and deployment of Cognitive AI stands as a testament to human ingenuity and as a step towards a future where AI and humans collaborate to achieve levels of exponential intelligence that neither could accomplish alone. The exploration of Cognitive AI, and its impact on redefining the essence of intelligence and the possibilities of technological advancement, is just beginning.\\n\\nThe journey ahead promises to be as transformative as it is challenging, beckoning us to engage with, develop, and deploy Cognitive AI in ways that amplify our collective potential and propel us towards a more intelligent, adaptable, and innovative future.\\n\\n57\\n\\nReferences' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Berglund, L., Tong, M., Kaufmann, M., Balesni, M., Stickland, A. C., Korbak, T., & Evans, O. (2023). The Reversal Curse: LLMs trained on \"A is B\" fail to learn \"B is A\". https://arxiv.org/abs/2309.12288\\n\\nBengio, Yoshua (11 December 2019) . “ From System 1 Deep Learning to System 2 Deep Learning”. Presentation at NeurIPS2019. Yoshua Bengio · From System 1 Deep Learning to System 2 Deep Learning · SlidesLive\\n\\nBesta, M., Memedi, F., Zhang, Z., Gerstenberger, R., Blach, N., Nyczyk, P., Copik, M., Kwaśniewski, G., Müller, J., Gianinazzi, L., Kubicek, A., Niewiadomski, H., Mutlu, O., & Hoefler, T. (2024). Topologies of Reasoning: Demystifying Chains, Trees, and Graphs of Thoughts. https://arxiv.org/abs/2401.14295' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Brynjolfsson, E., et al. (2023). Generative AI at Work. NBER Working Paper 31161. https://www.nber.org/papers/w31161\\n\\nBundy, A., Chater, N., & Muggleton, S. (2023). Introduction to ‘Cognitive artificial intelligence’. Philosophical Transactions of the Royal Society A, https://doi.org/10.1098/rsta.2022.0051\\n\\nChollet, François (6 December 2020). :Abtraction & Reasoning in AI Systems: A Modern Perspective”. Presentation at NeurIPS2020. Abstraction & Reasoning in AI systems: Modern Perspectives · SlidesLive' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Conneau, A., Khandelwal, K., Goyal, N., Chaudhary, V., Wenzek, G., Guzmán, F., … & Stoyanov, V. (2020). Unsupervised cross-lingual representation learning at scale. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. https://doi.org/10.18653/v1/2020.acl-main.747' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Dell'Acqua, Fabrizio and McFowland, Edward and Mollick, Ethan R. and Lifshitz-Assaf, Hila and Kellogg, Katherine and Rajendran, Saran and Krayer, Lisa and Candelon, François and Lakhani, Karim R., Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality (September 15, 2023). Harvard Business School Technology & Operations Mgt. Unit Working Paper No. 24-013, Available at SSRN: https://ssrn.com/abstract=4573321 or http://dx.doi.org/10.2139/ssrn.4573321\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Butler, J., Jaffe, S., Baym, N., Czerwinski, M., Iqbal, S., Nowak, K., Rintel, R., Sellen, A., Vorvoreanu, M., Hecht, B., and Teevan, J. (Eds.). Microsoft New Future of Work Report 2023. Microsoft Research Tech Report MSR-TR-2023-34. https://aka.ms/nfw2023\\n\\n58\\n\\nCambon, A., et al. (2023), Early LLM-based Tools for Enterprise Information Workers Likely Provide Meaningful Boosts to Productivity. MSFT Technical Report. https://www.microsoft.com/en-us/research/publication/early-llm-based-tools-for-enterprise-infor mation-workers-likely-provide-meaningful-boosts-to-productivity/ Devlin, J., Chang, M., Lee, K., & Toutanova, K. (2019). Untitled. Proceedings of the 2019 Conference of the North. https://doi.org/10.18653/v1/n19-1423' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Guo, Taicheng & Chen, Xiuying & Wang, Yaqi & Chang, Ruidi & Pei, Shichao & Chawla, Nitesh & Wiest, Olaf & Zhang, Xiangliang. (2024). Large Language Model based Multi-Agents: A Survey of Progress and Challenges. http://dx.doi.org/10.13140/RG.2.2.36311.85928\\n\\nHaslberger, M., et al. (2023) No Great Equalizer: Experimental Evidence on AI in the UK Labor Market. SSRN Working Paper 4594466. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4594466\\n\\nHaviv, A., Berant, J., & Globerson, A. (2021). Bertese: learning to speak to bert.. https://doi.org/10.18653/v1/2021.eacl-main.316\\n\\nHofstadter, Douglas R., 1945-. Gödel, Escher, Bach : an Eternal Golden Braid. New York :Basic Books, 1979.' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Ishay, A., Yang, Z., & Lee, J. (2023). Leveraging large language models to generate answer set programs. Proceedings of the Twentieth International Conference on Principles of Knowledge Representation and Reasoning. https://doi.org/10.24963/kr.2023/37\\n\\nKahneman, Daniel. “Thinking Fast and Slow”, Penguin Books, 2011.\\n\\nLatapie, H., O. Kilic, K. R. Thórisson, P. Wang & P. Hammer (2022). Neurosymbolic Systems of Perception and Cognition: The Role of Attention. Front. Psychol., 20 May 2022, Sec. Cognitive Science, Volume 13 - 2022 | https://doi.org/10.3389/fpsyg.2022.806397\\n\\nLaunchbury, John. “A DARPA Perspective on Artificial Intelligence”. DARPA, A DARPA Perspective on Artificial Intelligence' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='LeCun, Y. (2022, June 27). A path towards autonomous machine intelligence (Version 0.9.2). Courant Institute of Mathematical Sciences, New York University & Meta - Fundamental AI Research. A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27\\n\\nLiao, Q. V., Subramonyam, H., Wang, J., & Vaughan, J. (2023). Designerly understanding: information needs for model transparency to support design ideation for ai-powered user experience. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3544548.3580652\\n\\nMinsky, M. (1988). The Society of Mind. Simon & Schuster. ISBN 978-0-671-65713-0.\\n\\n59' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Moiseev, F., Dong, Z., Alfonseca, E., & Jaggi, M. (2022). Skill: structured knowledge infusion for large language models. https://doi.org/10.18653/v1/2022.naacl-main.113\\n\\nMohammad, Shah (2017), Design for “Crossing the Chasm” — Strategy & Examples. https://shahmm.medium.com/design-for-crossing-the-chasm-1c4d4c68a3f1\\n\\nMökander, J., Schuett, J., Kirk, H. R., & Floridi, L. (2023). Auditing large language models: a three-layered approach. AI and Ethics. https://doi.org/10.1007/s43681-023-00289-2\\n\\nNguyen, H., Fungwacharakorn, W., & Satoh, K. (2023). Logilaw dataset towards reinforcement learning from logical feedback (rllf). Frontiers in Artificial Intelligence and Applications. https://doi.org/10.3233/faia230967' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Nivel, E., K. R. Thórisson, B. R. Steunebrink, H. Dindo, G. Pezzulo, M. Rodriguez, C. Hernandez, D. Ognibene, J. Schmidhuber, R. Sanz, H. P. Helgason, A. Chella & G. K. Jonsson (2013). Bounded Recursive Self-Improvement. Reykjavik University School of Computer Science Technical Report, RUTR-SCS13006 / arXiv:1312.6764 [cs.AI] https://arxiv.org/abs/1312.6764\\n\\nNoy, S., & Zhang, W. (2023). Experimental Evidence on the Productivity Effects of Generative Artificial Intelligence. SSRN preprint.\\n\\nSpatharioti, S. E., et al. (2023). Comparing Traditional and LLM-based Search for Consumer Choice: A Randomized Experiment. arXiv preprint. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4375283' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Neil C. Thompson, Kristjan Greenewald, Keeheon Lee, G. Manso (10 July 2020). “The Computational Limits of Deep Learning”. [2007.05558] The Computational Limits of Deep Learning\\n\\nMinaee, S., Mikolov, T., Nikzad, N., Chenaghlu, M., Socher, R., Amatriain, X., & Gao, J. (2024). Large Language Models: A Survey. *arXiv preprint arXiv:2402.06196*. https://arxiv.org/abs/2402.06196\\n\\nPan, X., Yao, W., Zhang, H., Dang, Y., Yu, D., & Chen, J. (2022). Knowledge-in-context: towards knowledgeable semi-parametric language models. https://doi.org/10.48550/arxiv.2210.16433\\n\\nPeng, S., et al. (2023). The Impact of AI on Developer Productivity: Evidence from GitHub Copilot. arXiv preprint 2302.06590. https://arxiv.org/abs/2302.06590' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Porada, I., Suleman, K., & Cheung, J. (2019). Can a gorilla ride a camel? learning semantic plausibility from text. https://doi.org/10.18653/v1/d19-6015\\n\\nSpivack, Nova (2016), AI, BI, and the Necessity of Automating the Analyst. https://www.novaspivack.com/science/ai-bi-and-the-necessity-of-automating-the-analyst\\n\\n60\\n\\nShojaee-Mend, H., Mohebbati, R., Amiri, M., & Atarodi, A. (2023). Evaluating the strengths and weaknesses of large language models in answering neurophysiology questions. https://doi.org/10.21203/rs.3.rs-3348418/v1\\n\\nSinger, Gadi (31 January 2018). “Toward truly intelligent AI: From ‘Recognition’ to ‘Understanding’ https://www.linkedin.com/pulse/toward-truly-intelligent-ai-from-recognition-gadi-singer/' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='B. R. Steunebrink, K. R. Thórisson, J. Schmidhuber (2016). Growing Recursive Self-Improvers. In B. Steunebrink et al. (eds.), Proc. 9th International Conference on Artificial General Intelligence (AGI-16), July, New York City, 129-139. https://www.iiim.is/wp/wp-content/uploads/2014/05/AGI16_growing_recursive_self-improvers .pdf\\n\\nSun, Y. (2021). Ernie 3.0: large-scale knowledge enhanced pre-training for language understanding and generation. https://doi.org/10.48550/arxiv.2107.02137' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Thórisson, K. R. (2012). A New Constructivist AI: From Manual Construction to Self-Constructive Systems. In P. Wang and B. Goertzel (eds), Theoretical Foundations of Artificial General Intelligence. Atlantis Thinking Machines, 4:145-171. https://alumni.media.mit.edu/~kris/ftp/Thorisson_chapt9_TFofAGI_Wang_Goertzel_2012.pdf\\n\\nThórisson, K. R., D. Kremelberg, B. R. Steunebrink, E. Nivel (2016). About Understanding. In B. Steunebrink et al. (eds.), Proc. 9th International Conference on Artificial General Intelligence (AGI-16), July, New York City, 106-117. https://www.researchgate.net/publication/311589219_About_Understanding' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Thórisson, K. R. & A. Talbot (2018). Abduction, Deduction & Causal-Relational Models. IJCAI-18 Workshop on Architectures for Generality, Autonomy & Progress in AI, International Joint Conference on Artificial Intelligence, Stockholm, Sweden, Jul. 15. http://alumni.media.mit.edu/~kris/ftp/AEGAP18_Abduction_Deduction_Causal_Relational_Mo dels.pdf\\n\\nThórisson, K. R. (2020). Seed-Programmed Autonomous General Learning. Proc. Machine Learning Research, 131:32-70. http://proceedings.mlr.press/v131/thorisson20a/thorisson20a.pdf\\n\\nThórisson, K. R. (2021). The 'Explanation Hypothesis' in General Self-Supervised Learning. Proc. Machine Learning Research, 159:5-27. https://proceedings.mlr.press/v159/thorisson22b/thorisson22b.pdf\\n\\n61\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content=\"Valmeekam, K., Marquez, M., Olmo, A., Sreedharan, S., & Kambhampati, S. (2023). PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change. *arXiv preprint arXiv:2206.10498*. Retrieved from https://arxiv.org/abs/2206.10498\\n\\nValmeekam, K., Olmo, A., Sreedharan, S., & Kambhampati, S. (2022). Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change). In *NeurIPS 2022 Foundation Models for Decision Making Workshop*. Retrieved from https://openreview.net/forum?id=wUU-7XTL5XO\\n\\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., … & Polosukhin, I. (2017). Attention is all you need. https://doi.org/10.48550/arxiv.1706.03762\" metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Wu, T., Terry, M., & Cai, C. J. (2021). Ai chains: transparent and controllable human-ai interaction by chaining large language model prompts. https://doi.org/10.48550/arxiv.2110.01691\\n\\nYang, J., Wu, D., & Wang, K. (2023). Not All Large Language Models (LLMs) Succumb to the \"Reversal Curse\": A Comparative Study of Deductive Logical Reasoning in BERT and GPT Models. arXiv preprint https://arxiv.org/abs/2312.03633\\n\\nYang, K., Jia, D., & Chen, D. (2022). Generating natural language proofs with verifier-guided search. https://doi.org/10.48550/arxiv.2205.12443\\n\\nZhao, G., Li, Y., & Xu, Q. (2022). From emotion AI to cognitive AI. University of Oulu. (2022). https://www.sciltp.com/journals/ijndi/2022/1/115' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n",
            "page_content='Zhu, Y., Gao, T., Fan, L., Huang, S., Edmonds, M., Liu, H., Gao, F., Zhang, C., Qi, S., Wu, Y. N., Tenenbaum, J. B., & Zhu, S.-C. (2020). Dark, beyond deep: A paradigm shift to cognitive AI with humanlike common sense. Engineering, 6(3), 310-345. https://doi.org/10.1016/j.eng.2020.01.011\\n\\n62' metadata={'source': '/content/Cognition is All You Need - Article.pdf'}\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# Print each split and a separator for readability\n",
        "for split in splits:\n",
        "    print(split)\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI475GvX4X8b"
      },
      "source": [
        "#### <font color=FF595E>Create embeddings</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFrdfjo34fqJ"
      },
      "outputs": [],
      "source": [
        "#Import vectorstore database and embeddings model\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Embeddings model\n",
        "embeddings_model = OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ckp85W74w_0"
      },
      "outputs": [],
      "source": [
        "#Define vector DB. Run this line of code only once.\n",
        "#If accidently did more delete DB\n",
        "\n",
        "vector_db = Chroma.from_documents(documents=splits, embedding=embeddings_model())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Code to delete db. (if needed)\n",
        "\n",
        "# Delete the collection\n",
        "# vector_db.delete_collection()\n",
        "# print(\"Collection deleted successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "ZV77LGQJG-id",
        "outputId": "ce050789-adc3-45b2-9914-007ea5d2c48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'vector_db' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-c1168a650156>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Delete the collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvector_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Collection deleted successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vector_db' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSXMkxex49yT"
      },
      "source": [
        "#### <font color=FF595E>Define Retriever</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xhCcKBz48Ym"
      },
      "outputs": [],
      "source": [
        "retriever = vector_db.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFZGgepR5NrR"
      },
      "source": [
        "#### <font color=FF595E>Test retriever</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmEEL-zm5UpZ",
        "outputId": "85b4e3cb-93ed-48da-a97f-6ba2e2003cf7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(page_content=\"Figure 6. Conversational Versus Cognitive AI Quadrants.\\n\\nCognitive AI Functional Architecture\\n\\nCognitive AI represents a paradigm shift, moving beyond the confines of Conversational AI's reliance on probabilistic reasoning simulations to actual programmatic reasoning. This shift is embodied in a dual-layer architecture that elevates reasoning, self-improvement, and adaptability to second-order intelligence, fundamentally distinguishing Cognitive AI from its predecessors. Below we will discuss the functional architecture and formal requirements for Cognitive AI systems.\\n\\nFunctional Requirements for Cognitive AI\\n\\nTo qualify as Cognitive AI, a system must be architected to meet the following functional criteria:\", metadata={'source': '/content/Cognition is All You Need - Article.pdf'}),\n",
              "  0.1989898979663849),\n",
              " (Document(page_content='Reasoning....................................................................................... 13 Defining Cognitive AI............................................................................................................. 14 Cognitive AI Functional Architecture......................................................................................15 Functional Requirements for Cognitive AI........................................................................ 15 Dual-Layer Architecture...................................................................................................... 17 Large Language Models......................................................................................................19 Cognitive', metadata={'source': '/content/Cognition is All You Need - Article.pdf'}),\n",
              "  0.20082935690879822),\n",
              " (Document(page_content='One of the most important differentiating cognitive features of higher-intelligent lifeforms on Earth is the ability to form goals and execute complex multi-step plans to achieve them. Humans and a few other species are capable of this level of conceptual thinking. To form,\\n\\n37\\n\\nmaintain and execute plans requires a high level of abstract reasoning. Cognitive AI is able to model arbitrary types of plans with conditional logic workflows that both humans and agents can collaborate with.\\n\\nIn more concrete terms, recursive self-improvement is implemented in Cognitive AI architectures as a goal-directed process across one or more cognitive functions, where at least one must be a planning function.', metadata={'source': '/content/Cognition is All You Need - Article.pdf'}),\n",
              "  0.2562018632888794)]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "#Define question\n",
        "question = 'What are functional requirements for cognitive AI'\n",
        "\n",
        "#Fetch 3 documents from vector store related to question\n",
        "vector_db.similarity_search_with_score(question, k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHo7ejrc6Nv-"
      },
      "source": [
        "#### <font color=FF595E>Biuld chain that will answer queestions over defined docs</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2f-Hd586VM5",
        "outputId": "76d61a7a-5ded-4818-fd44-4b223d216ac6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='Answer the question based on the following context:\\n{context}\\n\\nQuestion: {question}\\n'))])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "# Prompt\n",
        "template = \"\"\"Answer the question based on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "#Define rag_prompt from template\n",
        "rag_prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "#Print the promt to check it everything is ok\n",
        "rag_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJKe7Kg06oZ9"
      },
      "outputs": [],
      "source": [
        "#Define LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfeUcpe66q_0"
      },
      "outputs": [],
      "source": [
        "RAG_llm = ChatOpenAI(model=GPT4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZri0Cgh6wN9"
      },
      "outputs": [],
      "source": [
        "#Define Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qi7Ce2bF6zxJ"
      },
      "outputs": [],
      "source": [
        "RAG_chain = rag_prompt | RAG_llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asInZZHw6679"
      },
      "outputs": [],
      "source": [
        "#Assign docs\n",
        "docs = vector_db.similarity_search(question, k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGCCU5uc7ome",
        "outputId": "b7b85d8a-4675-4531-fd2d-63ce197d795a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"The functional requirements for Cognitive AI, as outlined in the provided context, are not fully enumerated in the excerpts given. However, from the information provided, we can infer some of the key elements that are considered essential for a system to qualify as Cognitive AI:\\n\\n1. **Reasoning:** Cognitive AI must be capable of programmatic reasoning, moving beyond probabilistic reasoning simulations that are typical in Conversational AI. This implies a more advanced form of reasoning that can deal with complex, abstract concepts and execute conditional logic workflows.\\n\\n2. **Self-Improvement:** The architecture of Cognitive AI includes the capability for recursive self-improvement. This means the system is designed to continuously refine and enhance its own cognitive functions, including planning and reasoning, without external intervention.\\n\\n3. **Adaptability:** Cognitive AI systems must be adaptable, able to handle and adjust to new information or changes in their operating environment. This adaptability is crucial for the system’s ability to perform in dynamic real-world situations.\\n\\n4. **Planning Function:** At least one of the cognitive functions in a Cognitive AI system must be dedicated to planning. This involves the ability to form, maintain, and execute complex multi-step plans, incorporating conditional logic to achieve specific goals. This feature highlights the system's capacity for higher-level abstract reasoning similar to that of humans and other intelligent life forms.\\n\\n5. **Dual-Layer Architecture:** While not a functional requirement per se, the document mentions a dual-layer architecture as part of the Cognitive AI paradigm. This architecture presumably supports the system's reasoning, self-improvement, and adaptability by organizing cognitive functions into layers that can interact and refine each other.\\n\\nThese inferred requirements suggest that Cognitive AI aims to mimic the cognitive capabilities of higher-intelligent life forms, such as humans, in terms of reasoning, planning, and self-improvement, positioning these systems far beyond the capabilities of traditional Conversational AI.\", response_metadata={'finish_reason': 'stop', 'logprobs': None})"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "#Chain to answer question based on defined docs\n",
        "RAG_chain.invoke({\"context\":docs,\"question\": question})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0GdlvYG8n7N"
      },
      "source": [
        "#### <font color=FF595E>Composing the Retrieval-Augmented Generation Chain with dynamic retrieval</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VErBPe5S8yoQ"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "\n",
        "# Create the Retrieval-Augmented Generation (RAG) chain with dynamic retrieval\n",
        "rag_chain = (\n",
        "    # Define the input variables for the chain\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    # Pipe the input through the RAG prompt template\n",
        "    | rag_prompt\n",
        "    # Pass the formatted prompt to the language model (LLM)\n",
        "    | RAG_llm\n",
        "    # Parse the LLM's output using the StrOutputParser\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "nerKoeAU9Tiz",
        "outputId": "d87637e6-7f68-47a2-8af8-294f49c1baa2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"At the core of Cognitive AI's functional architecture is an intelligence stack comprising two critical layers: a Cognitive Layer and a Conversational Layer.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "#Invoke the chain\n",
        "\n",
        "rag_chain.invoke(\"What lies at the core of Cognitive AI's functional architecture?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsCq9hQ_-h-u"
      },
      "source": [
        "#### <font color=FF595E>Build RAG BOT chain prompt template</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAS8zwGe-ft5"
      },
      "outputs": [],
      "source": [
        "#Import required classes for prompt template\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "# Define the human prompt template\n",
        "# Here we making sure that context will be passed to LLM before question will be added by human.\n",
        "human_prompt = \"\"\"Answer the question based on the following context: {context}\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BFWS2tU_GRG"
      },
      "outputs": [],
      "source": [
        "# Initialize the chat history\n",
        "chat_history = ChatMessageHistory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kC-AtUKo_H3O"
      },
      "outputs": [],
      "source": [
        "# Define the question\n",
        "question = \"What lies at the core of Cognitive AI's functional architecture?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziPVct5i_b8K"
      },
      "outputs": [],
      "source": [
        "# Retrieve relevant context based on the question\n",
        "context = vector_db.similarity_search(question, k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-nZh8nv_e3W"
      },
      "outputs": [],
      "source": [
        "# Create a PromptTemplate from the human prompt\n",
        "prompt_template = PromptTemplate.from_template(human_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFcRGk7v_pPL"
      },
      "outputs": [],
      "source": [
        "# Format the prompt with the retrieved context and question\n",
        "formatted_prompt = prompt_template.format(context=context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hpm9Hn5P_wKd"
      },
      "outputs": [],
      "source": [
        "# Create a HumanMessage with the formatted prompt\n",
        "formatted_human_message = [HumanMessage(content=formatted_prompt)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHTX7REv_83k"
      },
      "outputs": [],
      "source": [
        "# Define the RAG prompt template\n",
        "rag_bot_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant. Answer all questions over the documents to the best of your ability.\"),\n",
        "        *formatted_human_message,\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FH0lA3GZAP9i"
      },
      "outputs": [],
      "source": [
        "# Create the RAG LLM chain by piping the RAG prompt to the LLM\n",
        "rag_bot_chain = rag_bot_prompt | RAG_llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QTgsoWAAgne",
        "outputId": "690a5c90-7d0c-4db8-901f-d12db65aab18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting the chat...\n",
            "AI: Alright, imagine your brain is like a super cool toy that can think and solve puzzles. This toy has two special parts. The first part is really good at playing with words, like when you tell stories or chat with your friends. The second part is like a superhero that can think really hard about problems, make smart guesses, and learn new things from puzzles and games you play. \n",
            "\n",
            "Neuro-symbolic reasoning is when both parts work together to help the toy (which is like a computer) understand and think about things almost like a human does. So, if you ask it a tricky question or give it a tough puzzle, it uses the word-playing part to understand the question and the superhero part to figure out the answer. It's like having a buddy who's really good at both telling stories and solving riddles!\n",
            "User: stop\n",
            "Exiting the chat...\n"
          ]
        }
      ],
      "source": [
        "#Define stop words for our chatbot\n",
        "stop_words = [\"exit\", \"quit\", \"stop\"]\n",
        "\n",
        "chat_history = ChatMessageHistory()\n",
        "\n",
        "\n",
        "rag_chain_with_message_history = RunnableWithMessageHistory(\n",
        "    rag_bot_chain,\n",
        "    lambda session_id : chat_history,\n",
        "    input_messages_key=\"messages\",\n",
        "    history_messages_key=\"chat_history\"\n",
        ")\n",
        "\n",
        "# Perform chat turns\n",
        "print(\"Starting the chat...\")\n",
        "while True:\n",
        "    question = input(\"User: \")\n",
        "\n",
        "    # Check if the user input matches a stop word\n",
        "    if question.lower() in stop_words:\n",
        "        print(\"Exiting the chat...\")\n",
        "        break\n",
        "\n",
        "    # Retrieve relevant context based on the question\n",
        "    context = vector_db.similarity_search(question, k=3)\n",
        "\n",
        "    # Add a user message to the chat history\n",
        "    chat_history.add_user_message(question)\n",
        "\n",
        "    #Generate AI response\n",
        "    ai_response = rag_chain_with_message_history.invoke({\"messages\": chat_history.messages}, {\"configurable\": {\"session_id\": chat_history}})\n",
        "\n",
        "    # Add an AI response message to the chat history\n",
        "    chat_history.add_ai_message(ai_response.content)\n",
        "\n",
        "    #Display AI answer\n",
        "    print(f\"AI: {ai_response.content}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}